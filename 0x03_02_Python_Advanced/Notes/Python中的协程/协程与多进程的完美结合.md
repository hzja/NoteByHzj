Python 协程 多进程<br />协程本质上是单线程单进程，通过充分利用IO等待时间来实现高并发。在IO等待时间之外的代码，还是串行运行的。因此，如果协程非常多，多少每个协程内部的串行代码运行时间超过了IO请求的等待时间，那么它的并发就会有一个上限。<br />举个例子，电饭煲煮饭，洗衣机洗衣服，热水壶烧水，他们都是启动设备以后就能自己运行，可以利用他们自己运行的时间，让这三件事情看起来几乎在同时进行。但如果除了这三件事情外，还有开电视，开空调，发微信……等等几十个事情。每个事情单独拿出来确实都只需要做个开头，剩下的就是等，但由于做这个开头也需要时间，因此把他们全部启动起来也要不少时间，效率还是被卡住。<br />现在，如果有两个人一起来做这些事情，那情况就不一样了。一个人煮饭和烧水，另一个人开洗衣机，开电视和空调。效率进一步提升。<br />这就是协程与多进程的结合，每个进程里面多个协程同时运行，充分利用CPU的每一个核心，又充分利用了IO等待时间，把CPU跑满，把网络带宽跑满。强强联合，速度更快。<br />有一个第三方库aiomultiprocess，能用几行代码就实现多进程与协程的组合。<br />首先使用pip安装：
```bash
python3 -m pip install aiomultiprocess
```
它的语法非常简单：
```python
from aiomultiprocess import Pool
async with Pool() as pool:
    results = await pool.map(协程, 参数列表)
```
只需要3行代码，它就会在CPU上每个核启动一个进程，每个进程中不停启动协程。<br />来写一段实际代码：
```python
import asyncio
import httpx
from aiomultiprocess import Pool

async def get(url):
    async with httpx.AsyncClient() as client:
        resp = await client.get(url)
        return resp.text


async def main():
    urls = [url1, url2, url3]
    async with Pool() as pool:
        async for result in pool.map(get, urls):
            print(result)  # 每一个URL返回的内容

if __name__ == '__main__':
    asyncio.run(main())
```
关于`aiomultiprocess`的更多使用，可以参阅它的[**官方文档**](https://aiomultiprocess.omnilib.dev/en/latest/guide.html)**。**<br />**参考文献**<br />官方文档: [https://aiomultiprocess.omnilib.dev/en/latest/guide.html](https://aiomultiprocess.omnilib.dev/en/latest/guide.html)
