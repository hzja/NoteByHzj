Linux uniq
```bash
root@Fcant:~ $ cat ghostwu.txt 
192.168.1.2
192.168.1.8
192.168.1.3
192.168.1.3
192.168.1.9
192.168.1.8
192.168.1.8
192.168.1.0
192.168.1.3
root@Fcant:~ $ uniq ghosts.txt 
192.168.1.2
192.168.1.8
192.168.1.3
192.168.1.9
192.168.1.8
192.168.1.0
192.168.1.3
```
去除连续的重复行。
<a name="YLgLk"></a>
### -u：只保留文件中的唯一
```bash
root@Fcant:~ $ uniq -u ghosts.txt 
192.168.1.2
192.168.1.8
192.168.1.9
192.168.1.0
192.168.1.3
```
<a name="MxP3a"></a>
### -c：去重复，并计算每行出现的次数
```bash
root@Fcant:~ $ uniq -c ghosts.txt 
1 192.168.1.2
1 192.168.1.8
2 192.168.1.3
1 192.168.1.9
2 192.168.1.8
1 192.168.1.0
1 192.168.1.3
root@Fcant:~ $ cat -n ghosts.txt 
1    192.168.1.2
2    192.168.1.8
3    192.168.1.3
4    192.168.1.3
5    192.168.1.9
6    192.168.1.8
7    192.168.1.8
8    192.168.1.0
9    192.168.1.3
```
<a name="e20a256c"></a>
### 可以用sort命令排序后，再去重复，得到的结果　也是唯一的
```bash
root@Fcant:~ $ sort -n ghosts.txt | uniq -c
1 192.168.1.0
1 192.168.1.2
3 192.168.1.3
3 192.168.1.8
1 192.168.1.9
```
<a name="LeVEN"></a>
### -d: 只显示重复的行
```bash
root@Fcant:~ $ uniq -d ghosts.txt 
192.168.1.3
192.168.1.8
```

