如果使用传统的加密算法(如AES)直接将敏感数据加密后发给合作方，那么在失去了统计特征的密文上，机器学习将无法有效地学习，所以选择合适的安全机制是实现联邦学习最关键的点之一。为了将多个参与者各自的数据拼凑在一起，并在这个拼凑的数据集上进行计算，在保证数据安全性的同时得到最终的结果，联邦学习针对不同的业务需求选择不同的安全机制，大致可归为以下两大类：

- 基于噪音：差分隐私
- 基于加密：同态加密、安全多方计算(密钥共享、不经意传输、混淆电路)

其中严格来说，同态加密并非狭义的安全计算（MPC）的范畴，而是自成一体系。只是同态加密所实现目标与安全计算有诸多类似之处，因此广义上安全计算也可将其囊括在内。相较于混淆电路和秘密分享，同态加密的思路其实更为直观：直接将原文加密，然后在密文上进行各种运算，最终得到结果的密文。
<a name="vmiRy"></a>
# 机制分类
<a name="WoXqq"></a>
## 基于噪音
基于噪音的安全计算方法，最主要代表是目前很火的差分隐私(differential privacy)。这类方法的思想是，对计算过程用噪音干扰，让原始数据淹没在噪音中，使别有用心者无法从得到的结果反推原始数据。这就好像我们拿到一张打了马赛克的图片，虽然可能可以猜出马赛克后面大概长啥样，但很难知道马赛克后面的所有细节。<br />![基于噪音.jpeg](./img/1622532989125-d580eeae-7228-4c6e-94fb-f721f5dfd9d5.jpeg)
<a name="ZQs1c"></a>
## 基于密码学
非噪音方法一般是通过密码学方法将数据编码或加密，得到一些奇怪的数字，而且这些奇怪的数字有一些神奇的性质，比如看上去很随机但其实保留了原始数据的线性关系，或者顺序明明被打乱但人们却能从中很容易找到与原始数据的映射关系。如果将计算过程比作炒菜，那数据就是炒菜的原料，输出就是最后做出来的美味佳肴。而实现安全计算方法，就好像是让厨师闭着眼睛炒菜一般。
<a name="x5av2"></a>
# 使用场景
|  | 横向联邦学习 | 纵向联邦学习 |
| --- | --- | --- |
| 安全机制 | 核心技术为差分隐私或安全多方计算。同态加密为辅助技术，一般对差分隐私噪声进行加密 | 使用半同态加密对中间值进行处理，只传输中间结果的密文 |

在横向联邦学习中，核心技术一般为差分隐私或者安全多方计算。同态加密算法作为一种辅助技术，对差分隐私的噪声进行加密，而算法的隐私保护更多的是由差分隐私本身和安全多方计算完成的。

在纵向联邦学习中，不同的参与方有不同的特征，为了实现协同训练，在训练过程中，不同的参与方之间需要传输中间结果以聚合所有特征的效果，但这些中间结果往往会被恶意的联邦成员用来推理分析用户的隐私数据。为了避免隐私的泄露，联邦学习使用半同态加密算法对中间值进行处理，只传输中间结果的密文。得益于半同态加密算法的性质，隐私不仅得到了保护，其他参与方仍然能通过中间结果的密文值完成协议内容。



