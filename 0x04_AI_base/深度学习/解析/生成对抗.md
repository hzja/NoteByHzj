<a name="0ab48b06"></a>
## [GAN原理介绍](https://arxiv.org/abs/1406.2661)

<a name="ece5150e"></a>
### 原理思想

生成对抗网络(Generative adversarial network, GAN)的基本原理其实非常简单，这里以生成图片为例进行说明。假设我们有两个网络，![](./img/dfcf28d0734569a6a693bc8194de62bf.svg)（Generator）和 ![](./img/f623e75af30e62bbd73d6df5b50bb7b5.svg)（Discriminator）。正如它的名字所暗示的那样，它们的功能分别是：

- ![](./img/dfcf28d0734569a6a693bc8194de62bf.svg) 是一个生成图片的网络，它接收一个随机的噪声 ![](./img/fbade9e36a3f36d3d676c1b808451dd7.svg) ，通过这个噪声生成图片，记做 ![](./img/e5b3819799b18c542307257031fe8c82.svg) 。
- ![](./img/f623e75af30e62bbd73d6df5b50bb7b5.svg)是一个判别网络，判别一张图片是real/fake, real是指输入图片来自于训练集，而fake是指图像不是来自于训练集，也就是虚假图片。它的输入参数是 ![](./img/9dd4e461268c8034f5c8564e155c67a6.svg) ，![](./img/9dd4e461268c8034f5c8564e155c67a6.svg)代表一张图片，输出 ![](./img/15444eb27adfc21cf2a51f356dc5fa78.svg)代表![](./img/9dd4e461268c8034f5c8564e155c67a6.svg)为真实图片的概率，如果为  ![](./img/c4ca4238a0b923820dcc509a6f75849b.svg)，就代表是真实的图片，而输出为 ![](./img/cfcd208495d565ef66e7dff9f98764da.svg) ，就代表不可能是真实的图片。

在训练过程中，**生成网络** ![](./img/dfcf28d0734569a6a693bc8194de62bf.svg)**的目标就是尽量生成真实的图片去欺骗判别网络** ![](./img/f623e75af30e62bbd73d6df5b50bb7b5.svg)**。而** ![](./img/f623e75af30e62bbd73d6df5b50bb7b5.svg) **的目标就是尽量把** ![](./img/dfcf28d0734569a6a693bc8194de62bf.svg) **生成的图片和真实的图片分别开来。**这样， ![](./img/dfcf28d0734569a6a693bc8194de62bf.svg) 和 ![](./img/f623e75af30e62bbd73d6df5b50bb7b5.svg) 构成了一个动态的“博弈过程”。最后博弈的结果是什么？在最理想的状态下，![](./img/dfcf28d0734569a6a693bc8194de62bf.svg) 可以生成足以“以假乱真”的图片 ![](./img/e5b3819799b18c542307257031fe8c82.svg) 。对于 ![](./img/f623e75af30e62bbd73d6df5b50bb7b5.svg) 来说，它难以判定 ![](./img/dfcf28d0734569a6a693bc8194de62bf.svg) 生成的图片究竟是不是真实的，因此 ![](./img/153594498a44d69f88ba4e385de1e51f.svg) 。这样我们的目的就达成了：我们得到了一个生成式的模型 ![](./img/dfcf28d0734569a6a693bc8194de62bf.svg) ，它可以用来生成图片。所以GAN的核心思想就是对抗训练(adversarial traning)。

<a name="03131841"></a>
### 公式描述

以上只是大致说了一下GAN的核心原理，如何用数学语言描述呢？这里直接摘录论文里的公式：<br />![v2-f98f1d3caabbca9b6baa4235c40150b4_hd.jpg](./img/1592378592364-8081cb64-fdb5-4260-8a29-abb5c2d57fb2.jpeg)<br />简单分析一下这个公式：

- 整个式子由两项构成。 ![](./img/9dd4e461268c8034f5c8564e155c67a6.svg)表示真实图片， ![](./img/fbade9e36a3f36d3d676c1b808451dd7.svg)表示输入 ![](./img/dfcf28d0734569a6a693bc8194de62bf.svg) 网络的噪声，而 ![](./img/e5b3819799b18c542307257031fe8c82.svg)表示 ![](./img/dfcf28d0734569a6a693bc8194de62bf.svg)网络生成的图片。
- ![](./img/15444eb27adfc21cf2a51f356dc5fa78.svg)表示 ![](./img/f623e75af30e62bbd73d6df5b50bb7b5.svg)网络判断真实图片是否真实的概率（因为![](./img/9dd4e461268c8034f5c8564e155c67a6.svg)就是真实的，所以对于![](./img/f623e75af30e62bbd73d6df5b50bb7b5.svg)来说，这个值越接近![](./img/c4ca4238a0b923820dcc509a6f75849b.svg)越好）。而![](./img/6f21971f22a50cd73b2de51691b73be8.svg)是![](./img/f623e75af30e62bbd73d6df5b50bb7b5.svg)网络判断![](./img/dfcf28d0734569a6a693bc8194de62bf.svg)生成的图片的是否真实的概率。
- ![](./img/dfcf28d0734569a6a693bc8194de62bf.svg)的目的：上面提到过，![](./img/6f21971f22a50cd73b2de51691b73be8.svg)是![](./img/f623e75af30e62bbd73d6df5b50bb7b5.svg)网络判断![](./img/dfcf28d0734569a6a693bc8194de62bf.svg)生成的图片是否真实的概率，![](./img/dfcf28d0734569a6a693bc8194de62bf.svg)应该希望自己生成的图片“越接近真实越好”。也就是说，![](./img/dfcf28d0734569a6a693bc8194de62bf.svg)希望![](./img/6f21971f22a50cd73b2de51691b73be8.svg)尽可能得大，也就等价于使得![](./img/841f40650f47fdccfdc38e066be4a823.svg)尽可能小。因此我们看到式子的最前面的记号是 ![](./img/ed729616aaf3b406eed57498c00a39b2.svg)。
- ![](./img/f623e75af30e62bbd73d6df5b50bb7b5.svg)的目的：![](./img/f623e75af30e62bbd73d6df5b50bb7b5.svg)的能力越强，![](./img/15444eb27adfc21cf2a51f356dc5fa78.svg)应该越大，![](./img/0c45a4b72f3a34258b138c5552bf2155.svg)应该越小。这时![](./img/b0e66a772b60f237845133f29f219de4.svg)会变大。因此式子对于 ![](./img/f623e75af30e62bbd73d6df5b50bb7b5.svg)来说是求最大 ![](./img/713991a19d254b56918a9b2201b1332b.svg)。

<a name="GfOba"></a>
### 训练过程

下面这幅图片很好地描述了这个过程：<br />![image.png](./img/1592379575377-114e3030-43e2-486a-a46f-a632702b11fb.png)<br />其中，黑色虚线是训练集中真实样本的概率密度分布，绿色实线是生成器G生成的假样本的概率密度分布，蓝色虚线是判别器D的概率分布。

1. 从随机噪声分布z中采样，经过G，生成假样本，此时G的拟合能力比较差，生成的样本与真实样本差别很大；
2. 经过训练的判别器D，很容易将真/假样本分辨出来；
3. 在判别器D的梯度引导下，生成器G能够生成更逼真的假样本；
4. 最终，经过多轮的对抗训练，生成器G能够完美拟合真实样本的概率分布，而判别器也已经无法分辨出真假样本，几乎处处D(G(z))=0.5;

那么如何用随机梯度下降法训练D和G？论文中也给出了算法：<br />![v2-78851777a659db4821695242cd39b42e_hd.jpg](./img/1592379652871-d0623629-5b36-4e21-9beb-880f66dd289c.jpeg)<br />这里红框圈出的部分是我们要额外注意的。第一步我们训练![](./img/f623e75af30e62bbd73d6df5b50bb7b5.svg)，![](./img/f623e75af30e62bbd73d6df5b50bb7b5.svg)是希望![](./img/bc2ed849f3366239a001b2ae243d2775.svg)越大越好，所以是梯度上升求最大值，也就等价于加上梯度(ascending)。第二步训练![](./img/dfcf28d0734569a6a693bc8194de62bf.svg)时，![](./img/bc2ed849f3366239a001b2ae243d2775.svg)越小越好，所以是梯度下降求最小值，也等价于减去梯度(descending)。整个训练过程交替进行直至收敛。

<a name="RfpUp"></a>
### 总结
生成对抗网络基于对抗训练的思想构建生成模型，只要是可微的模型，都可以用来构建判别器/生成器。模型训练直接使用反向传播算法，无需MCMC进行梯度估计，这是相比其他生成模型的优势。但是GAN仍然存在训练不稳定，模式塌陷等问题。

<a name="IOzy0"></a>
### Code实现
[https://github.com/jiqizhixin/ML-Tutorial-Experiment/blob/master/Experiments/tf_GAN.ipynb](https://github.com/jiqizhixin/ML-Tutorial-Experiment/blob/master/Experiments/tf_GAN.ipynb)

<a name="Lppys"></a>
### Source
[https://arxiv.org/abs/1406.2661](https://arxiv.org/abs/1406.2661)
