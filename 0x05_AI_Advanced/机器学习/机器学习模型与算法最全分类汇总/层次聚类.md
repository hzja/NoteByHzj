机器学习 层次聚类<br />聚类属于机器学习的无监督学习，而且也分很多种方法，比如大家熟知的有K-means。层次聚类也是聚类中的一种，也很常用。下面先简单回顾一下K-means的基本原理，然后慢慢引出层次聚类的定义和分层步骤，这样更有助于大家理解。
<a name="cqC2u"></a>
## 层次聚类和K-means有什么不同？
K-means 工作原理可以简要概述为：

- 决定簇数（k）
- 从数据中随机选取 k 个点作为质心
- 将所有点分配到最近的聚类质心
- 计算新形成的簇的质心
- 重复步骤 3 和 4

这是一个迭代过程，直到新形成的簇的质心不变，或者达到最大迭代次数。<br />但是 K-means 是存在一些缺点的，必须在算法开始前就决定簇数 K 的数量，但实际并不知道应该有多少个簇，所以一般都是根据自己的理解先设定一个值，这就可能导致理解和实际情况存在一些偏差。<br />层次聚类完全不同，它不需要开始的时候指定簇数，而是先完整的形成整个层次聚类后，通过决定合适的距离，自动就可以找到对应的簇数和聚类。
<a name="YDZ4P"></a>
## 什么是层次聚类？
下面由浅及深的介绍什么是层次聚类，先来一个简单的例子。<br />假设有以下几点，将它们分组：<br />![](https://cdn.nlark.com/yuque/0/2021/webp/396745/1637715025127-077a593d-9028-40d7-b369-e2c62fe5f457.webp#clientId=u8d8faa84-43b4-4&from=paste&id=u4d1698c8&originalType=url&ratio=1&rotation=0&showTitle=false&status=done&style=shadow&taskId=u1776baba-e960-4c0a-92cb-9465493dfef&title=)<br />可以将这些点中的每一个分配给一个单独的簇，就是4个簇（4种颜色）：<br />![](https://cdn.nlark.com/yuque/0/2021/webp/396745/1637715025059-0e051d3b-6498-459b-aba3-597a3422ee8b.webp#clientId=u8d8faa84-43b4-4&from=paste&id=uc4c476f2&originalType=url&ratio=1&rotation=0&showTitle=false&status=done&style=shadow&taskId=u3a2cefcb-f6c2-4fdd-a3ca-ae297c48a3f&title=)<br />然后基于这些簇的相似性（距离），将最相似的（距离最近的）点组合在一起并重复这个过程，直到只剩下一个集群：<br />![](https://cdn.nlark.com/yuque/0/2021/webp/396745/1637715025060-ac947960-c5a5-4490-a49e-3d65d2b59b66.webp#clientId=u8d8faa84-43b4-4&from=paste&id=u9b59653d&originalType=url&ratio=1&rotation=0&showTitle=false&status=done&style=shadow&taskId=u22d0c870-5a33-42f9-914f-579c39c6f11&title=)<br />上面本质上就是在构建一个层次结构。先了解到这里，后面详细介绍它的分层步骤。
<a name="Py5px"></a>
## 层次聚类的类型
主要有两种类型的层次聚类：

- 凝聚层次聚类
- 分裂层次聚类
<a name="ZjXTU"></a>
### 凝聚层次聚类
先让所有点分别成为一个单独的簇，然后通过相似性不断组合，直到最后只有一个簇为止，这就是凝聚层次聚类的过程，和上面刚刚说的一致。
<a name="sc6lF"></a>
### 分裂层次聚类
分裂层次聚类正好反过来，它是从单个集群开始逐步分裂，直到无法分裂，即每个点都是一个簇。<br />所以无论是 10、100、1000 个数据点都不重要，这些点在开始的时候都属于同一个簇：<br />![](https://cdn.nlark.com/yuque/0/2021/webp/396745/1637715025046-c6ac20f7-b117-45ef-a5be-adfa71814c2f.webp#clientId=u8d8faa84-43b4-4&from=paste&id=u46580926&originalType=url&ratio=1&rotation=0&showTitle=false&status=done&style=shadow&taskId=ubee15a57-803d-45e6-a586-0afd70524cf&title=)<br />现在，在每次迭代中拆分簇中相隔最远的两点，并重复这个过程，直到每个簇只包含一个点：<br />![](https://cdn.nlark.com/yuque/0/2021/webp/396745/1637715025053-4baf11bc-0071-4292-9580-59f10c438ad1.webp#clientId=u8d8faa84-43b4-4&from=paste&id=uf57cf3e2&originalType=url&ratio=1&rotation=0&showTitle=false&status=done&style=shadow&taskId=ub06a044b-e09a-446f-8d70-9bfe9ddcc33&title=)<br />上面的过程就是**分裂层次聚类**。
<a name="vs8fw"></a>
## 执行层次聚类的步骤
上面已经说了层次聚类的大概过程，那关键的来了，如何确定点和点的相似性呢？<br />这是聚类中最重要的问题之一了，一般计算相似度的方法是：**计算这些簇的质心之间的距离**。距离最小的点称为相似点，可以合并它们，也可以将其称为**基于距离的算法**。<br />另外在层次聚类中，还有一个称为**邻近矩阵**的概念，它存储了每个点之间的距离。下面通过一个例子来理解如何计算相似度、邻近矩阵、以及层次聚类的具体步骤。
<a name="Ag6l4"></a>
### 案例介绍
假设一位老师想要将学生分成不同的组。现在有每个学生在作业中的分数，想根据这些分数将他们分成几组。关于拥有多少组，这里没有固定的目标。由于老师不知道应该将哪种类型的学生分配到哪个组，因此不能作为监督学习问题来解决。下面，将尝试应用层次聚类将学生分成不同的组。<br />下面是个5名学生的成绩：<br />![](https://cdn.nlark.com/yuque/0/2021/webp/396745/1637715025442-285825e9-0838-4f1f-81eb-ab2e257c8ae4.webp#clientId=u8d8faa84-43b4-4&from=paste&id=u8df93197&originalType=url&ratio=1&rotation=0&showTitle=false&status=done&style=shadow&taskId=u05d5e65e-3e18-4f86-8586-5e1001e5aeb&title=)
<a name="bGygk"></a>
### 创建邻近矩阵
首先，要创建一个邻近矩阵，它储存了每个点两两之间的距离，因此可以得到一个形状为 n X n 的方阵。<br />这个案例中，可以得到以下 5 x 5 的邻近矩阵：<br />![](https://cdn.nlark.com/yuque/0/2021/webp/396745/1637715025482-208536a9-895f-49cc-8ada-1f7fd303cbd8.webp#clientId=u8d8faa84-43b4-4&from=paste&id=u13001035&originHeight=254&originWidth=259&originalType=url&ratio=1&rotation=0&showTitle=false&status=done&style=none&taskId=u7d2fb066-71ad-4253-aff6-ce5a4d7c871&title=)<br />矩阵里有两点需要注意下：

- 矩阵的对角元素始终为 0，因为点与其自身的距离始终为 0
- 使用欧几里得距离公式来计算非对角元素的距离

比如，要计算点 1 和 2 之间的距离，计算公式为：![](https://cdn.nlark.com/yuque/__latex/b9edd1d01892ae64abea0a1f87cd9ffb.svg#card=math&code=%5Csqrt%7B%2810-7%29%5E2%7D%3D%5Csqrt%7B9%7D%3D3&id=raWjE)<br />同理，按此计算方法完成后填充邻近矩阵其余元素。
<a name="Xw8mb"></a>
### 执行层次聚类
这里使用凝聚层次聚类来实现。<br />步骤 1：首先，将所有点分配成单个簇：<br />![](https://cdn.nlark.com/yuque/0/2021/webp/396745/1637715025629-f9de39c1-44c1-4d58-ada5-b6f0da83cbd3.webp#clientId=u8d8faa84-43b4-4&from=paste&id=u5b79b765&originalType=url&ratio=1&rotation=0&showTitle=false&status=done&style=shadow&taskId=u0b46cc14-32d7-48cd-9e6b-51a5e732489&title=)<br />这里不同的颜色代表不同的簇，数据中的 5 个点，即有 5 个不同的簇。<br />步骤2：接下来，需要**查找邻近矩阵中的最小距离并合并距离最小的点**。然后更新邻近矩阵：![](https://cdn.nlark.com/yuque/0/2021/webp/396745/1637715025480-a70d3ee0-48e6-49ec-bec5-dd6e59de9eef.webp#clientId=u8d8faa84-43b4-4&from=paste&id=ub60c96de&originalType=url&ratio=1&rotation=0&showTitle=false&status=done&style=shadow&taskId=u589fdea5-de76-4cd7-a339-5bf37768e95&title=)<br />最小距离是 3，因此将合并点 1 和 2：<br />![](https://cdn.nlark.com/yuque/0/2021/webp/396745/1637715025826-cb44ca11-9fd4-4b1d-bc19-003d30f0622c.webp#clientId=u8d8faa84-43b4-4&from=paste&id=u7a137799&originalType=url&ratio=1&rotation=0&showTitle=false&status=done&style=shadow&taskId=ufcb9479c-9eff-419b-951f-b90b4654de2&title=)<br />让看看更新的集群并相应地更新邻近矩阵：<br />![](https://cdn.nlark.com/yuque/0/2021/webp/396745/1637715025960-34b17b72-6669-492a-954a-221e7591c60d.webp#clientId=u8d8faa84-43b4-4&from=paste&id=u8f0b5f84&originalType=url&ratio=1&rotation=0&showTitle=false&status=done&style=shadow&taskId=u97f2256c-c6b5-4d8e-8de6-9dfdcf63caa&title=)<br />更新之后，取了1、2 两个点中值 (7, 10) 最大的来替换这个簇的值。当然除了最大值之外，还可以取最小值或平均值。然后，将再次计算这些簇的邻近矩阵：<br />![](https://cdn.nlark.com/yuque/0/2021/webp/396745/1637715025871-306907d5-eae1-4dc4-bd11-72e75d03a54c.webp#clientId=u8d8faa84-43b4-4&from=paste&id=u19e9dc0c&originalType=url&ratio=1&rotation=0&showTitle=false&status=done&style=shadow&taskId=u9a60de66-b891-4c4b-bb83-32a8dc490e4&title=)<br />第 3 步：重复第 2 步，直到只剩下一个簇。<br />重复所有的步骤后，将得到如下所示的合并的聚类：<br />![](https://cdn.nlark.com/yuque/0/2021/webp/396745/1637715025963-95d7deee-e8fd-4380-94ec-6e0617e8007d.webp#clientId=u8d8faa84-43b4-4&from=paste&id=u73314754&originalType=url&ratio=1&rotation=0&showTitle=false&status=done&style=shadow&taskId=u879c351e-0b8b-4f5c-af5e-e2eae484e23&title=)<br />这就是凝聚层次聚类的工作原理。但问题是仍然不知道该分几组？是2、3、还是4组呢？<br />下面开始介绍如何选择聚类数。
<a name="ePlwr"></a>
## 如何选择聚类数？
为了获得层次聚类的簇数，使用了一个概念，叫作**树状图**。<br />通过树状图，可以更方便的选出聚类的簇数。<br />回到上面的例子。当合并两个簇时，树状图会相应地记录这些簇之间的距离并以图形形式表示。下面这个是树状图的原始状态，横坐标记录了每个点的标记，纵轴记录了点和点之间的距离：<br />![](https://cdn.nlark.com/yuque/0/2021/webp/396745/1637715026042-7ff00705-5482-48aa-9e11-d23b61f19667.webp#clientId=u8d8faa84-43b4-4&from=paste&id=ueb491471&originalType=url&ratio=1&rotation=0&showTitle=false&status=done&style=shadow&taskId=ucb6b5bd2-6c83-470f-a463-38efe5aa0f2&title=)<br />当合并两个簇时，将会在树状图中连接起来，连接的高度就是点之间的距离。下面是刚刚层次聚类的过程。<br />![](https://cdn.nlark.com/yuque/0/2021/webp/396745/1637715026263-08cd79f2-cf9e-414c-aad4-efc8fcc72da5.webp#clientId=u8d8faa84-43b4-4&from=paste&id=u3034e4c8&originalType=url&ratio=1&rotation=0&showTitle=false&status=done&style=shadow&taskId=uf1d1f0f2-7ce1-4832-8df9-7d443a5d784&title=)<br />然后开始对上面的过程进行树状图的绘制。从合并样本 1 和 2 开始，这两个样本之间的距离为 3。<br />![](https://cdn.nlark.com/yuque/0/2021/webp/396745/1637715026155-3994c77f-f477-4905-9941-724d14be0c09.webp#clientId=u8d8faa84-43b4-4&from=paste&id=ud9dd709f&originalType=url&ratio=1&rotation=0&showTitle=false&status=done&style=shadow&taskId=ua4c0c20b-0ff3-434e-b397-cc97ab291e5&title=)<br />可以看到已经合并了 1 和 2。垂直线代表 1 和 2 的距离。同理，按照层次聚类过程绘制合并簇类的所有步骤，最后得到了这样的树状图：<br />![](https://cdn.nlark.com/yuque/0/2021/webp/396745/1637715026372-0ee25713-63d6-4bd2-87b2-d7876ff07127.webp#clientId=u8d8faa84-43b4-4&from=paste&id=u4484000a&originalType=url&ratio=1&rotation=0&showTitle=false&status=done&style=shadow&taskId=uf796ed15-778d-459a-8343-562daab19db&title=)<br />通过树状图，可以清楚地形象化层次聚类的步骤。树状图中垂直线的距离越远代表簇之间的距离越大。<br />有了这个树状图，决定簇类数就方便多了。<br />现在可以设置一个**阈值距离**，绘制一条水平线。比如将阈值设置为 12，并绘制一条水平线，如下：<br />![](https://cdn.nlark.com/yuque/0/2021/webp/396745/1637715026410-c5dcfa2c-b127-4817-aa17-5b0522c4f5dd.webp#clientId=u8d8faa84-43b4-4&from=paste&id=u3c7182e1&originalType=url&ratio=1&rotation=0&showTitle=false&status=done&style=shadow&taskId=u25e26a97-844a-4477-a786-eb780fbafb7&title=)<br />从交点中可以看到，聚类的数量就是与阈值水平线与垂直线相交的数量（红线与 2 条垂直线相交，将有 2 个簇）。与横坐标相对应的，一个簇将有一个样本集合为 (1,2,4)，另一个集群将有一个样本集合 (3,5)。<br />这样，就通过树状图解决了分层聚类中要决定聚类的数量。
<a name="nmRss"></a>
## Python代码实战案例
上面是理论基础，有点数学基础都能看懂。下面介绍下在如何用代码Python来实现这一过程。这里拿一个**客户细分**的数据来展示一下。<br />数据集和代码在这里：[https://github.com/xiaoyusmd/PythonDataScience](https://github.com/xiaoyusmd/PythonDataScience)<br />这个数据来源于UCI 机器学习库。目的是根据批发分销商的客户在不同产品类别（如牛奶、杂货、地区等）上的年度支出，对他们进行细分。<br />首先对数据进行一个标准化，为了让所有数据在同一个维度便于计算，然后应用层次聚类来细分客户。
```python
from sklearn.preprocessing import normalize
data_scaled = normalize(data)
data_scaled = pd.DataFrame(data_scaled, columns=data.columns)

import scipy.cluster.hierarchy as shc
plt.figure(figsize=(10, 7))  
plt.title("Dendrograms")  
dend = shc.dendrogram(shc.linkage(data_scaled, method='ward'))
```
![](https://cdn.nlark.com/yuque/0/2021/webp/396745/1637715026555-8d225009-a206-4b3b-af81-cf064689e55b.webp#clientId=u8d8faa84-43b4-4&from=paste&id=u7b1d0f10&originalType=url&ratio=1&rotation=0&showTitle=false&status=done&style=shadow&taskId=ua50aa4ea-2fc4-491d-aecb-3f3969b7c80&title=)<br />x 轴包含了所有样本，y 轴代表这些样本之间的距离。距离最大的垂直线是蓝线，假如决定要以阈值 6 切割树状图：
```python
plt.figure(figsize=(10, 7))  
plt.title("Dendrograms")  
dend = shc.dendrogram(shc.linkage(data_scaled, method='ward'))
plt.axhline(y=6, color='r', linestyle='--')
```
![](https://cdn.nlark.com/yuque/0/2021/webp/396745/1637715026550-4c34bc5d-1bb9-4ea7-91eb-9e2840856286.webp#clientId=u8d8faa84-43b4-4&from=paste&id=uea76bd1e&originalType=url&ratio=1&rotation=0&showTitle=false&status=done&style=shadow&taskId=u9f45ad04-a59d-4dd4-9558-327e6842f7e&title=)<br />现在有两个簇了，要对这 2 个簇应用层次聚类：
```python
from sklearn.cluster import AgglomerativeClustering
cluster = AgglomerativeClustering(n_clusters=2, affinity='euclidean', linkage='ward')  
cluster.fit_predict(data_scaled)
```
![](https://cdn.nlark.com/yuque/0/2021/webp/396745/1637715026608-199d016d-7e0e-4ac7-9666-c0703f0afcf4.webp#clientId=u8d8faa84-43b4-4&from=paste&id=ucf68b0c7&originalType=url&ratio=1&rotation=0&showTitle=false&status=done&style=shadow&taskId=ua27ebc02-de6e-49a0-afda-e3c39d0f1f1&title=)<br />由于定义了 2 个簇，因此可以在输出中看到 0 和 1 的值。0 代表属于第一个簇的点，1 代表属于第二个簇的点。
```python
plt.figure(figsize=(10, 7))  
plt.scatter(data_scaled['Milk'], data_scaled['Grocery'], c=cluster.labels_) 
```
![](https://cdn.nlark.com/yuque/0/2021/webp/396745/1637715026734-dbc0093b-2a8d-41a9-a3d9-b341e8171f19.webp#clientId=u8d8faa84-43b4-4&from=paste&id=u5e22ce25&originalType=url&ratio=1&rotation=0&showTitle=false&status=done&style=shadow&taskId=u94bfec89-b6d7-4955-83b8-f373750b98b&title=)<br />到这里就成功的完成了聚类。
