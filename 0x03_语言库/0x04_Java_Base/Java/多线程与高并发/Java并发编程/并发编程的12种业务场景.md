Java并发<br />并发编程说白了就是多线程编程，但多线程一定比单线程效率更高？<br />答：不一定，要看具体业务场景。<br />毕竟如果使用了多线程，那么线程之间的竞争和抢占cpu资源，线程的上下文切换，也是相对来说比较耗时的操作。<br />下面这几个问题在面试中，必定遇到过：

1. 在哪些业务场景中使用过多线程？
2. 怎么用的？
3. 踩过哪些坑？

聊聊之前在项目中用并发编程的12种业务场景，给有需要的朋友一个参考。<br />![](https://cdn.nlark.com/yuque/0/2022/png/396745/1651796909905-00da5d11-aa38-4246-a95b-3d08251db087.png#clientId=u1e9c4639-7a51-4&from=paste&id=u3b9ff916&originHeight=1164&originWidth=1066&originalType=url&ratio=1&rotation=0&showTitle=false&status=done&style=shadow&taskId=ueeca5098-cb0c-4e01-a42b-1dfcf017e34&title=)
<a name="i4ryP"></a>
## 1、简单定时任务
各位亲爱的朋友，Thread类真的能做定时任务。如果看过一些定时任务框架的源码，最后会发现，它们的底层也会使用Thread类。<br />实现这种定时任务的具体代码如下：
```java
public static void init() {
    new Thread(() -> {
        while (true) {
            try {
                System.out.println("下载文件");
                Thread.sleep(1000 * 60 * 5);
            } catch (Exception e) {
                log.error(e);
            }
        }
    }).start();
}
```
使用Thread类可以做最简单的定时任务，在run方法中有个while的死循环（当然还有其他方式），执行自己的任务。有个需要特别注意的地方是，需要用try...catch捕获异常，否则如果出现异常，就直接退出循环，下次将无法继续执行了。<br />但这种方式做的定时任务，只能周期性执行，不能支持定时在某个时间点执行。<br />特别提醒一下，该线程建议定义成守护线程，可以通过setDaemon方法设置，让它在后台默默执行就好。<br />使用场景：比如项目中有时需要每隔5分钟去下载某个文件，或者每隔10分钟去读取模板文件生成静态html页面等等，一些简单的周期性任务场景。<br />使用Thread类做定时任务的优缺点：

- 优点：这种定时任务非常简单，学习成本低，容易入手，对于那些简单的周期性任务，是个不错的选择。
- 缺点：不支持指定某个时间点执行任务，不支持延迟执行等操作，功能过于单一，无法应对一些较为复杂的场景。
<a name="uetTv"></a>
## 2、监听器
有时候，需要写个监听器，去监听某些数据的变化。<br />比如：在使用canal的时候，需要监听binlog的变化，能够及时把数据库中的数据，同步到另外一个业务数据库中。<br />![](https://cdn.nlark.com/yuque/0/2022/png/396745/1651796910014-30d26e2b-42df-492c-8620-56584d78bb18.png#clientId=u1e9c4639-7a51-4&from=paste&id=u7c247e51&originHeight=569&originWidth=1080&originalType=url&ratio=1&rotation=0&showTitle=false&status=done&style=shadow&taskId=udaca5c06-47d6-4ba9-b9e6-14d6dafcb73&title=)如果直接写一个监听器去监听数据就太没意思了，想实现这样一个功能：在配置中心有个开关，配置监听器是否开启，如果开启了使用单线程异步执行。<br />主要代码如下：
```java
@Service
public CanalService {
    private volatile boolean running = false;
    private Thread thread;

    @Autowired
    private CanalConnector canalConnector;
    
    public void handle() {
        //连接canal
        while(running) {
           //业务处理
        }
    }
    
    public void start() {
       thread = new Thread(this::handle, "name");
       running = true;
       thread.start();
    }
    
    public void stop() {
       if(!running) {
          return;
       }
       running = false;
    }
}
```
在`start`方法中开启了一个线程，在该线程中异步执行handle方法的具体任务。然后通过调用stop方法，可以停止该线程。<br />其中，使用`volatile`关键字控制的running变量作为开关，它可以控制线程中的状态。<br />接下来，有个比较关键的点是：如何通过配置中心的配置，控制这个开关呢？<br />以apollo配置为例，在配置中心的后台，修改配置之后，自动获取最新配置的核心代码如下：
```java
public class CanalConfig {
    @Autowired
    private CanalService canalService;

    @ApolloConfigChangeListener
    public void change(ConfigChangeEvent event) {
        String value = event.getChange("test.canal.enable").getNewValue();
        if(BooleanUtils.toBoolean(value)) {
            canalService.start();
        } else {
            canalService.stop();
        }
    }
}
```
通过apollo的`ApolloConfigChangeListener`注解，可以监听配置参数的变化。<br />如果`test.canal.enable`开关配置的true，则调用`canalService`类的`start`方法开启canal数据同步功能。如果开关配置的false，则调用`canalService`类的`stop`方法，自动停止canal数据同步功能。
<a name="qT18e"></a>
## 3、收集日志
在某些高并发的场景中，需要收集部分用户的日志（比如：用户登录的日志），写到数据库中，以便于做分析。<br />但由于项目中，还没有引入消息中间件，比如：kafka、rocketmq等。<br />如果直接将日志同步写入数据库，可能会影响接口性能。<br />所以，大家很自然想到了异步处理。<br />实现这个需求最简单的做法是，开启一个线程，异步写入数据到数据库即可。<br />这样做，可以是可以。<br />但如果用户登录操作的耗时，比异步写入数据库的时间要少得多。这样导致的结果是：生产日志的速度，比消费日志的速度要快得多，最终的性能瓶颈在消费端。<br />其实，还有更优雅的处理方式，虽说没有使用消息中间件，但借用了它的思想。<br />这套记录登录日志的功能，分为：日志生产端、日志存储端和日志消费端。<br />如下图所示：![](https://cdn.nlark.com/yuque/0/2022/png/396745/1651796910055-819e61c9-0b7a-4b02-9917-5c156265fe1c.png#clientId=u1e9c4639-7a51-4&from=paste&id=u778b283b&originHeight=300&originWidth=794&originalType=url&ratio=1&rotation=0&showTitle=false&status=done&style=shadow&taskId=u6844f941-4e68-49e3-b7fc-65bc0f79a48&title=)<br />先定义了一个阻塞队列。
```java
@Component
public class LoginLogQueue {
    private static final int QUEUE_MAX_SIZE    = 1000;

    private BlockingQueueblockingQueue queue = new LinkedBlockingQueue<>(QUEUE_MAX_SIZE);

    //生成消息
    public boolean push(LoginLog loginLog) {
        return this.queue.add(loginLog);
    } 

    //消费消息
    public LoginLog poll() {
        LoginLog loginLog = null;
        try {
            loginLog = this.queue.take();
        } catch (InterruptedException e) {
            e.printStackTrace();
        }
        return result;
    }
}
```
然后定义了一个日志的生产者。
```java
@Service
public class LoginSerivce {
    
    @Autowired
    private LoginLogQueue loginLogQueue;

    public int login(UserInfo userInfo) {
        //业务处理
        LoginLog loginLog = convert(userInfo);
        loginLogQueue.push(loginLog);
    }  
}
```
接下来，定义了日志的消费者。
```java
@Service
public class LoginInfoConsumer {
    @Autowired
    private LoginLogQueue queue;

    @PostConstruct
    public voit init {
       new Thread(() -> {
          while (true) {
              LoginLog loginLog = queue.take();
              //写入数据库
          }
        }).start();
    }
}
```
当然，这个例子中使用单线程接收登录日志，为了提升性能，也可以使用线程池来处理业务逻辑（比如：写入数据库）等。
<a name="NF5OO"></a>
## 4、Excel导入
可能会经常收到运营同学提过来的Excel数据导入需求，比如：将某一大类下的所有子类一次性导入系统，或者导入一批新的供应商数据等等。<br />以导入供应商数据为例，它所涉及的业务流程很长，比如：

1. 调用天眼查接口校验企业名称和统一社会信用代码。
2. 写入供应商基本表
3. 写入组织表
4. 给供应商自动创建一个用户
5. 给该用户分配权限
6. 自定义域名
7. 发站内通知

等等。<br />如果在程序中，解析完excel，读取了所有数据之后。用单线程一条条处理业务逻辑，可能耗时会非常长。<br />为了提升excel数据导入效率，非常有必要使用多线程来处理。<br />当然在java中实现多线程的手段有很多种，下面重点聊聊java8中最简单的实现方式：`parallelStream`。<br />伪代码如下：
```java
supplierList.parallelStream().forEach(x -> importSupplier(x));
```
`parallelStream`是一个并行执行的流，它默认通过ForkJoinPool实现的，能提高多线程任务的速度。<br />ForkJoinPool处理的过程会分而治之，它的核心思想是：将一个大任务切分成多个小任务。每个小任务都能单独执行，最后它会把所用任务的执行结果进行汇总。<br />下面用一张图简单介绍一下ForkJoinPool的原理：![](https://cdn.nlark.com/yuque/0/2022/png/396745/1651796909989-7ea72628-f3df-41e4-a245-301abc9d0e00.png#clientId=u1e9c4639-7a51-4&from=paste&id=u1c814a48&originHeight=366&originWidth=1080&originalType=url&ratio=1&rotation=0&showTitle=false&status=done&style=shadow&taskId=u012bd3ab-36bb-4a4c-9b92-9a119a0c099&title=)<br />当然除了excel导入之外，还有类似的读取文本文件，也可以用类似的方法处理。<br />温馨的提醒一下，如果一次性导入的数据非常多，用多线程处理，可能会使系统的cpu使用率飙升，需要特别关注。
<a name="Zovwv"></a>
## 5、查询接口
很多时候，需要在某个查询接口中，调用其他服务的接口，组合数据之后，一起返回。<br />比如有这样的业务场景：<br />在用户信息查询接口中需要返回：用户名称、性别、等级、头像、积分、成长值等信息。<br />而用户名称、性别、等级、头像在用户服务中，积分在积分服务中，成长值在成长值服务中。为了汇总这些数据统一返回，需要另外提供一个对外接口服务。<br />于是，用户信息查询接口需要调用用户查询接口、积分查询接口 和 成长值查询接口，然后汇总数据统一返回。<br />调用过程如下图所示：<br />![](https://cdn.nlark.com/yuque/0/2022/png/396745/1651796910007-a1513868-7443-4b30-8368-546e97e341ce.png#clientId=u1e9c4639-7a51-4&from=paste&id=u18c02bbe&originHeight=712&originWidth=326&originalType=url&ratio=1&rotation=0&showTitle=false&status=done&style=shadow&taskId=u30895b52-402a-496f-92d1-080751b612c&title=)<br />调用远程接口总耗时 530ms = 200ms + 150ms + 180ms<br />显然这种串行调用远程接口性能是非常不好的，调用远程接口总的耗时为所有的远程接口耗时之和。<br />那么如何优化远程接口性能呢？<br />既然串行调用多个远程接口性能很差，为什么不改成并行呢？<br />如下图所示：![](https://cdn.nlark.com/yuque/0/2022/png/396745/1651796910245-046f92f8-ea4e-433f-9bea-28bead8ef266.png#clientId=u1e9c4639-7a51-4&from=paste&id=ua8969352&originHeight=408&originWidth=814&originalType=url&ratio=1&rotation=0&showTitle=false&status=done&style=shadow&taskId=u994f661e-d837-47fa-a5d9-e45d02e253b&title=)<br />调用远程接口总耗时 200ms = 200ms（即耗时最长的那次远程接口调用）<br />在java8之前可以通过实现Callable接口，获取线程返回结果。<br />java8以后通过`CompleteFuture`类实现该功能。这里以CompleteFuture为例：
```java
public UserInfo getUserInfo(Long id) throws InterruptedException, ExecutionException {
    final UserInfo userInfo = new UserInfo();
    CompletableFuture userFuture = CompletableFuture.supplyAsync(() -> {
        getRemoteUserAndFill(id, userInfo);
        return Boolean.TRUE;
    }, executor);

    CompletableFuture bonusFuture = CompletableFuture.supplyAsync(() -> {
        getRemoteBonusAndFill(id, userInfo);
        return Boolean.TRUE;
    }, executor);

    CompletableFuture growthFuture = CompletableFuture.supplyAsync(() -> {
        getRemoteGrowthAndFill(id, userInfo);
        return Boolean.TRUE;
    }, executor);
    CompletableFuture.allOf(userFuture, bonusFuture, growthFuture).join();

    userFuture.get();
    bonusFuture.get();
    growthFuture.get();
    return userInfo;
}
```
温馨提醒一下，这两种方式别忘了使用线程池。示例中用到了executor，表示自定义的线程池，为了防止高并发场景下，出现线程过多的问题。
<a name="URDGT"></a>
## 6、获取用户上下文
在项目开发时，有没有遇到过这样的需求：用户登录之后，在所有的请求接口中，通过某个公共方法，就能获取到当前登录用户的信息？<br />获取的用户上下文，以CurrentUser为例。<br />CurrentUser内部包含了一个ThreadLocal对象，它负责保存当前线程的用户上下文信息。当然为了保证在线程池中，也能从用户上下文中获取到正确的用户信息，这里用了阿里的`TransmittableThreadLocal`。伪代码如下：
```java
@Data
public class CurrentUser {
    private static final TransmittableThreadLocal<CurrentUser> THREA_LOCAL = new TransmittableThreadLocal<>();
    
    private String id;
    private String userName;
    private String password;
    private String phone;
    ...
    
    public statis void set(CurrentUser user) {
      THREA_LOCAL.set(user);
    }
    
    public static void getCurrent() {
      return THREA_LOCAL.get();
    }
}
```
这里为什么用了阿里的`TransmittableThreadLocal`，而不是普通的ThreadLocal呢？在线程池中，由于线程会被多次复用，导致从普通的ThreadLocal中无法获取正确的用户信息。父线程中的参数，没法传递给子线程，而`TransmittableThreadLocal`很好解决了这个问题。<br />然后在项目中定义一个全局的spring mvc拦截器，专门设置用户上下文到ThreadLocal中。伪代码如下：
```java
public class UserInterceptor extends HandlerInterceptorAdapter {
   
   @Override  
   public boolean preHandle(HttpServletRequest request, HttpServletResponse response, Object handler) throws Exception {
      CurrentUser user = getUser(request);
      if(Objects.nonNull(user)) {
         CurrentUser.set(user);
      }
   } 
}
```
用户在请求接口时，会先触发该拦截器，它会根据用户cookie中的token，调用调用接口获取redis中的用户信息。如果能获取到，说明用户已经登录，则把用户信息设置到CurrentUser类的ThreadLocal中。<br />接下来，在api服务的下层，即business层的方法中，就能轻松通过`CurrentUser.getCurrent();`方法获取到想要的用户上下文信息了。![](https://cdn.nlark.com/yuque/0/2022/png/396745/1651796910350-85f73918-8a80-426e-ae5b-6dfe004227ab.png#clientId=u1e9c4639-7a51-4&from=paste&id=uf09e85f8&originHeight=803&originWidth=1080&originalType=url&ratio=1&rotation=0&showTitle=false&status=done&style=shadow&taskId=u2ed1890f-e0e0-4a28-965e-1bb6bc453bd&title=)<br />这套用户体系的想法是很good的，但深入使用后，发现了一个小插曲：<br />api服务和mq消费者服务都引用了business层，business层中的方法两个服务都能直接调用。<br />都知道在api服务中用户是需要登录的，而mq消费者服务则不需要登录。![](https://cdn.nlark.com/yuque/0/2022/png/396745/1651796910484-229601f2-b589-4c96-ad9f-e2000f8eedaf.png#clientId=u1e9c4639-7a51-4&from=paste&id=uff7cb562&originHeight=592&originWidth=720&originalType=url&ratio=1&rotation=0&showTitle=false&status=done&style=shadow&taskId=uaf4df92c-b5dc-4990-ab98-4c22c6a775d&title=)<br />如果business中的某个方法刚开始是给api开发的，在方法深处使用了CurrentUser.getCurrent();获取用户上下文。但后来，某位新来的帅哥在mq消费者中也调用了那个方法，并未发觉这个小机关，就会中招，出现找不到用户上下文的问题。![](https://cdn.nlark.com/yuque/0/2022/png/396745/1651796910511-fd90ab86-f3a0-4427-abd9-3a20ba5863b0.png#clientId=u1e9c4639-7a51-4&from=paste&id=uaeedc854&originHeight=714&originWidth=680&originalType=url&ratio=1&rotation=0&showTitle=false&status=done&style=shadow&taskId=u436bd762-8adc-49d2-b251-a09821c762b&title=)<br />所以当时的第一个想法是：代码没做兼容处理，因为之前这类问题偶尔会发生一次。<br />想要解决这个问题，其实也很简单。只需先判断一下能否从CurrentUser中获取用户信息，如果不能，则取配置的系统用户信息。伪代码如下：
```java
@Autowired
private BusinessConfig businessConfig;

CurrentUser user = CurrentUser.getCurrent();
if(Objects.nonNull(user)) {
	entity.setUserId(user.getUserId());
	entity.setUserName(user.getUserName());
} else {
	entity.setUserId(businessConfig.getDefaultUserId());
	entity.setUserName(businessConfig.getDefaultUserName());
}
```
这种简单无公害的代码，如果只是在一两个地方加还OK。<br />此外，众所周知，`SimpleDateFormat`在java8以前，是用来处理时间的工具类，它是非线程安全的。也就是说，用该方法解析日期会有线程安全问题。<br />为了避免线程安全问题的出现，可以把SimpleDateFormat对象定义成局部变量。但如果一定要把它定义成静态变量，可以使用ThreadLocal保存日期，也能解决线程安全问题。
<a name="uoK0U"></a>
## 8、传递参数
之前见过有些同事写代码时，一个非常有趣的用法，即：使用MDC传递参数。<br />MDC是什么？<br />MDC是org.slf4j包下的一个类，它的全称是Mapped Diagnostic Context，可以认为它是一个线程安全的存放诊断日志的容器。<br />MDC的底层是用了ThreadLocal来保存数据的。<br />例如现在有这样一种场景：使用`RestTemplate`调用远程接口时，有时需要在header中传递信息，比如：traceId，source等，便于在查询日志时能够串联一次完整的请求链路，快速定位问题。<br />这种业务场景就能通过`ClientHttpRequestInterceptor`接口实现，具体做法如下：<br />第一步，定义一个LogFilter拦截所有接口请求，在MDC中设置traceId：
```java
public class LogFilter implements Filter {
    @Override
    public void init(FilterConfig filterConfig) throws ServletException {
    }

    @Override
    public void doFilter(ServletRequest request, ServletResponse response, FilterChain chain) throws IOException, ServletException {
        MdcUtil.add(UUID.randomUUID().toString());
        System.out.println("记录请求日志");
        chain.doFilter(request, response);
        System.out.println("记录响应日志");
    }

    @Override
    public void destroy() {
    }
}
```
第二步，实现`ClientHttpRequestInterceptor`接口，MDC中获取当前请求的traceId，然后设置到header中：
```java
public class RestTemplateInterceptor implements ClientHttpRequestInterceptor {

    @Override
    public ClientHttpResponse intercept(HttpRequest request, byte[] body, ClientHttpRequestExecution execution) throws IOException {
        request.getHeaders().set("traceId", MdcUtil.get());
        return execution.execute(request, body);
    }
}
```
第三步，定义配置类，配置上面定义的`RestTemplateInterceptor`类：
```java
@Configuration
public class RestTemplateConfiguration {

    @Bean
    public RestTemplate restTemplate() {
        RestTemplate restTemplate = new RestTemplate();
        restTemplate.setInterceptors(Collections.singletonList(restTemplateInterceptor()));
        return restTemplate;
    }

    @Bean
    public RestTemplateInterceptor restTemplateInterceptor() {
        return new RestTemplateInterceptor();
    }
}
```
其中MdcUtil其实是利用MDC工具在ThreadLocal中存储和获取traceId
```java
public class MdcUtil {

    private static final String TRACE_ID = "TRACE_ID";

    public static String get() {
        return MDC.get(TRACE_ID);
    }

    public static void add(String value) {
        MDC.put(TRACE_ID, value);
    }
}
```
当然，这个例子中没有演示MdcUtil类的add方法具体调的地方，可以在filter中执行接口方法之前，生成traceId，调用MdcUtil类的add方法添加到MDC中，然后在同一个请求的其他地方就能通过MdcUtil类的get方法获取到该traceId。<br />能使用MDC保存traceId等参数的根本原因是，用户请求到应用服务器，Tomcat会从线程池中分配一个线程去处理该请求。<br />那么该请求的整个过程中，保存到MDC的ThreadLocal中的参数，也是该线程独享的，所以不会有线程安全问题。
<a name="Rsin5"></a>
## 9、模拟高并发
有时候写的接口，在低并发的场景下，一点问题都没有。<br />但如果一旦出现高并发调用，该接口可能会出现一些意想不到的问题。<br />为了防止类似的事情发生，一般在项目上线前，非常有必要对接口做一下压力测试。<br />当然，现在已经有比较成熟的压力测试工具，比如：Jmeter、`LoadRunner`等。<br />如果觉得下载压测工具比较麻烦，也可以手写一个简单的模拟并发操作的工具，用`CountDownLatch`就能实现，例如：
```java
public static void concurrenceTest() {
    /**
     * 模拟高并发情况代码
     */
    final AtomicInteger atomicInteger = new AtomicInteger(0);
    final CountDownLatch countDownLatch = new CountDownLatch(1000); // 相当于计数器，当所有都准备好了，再一起执行，模仿多并发，保证并发量
    final CountDownLatch countDownLatch2 = new CountDownLatch(1000); // 保证所有线程执行完了再打印atomicInteger的值
    ExecutorService executorService = Executors.newFixedThreadPool(10);
    try {
        for (int i = 0; i < 1000; i++) {
            executorService.submit(new Runnable() {
                @Override
                public void run() {
                    try {
                        countDownLatch.await(); //一直阻塞当前线程，直到计时器的值为0,保证同时并发
                    } catch (InterruptedException e) {
                        log.error(e.getMessage(),e);
                    }
                    //每个线程增加1000次，每次加1
                    for (int j = 0; j < 1000; j++) {
                        atomicInteger.incrementAndGet();
                    }
                    countDownLatch2.countDown();
                }
            });
            countDownLatch.countDown();
        }

        countDownLatch2.await();// 保证所有线程执行完
        executorService.shutdown();
    } catch (Exception e){
        log.error(e.getMessage(),e);
    }
}
```
<a name="LhPQ1"></a>
## 10、处理mq消息
在高并发的场景中，消息积压问题，可以说如影随形，真的没办法从根本上解决。表面上看，已经解决了，但后面不知道什么时候，就会冒出一次，比如这次：<br />有天下午，产品过来说：有几个商户投诉过来了，他们说菜品有延迟，快查一下原因。<br />这次问题出现得有点奇怪。<br />为什么这么说？<br />首先这个时间点就有点奇怪，平常出问题，不都是中午或者晚上用餐高峰期吗？怎么这次问题出现在下午？<br />根据以往积累的经验，直接看了kafka的topic的数据，果然上面消息有积压，但这次每个partition都积压了十几万的消息没有消费，比以往加压的消息数量增加了几百倍。这次消息积压得极不寻常。<br />赶紧查服务监控看看消费者挂了没，还好没挂。又查服务日志没有发现异常。这时有点迷茫，碰运气问了问订单组下午发生了什么事情没？他们说下午有个促销活动，跑了一个JOB批量更新过有些商户的订单信息。<br />这时，一下子如梦初醒，是他们在JOB中批量发消息导致的问题。实在太坑了。<br />虽说知道问题的原因了，倒是眼前积压的这十几万的消息该如何处理呢？<br />此时，如果直接调大partition数量是不行的，历史消息已经存储到4个固定的partition，只有新增的消息才会到新的partition。重点需要处理的是已有的partition。<br />直接加服务节点也不行，因为kafka允许同组的多个partition被一个consumer消费，但不允许一个partition被同组的多个consumer消费，可能会造成资源浪费。<br />看来只有用多线程处理了。<br />为了紧急解决问题，改成了用线程池处理消息，核心线程和最大线程数都配置成了50。<br />大致用法如下：

1. 先定义一个线程池：
```java
@Configuration
public class ThreadPoolConfig {
	
	@Value("${thread.pool.corePoolSize:5}")
	private int corePoolSize;
	
	@Value("${thread.pool.maxPoolSize:10}")
	private int maxPoolSize;
	
	@Value("${thread.pool.queueCapacity:200}")
	private int queueCapacity;
	
	@Value("${thread.pool.keepAliveSeconds:30}")
	private int keepAliveSeconds;
	
	@Value("${thread.pool.threadNamePrefix:ASYNC_}")
	private String threadNamePrefix;
	
	@Bean("messageExecutor")
	public Executor messageExecutor() {
		ThreadPoolTaskExecutor executor = new ThreadPoolTaskExecutor();
		executor.setCorePoolSize(corePoolSize);
		executor.setMaxPoolSize(maxPoolSize);
		executor.setQueueCapacity(queueCapacity);
		executor.setKeepAliveSeconds(keepAliveSeconds);
		executor.setThreadNamePrefix(threadNamePrefix);
		executor.setRejectedExecutionHandler(new ThreadPoolExecutor.CallerRunsPolicy());
		executor.initialize();
		return executor;
	}
}
```

1. 再定义一个消息的consumer：
```java
@Service
public class MyConsumerService {
    @Autowired
    private Executor messageExecutor;
    
    @KafkaListener(id="test",topics={"topic-test"})
    public void listen(String message){
        System.out.println("收到消息：" + message);
        messageExecutor.submit(new MyWork(message);
    }
}
```

1. 在定义的Runable实现类中处理业务逻辑：
```java
public class MyWork implements Runnable {
    private String message;
    
    public MyWork(String message) {
       this.message = message;
    }

    @Override
    public void run() {
        System.out.println(message);
    }
}
```
果然，调整之后消息积压数量确实下降的非常快，大约半小时后，积压的消息就非常顺利的处理完了。<br />但此时有个更严重的问题出现：收到了报警邮件，有两个订单系统的节点down机了。。。
<a name="fhUOM"></a>
## 11、统计数量
在多线程的场景中，有时候需要统计数量，比如：用多线程导入供应商数据时，统计导入成功的供应商数有多少。<br />如果这时候用count++统计次数，最终的结果可能会不准。因为count++并非原子操作，如果多个线程同时执行该操作，则统计的次数，可能会出现异常。<br />为了解决这个问题，就需要使用concurent的atomic包下面的类，比如：`AtomicInteger`、`AtomicLong`等。
```java
@Servcie
public class ImportSupplierService {
  private static AtomicInteger count = new AtomicInteger(0);

  public int importSupplier(List<SupplierInfo> supplierList) {
       if(CollectionUtils.isEmpty(supplierList)) {
           return 0;
       }

       supplierList.parallelStream().forEach(x -> {
           try {
             importSupplier(x);
             count.addAndGet(1);
           } catch(Exception e) {
              log.error(e.getMessage(),e);
           }
       );

      return count.get();
  }    
}
```
`AtomicInteger`的底层说白了使用自旋锁+CAS。
```java
public final int incrementAndGet() {
    for (;;) {
        int current = get();
        int next = current + 1;
        if (compareAndSet(current, next))
            return next;
    }
}
```
自旋锁说白了就是一个死循环。<br />而CAS是比较和交换的意思。<br />它的实现逻辑是：将内存位置处的旧值与预期值进行比较，若相等，则将内存位置处的值替换为新值。若不相等，则不做任何操作。
<a name="eBMsI"></a>
## 12、延迟定时任务
经常有延迟处理数据的需求，比如：如果用户下单后，超过30分钟还未完成支付，则系统自动将该订单取消。<br />这里需求就可以使用延迟定时任务实现。<br />`ScheduledExecutorService`是JDK1.5+版本引进的定时任务，该类位于java.util.concurrent并发包下。<br />`ScheduledExecutorService`是基于多线程的，设计的初衷是为了解决`Timer`单线程执行，多个任务之间会互相影响的问题。<br />它主要包含4个方法：

- `schedule(Runnable command,long delay,TimeUnit unit)`，带延迟时间的调度，只执行一次，调度之后可通过`Future.get()`阻塞直至任务执行完毕。
- `schedule(Callablecallable,long delay,TimeUnit unit)`，带延迟时间的调度，只执行一次，调度之后可通过`Future.get()`阻塞直至任务执行完毕，并且可以获取执行结果。
- `scheduleAtFixedRate`，表示以固定频率执行的任务，如果当前任务耗时较多，超过定时周期period，则当前任务结束后会立即执行。
- `scheduleWithFixedDelay`，表示以固定延时执行任务，延时是相对当前任务结束为起点计算开始时间。

实现这种定时任务的具体代码如下：
```java
public class ScheduleExecutorTest {

    public static void main(String[] args) {
        ScheduledExecutorService scheduledExecutorService = Executors.newScheduledThreadPool(5);
        scheduledExecutorService.scheduleAtFixedRate(() -> {
            System.out.println("doSomething");
        },1000,1000, TimeUnit.MILLISECONDS);
    }
}
```
调用`ScheduledExecutorService`类的`scheduleAtFixedRate`方法实现周期性任务，每隔1秒钟执行一次，每次延迟1秒再执行。<br />这种定时任务是阿里巴巴开发者规范中用来替代`Timer`类的方案，对于多线程执行周期性任务，是个不错的选择。<br />使用`ScheduledExecutorService`类做延迟定时任务的优缺点：

- 优点：基于多线程的定时任务，多个任务之间不会相关影响，支持周期性的执行任务，并且带延迟功能。
- 缺点：不支持一些较复杂的定时规则。

当然，也可以使用分布式定时任务，比如：xxl-job或者elastic-job等等。<br />其实，在实际工作中使用多线程的场景远远不只这12种，在这里只是抛砖引玉，介绍了一些比较常见的业务场景。 
