Python Pandas
<a name="adGFO"></a>
## 从剪贴板中创建DataFrame
假设将一些数据储存在Excel或者Google Sheet中，又想要尽快地将他们读取至DataFrame中。<br />需要选择这些数据并复制至剪贴板。然后，可以使用`**read_clipboard()**`**函数**将他们读取至DataFrame中：<br />![2021-08-09-07-01-33-624741.png](./img/1628468452335-825ff950-bfcc-4592-97b4-0a4849347241.png)<br />和`read_csv()`类似，`read_clipboard()`会自动检测每一列的正确的数据类型：<br />![2021-08-09-07-01-33-688746.png](./img/1628468452355-7cffe41a-b39d-4509-8a69-19e086cd0385.png)<br />再复制另外一个数据至剪贴板：<br />![2021-08-09-07-01-33-745738.png](./img/1628468452351-04562dc9-1a2c-4296-a46c-29165c254aed.png)<br />神奇的是，pandas已经将第一列作为索引了：<br />![2021-08-09-07-01-33-814736.png](./img/1628468452358-de523307-1c23-4354-855b-993ea2f91e6b.png)<br />需要注意的是，**如果想要内容在未来可复制，那么**`**read_clipboard()**`**并不值得推荐。**
<a name="b3VHw"></a>
## 将DataFrame划分为两个随机的子集
假设想要将一个DataFrame划分为两部分，随机地将75%的行给一个DataFrame，剩下的25%的行给另一个DataFrame。<br />举例来说，movie ratings这个DataFrame有979行：<br />![2021-08-09-07-01-33-884736.png](./img/1628468452363-659209f7-ab2b-4a1b-b218-ad25d5363a16.png)<br />可以使用`**sample()**`**函数**来随机选取75%的行，并将它们赋值给"movies_1"DataFrame：<br />![2021-08-09-07-01-33-943737.png](./img/1628468457325-ccd16273-ef9e-4cb3-861f-fce9f371f59d.png)<br />接着使用`drop()`函数来舍弃“moive_1”中出现过的行，将剩下的行赋值给"movies_2"DataFrame：<br />可以发现总的行数是正确的：<br />![2021-08-09-07-01-34-330739.png](./img/1628468588565-d670fb4b-7fcb-4918-acd7-62b340836356.png)<br />还可以检查每部电影的索引，或者"moives_1":<br />![2021-08-09-07-01-34-399736.png](./img/1628468588563-66ac5fc2-298f-4b72-8756-4038e35219dc.png)<br />或者"moives_2":<br />![2021-08-09-07-01-34-473738.png](./img/1628468588586-1c3d614c-6f0a-4b9a-9f66-0e62eba9542a.png)<br />需要注意的是，**这个方法在索引值不唯一的情况下不起作用。**<br />**注：**该方法在机器学习或者深度学习中很有用，因为在模型训练前，往往需要将全部数据集按某个比例划分成训练集和测试集。该方法既简单又高效，值得学习和尝试。
<a name="WV8Ld"></a>
## 多种类型过滤DataFrame
先看一眼movies这个DataFrame：
```python
In [60]:movies.head()
Out[60]:
```
![2021-08-09-07-01-34-537736.png](./img/1628468648021-b70f7229-aafe-4e5a-bbe3-4fc50f5f4073.png)<br />其中有一列是genre（类型）:<br />![2021-08-09-07-01-34-737738.png](./img/1628468648010-658424f3-627a-42f8-bdb1-a2aa75a82ad8.png)<br />比如想要对该DataFrame进行过滤，只想显示genre为Action或者Drama或者Western的电影，可以使用多个条件，以"or"符号分隔：
```python
In [62]:movies[(movies.genre == 'Action') |       (movies.genre == 'Drama') |       (movies.genre == 'Western')].head()
Out[62]:
```
![2021-08-09-07-01-34-796735.png](./img/1628468681798-e587be70-c74e-4da0-b1b2-2b603b48088a.png)<br />但是，实际上可以使用`isin()`函数将代码写得更加清晰，将genres列表传递给该函数：
```python
In [63]:movies[movies.genre.isin(['Action', 'Drama', 'Western'])].head()
Out[63]:
```
![2021-08-09-07-01-34-864737.png](./img/1628468681819-b3fd7596-41a1-4c6b-b04f-c74d8cc9e84e.png)<br />如果想要进行相反的过滤，也就是把刚才的三种类型的电影排除掉，那么可以在过滤条件前加上破浪号：
```python
In [64]:movies[~movies.genre.isin(['Action', 'Drama', 'Western'])].head()
Out[64]:
```
![2021-08-09-07-01-34-924738.png](./img/1628468709461-10ed8f60-f9c7-4e69-a619-9ec1f3e5afbb.png)<br />这种方法能够起作用是**因为在Python中，波浪号表示“not”操作。**
<a name="X4IqH"></a>
## DataFrame筛选数量最多类别
假设想要对movies这个DataFrame通过genre进行过滤，但是只需要前3个数量最多的genre。<br />对genre使用`**value_counts()**`**函数**，并将它保存成counts（type为Series）:<br />![2021-08-09-07-01-34-998736.png](./img/1628468709497-dc1c87a6-ba93-41fb-9d05-47be6fb4c59f.png)<br />该Series的`nlargest()`函数能够轻松地计算出Series中前3个最大值：<br />![2021-08-09-07-01-35-074735.png](./img/1628468742663-846c1d01-1239-4936-832d-de07cf78c42b.png)<br />事实上在该Series中需要的是索引：<br />![2021-08-09-07-01-35-135738.png](./img/1628468742685-0cef2729-29d6-4c9a-a176-a970adf52b38.png)<br />最后，将该索引传递给`isin()`函数，该函数会把它当成genre列表：
```python
In [68]:movies[movies.genre.isin(counts.nlargest(3).index)].head()
Out[68]:
```
![2021-08-09-07-01-35-202739.png](./img/1628468742686-2c588b4e-1b6e-475b-8601-1a5ee6292119.png)<br />这样，在DataFrame中只剩下Drame, Comdey, Action这三种类型的电影了。
<a name="uf8XA"></a>
## 处理缺失值
来看一看UFO sightings这个DataFrame:<br />![2021-08-09-07-01-35-295740.png](./img/1628468834652-344a177b-b537-4220-b932-b78cb296d29e.png)<br />会注意到有些值是**缺失的**。<br />为了找出每一列中有多少值是缺失的，可以使用`**isna()**`**函数**，然后再使用`**sum()**`:<br />![2021-08-09-07-01-35-375738.png](./img/1628468834666-ee44ba0a-b4c5-4ffb-ae94-c9c96f76ebfb.png)<br />`isna()`会产生一个由True和False组成的DataFrame，`sum()`会将所有的True值转换为1，False转换为0并把它们加起来。<br />类似地，可以通过`mean()`和`isna()`函数找出每一列中缺失值的百分比。<br />![2021-08-09-07-01-35-618737.png](./img/1628468834680-27bce78b-78e9-4ada-9830-e4d825803b17.png)<br />如果想要舍弃那些包含了缺失值的列，可以使用`dropna()`函数：<br />![2021-08-09-07-01-35-682738.png](./img/1628468913305-c91854e6-daaa-4dbc-88d0-4f32be2fa5b5.png)<br />或者想要舍弃那么缺失值占比超过10%的列，可以给`dropna()`设置一个阈值：<br />![2021-08-09-07-01-35-966736.png](./img/1628468913327-6f669c57-9ab7-4cb3-918b-02a5def8f4f4.png)<br />`len(ufo)`返回总行数，将它乘以0.9，以告诉pandas保留那些至少90%的值不是缺失值的列。
<a name="na2p5"></a>
## 一个字符串划分成多列
先创建另一个新的示例DataFrame:<br />![2021-08-09-07-01-36-035749.png](./img/1628468913330-30f3bcca-51c0-4bc0-952e-f74e007adfd7.png)<br />如果需要将“name”这一列划分为三个独立的列，用来表示first, middle, last name呢？将会使用`**str.split()**`**函数**，告诉它**以空格进行分隔**，并将结果扩展成一个DataFrame:<br />![2021-08-09-19-45-55-299826.png](./img/1628510721748-66f3198f-fdaf-428e-8a35-7fe479e83e0c.png)<br />这三列实际上可以通过一行代码保存至原来的DataFrame：<br />![2021-08-09-07-01-36-357741.png](./img/1628469185676-7a9469e2-bae5-4631-892d-40779acdfc0b.png)<br />如果想要划分一个字符串，但是仅保留其中一个结果列呢？比如说，以", "来划分location这一列：<br />![2021-08-09-07-01-36-424734.png](./img/1628469185681-c58e3006-9254-4c39-8e98-361c15d3cc5a.png)<br />如果只想保留第0列作为city name，仅需要选择那一列并保存至DataFrame:<br />![2021-08-09-07-01-36-721735.png](./img/1628469185683-ee4755ba-8ff4-4179-b21e-0bc043955433.png)
<a name="OI4nh"></a>
## Series扩展成DataFrame
创建一个新的示例DataFrame:<br />![2021-08-09-07-01-36-786739.png](./img/1628469260580-fb31c81c-e892-497d-9557-58ef88399cbe.png)<br />这里有两列，第二列包含了Python中的由整数元素组成的列表。<br />如果想要将第二列扩展成DataFrame，可以对那一列使用`**apply()**`**函数并传递给Series constructor**:<br />![2021-08-09-07-01-36-872738.png](./img/1628469260597-dba7eb97-3830-4820-820e-80ec931160f6.png)<br />通过使用`concat()`函数，可以将原来的DataFrame和新的DataFrame组合起来：<br />![2021-08-09-07-01-37-273737.png](./img/1628469260599-2a7a87f8-d357-4570-8ebd-852b267d3745.png)
<a name="LNvnC"></a>
## 对多个函数进行聚合
来看一眼从Chipotle restaurant chain得到的orders这个DataFrame:
```python
In [82]:orders.head(10)
Out[82]:
```
![2021-08-09-07-01-37-477739.png](./img/1628469260606-543d0a42-f711-4820-b676-e13285255705.png)<br />每个订单（order）都有订单号（order_id），包含一行或者多行。为了找出每个订单的总价格，可以将那个订单号的价格（item_price）加起来。比如，这里是订单号为1的总价格：<br />![2021-08-09-07-01-37-707738.png](./img/1628469327349-85c512db-bfae-4e3a-90aa-724763be7cbb.png)<br />如果想要计算每个订单的总价格，可以对order_id使用`groupby()`，再对每个`group`的`item_price`进行求和。<br />![2021-08-09-07-01-37-790737.png](./img/1628469327384-48d930b3-d8dc-4fbb-a033-59e1b4aa525d.png)<br />但是，事实上不可能在聚合时仅使用一个函数，比如`sum()`。**为了对多个函数进行聚合，可以使用**`**agg()**`**函数，**传给它一个函数列表，比如`sum()`和`count()`:<br />![2021-08-09-07-01-37-853737.png](./img/1628469327390-19ddb5e3-6960-4f64-af5e-8bfce4d96709.png)<br />没定订单的总价格和数量。
<a name="nbLUQ"></a>
## 聚合结果与DataFrame组合
再看一眼orders这个DataFrame:
```python
In [86]:orders.head(10)
Out[86]:
```
![2021-08-09-07-01-37-921737.png](./img/1628464478785-41feabd2-483b-4c33-b080-712dbef2302e.png)<br />如果想要增加新的一列，用于展示每个订单的总价格呢？回忆一下，通过使用`sum()`函数得到了总价格：<br />![2021-08-09-07-01-37-985736.png](./img/1628464478811-4831e067-0fe9-4f4e-9252-6ad3543aa56c.png)<br />`sum()`是一个聚合函数，这表明它返回输入数据的精简版本（reduced version ）。<br />换句话说，`sum()`函数的输出：<br />![2021-08-09-07-01-38-051736.png](./img/1628464478817-81c60647-f77c-4f1b-84ec-69f90c49318b.png)<br />比这个函数的输入要小：<br />![2021-08-09-07-01-38-102736.png](./img/1628464478809-f5713ed8-f540-43d3-9016-2ce1521bfee8.png)<br />解决的办法是**使用**`**transform()**`**函数，它会执行相同的操作但是返回与输入数据相同的形状**：<br />![2021-08-09-07-01-38-163739.png](./img/1628464478816-b2eac2a3-3c6a-40dc-bd78-9ea2bfba2d67.png)<br />将这个结果存储至DataFrame中新的一列：
```python
In [91]:orders['total_price'] = total_priceorders.head(10)
Out[91]:
```
![2021-08-09-07-01-38-385736.png](./img/1628464479449-05c0cfd9-c211-41dc-9e5c-8459085ac6cb.png)<br />可以看到，每个订单的总价格在每一行中显示出来了。<br />这样就能方便地甲酸每个订单的价格占该订单的总价格的百分比：
```python
In [92]:orders['percent_of_total'] = orders.item_price / orders.total_priceorders.head(10)
In [92]:
```
![2021-08-09-07-01-38-455735.png](./img/1628464479460-0d92e6f7-5499-4ed6-90d6-33dcc9c65f61.png)
<a name="jLd17"></a>
## 选取行和列的切片
看一眼另一个数据集：
```python
In [93]:titanic.head()
Out[93]:
```
![2021-08-09-07-01-38-517741.png](./img/1628464327756-38af34be-dab4-4dad-bae9-8f6203b6c6f9.png)<br />这就是著名的Titanic数据集，它保存了Titanic上乘客的信息以及他们是否存活。<br />如果想要对这个数据集做一个数值方面的总结，可以使用`describe()`函数：<br />![2021-08-09-07-01-38-801737.png](./img/1628464327762-82e41716-3c84-43fc-b689-600115d03274.png)<br />但是，这个DataFrame结果可能比想要的信息显示得更多。<br />如果想对这个结果进行过滤，只想显示“五数概括法”（five-number summary）的信息，可以使用`**loc**`**函数并传递"min"到"max"的切片**:<br />![2021-08-09-07-01-38-866736.png](./img/1628464327795-33ddc37b-2f4c-490f-88cd-1e75e5c97ad0.png)<br />如果不是对所有列都感兴趣，也可以传递列名的切片：<br />![2021-08-09-07-01-38-944735.png](./img/1628464327807-198cacab-3735-4c70-b233-9d00422178d3.png)
<a name="KLgzX"></a>
## MultiIndexed Series重塑
Titanic数据集的Survived列由1和0组成，因此可以对这一列计算总的存活率：<br />![2021-08-09-07-01-39-004737.png](./img/1628464224862-1f12d351-3d21-4fed-8fcf-f1fa3ab95854.png)<br />如果想对某个类别，比如“Sex”，计算存活率，可以使用`groupby()`:<br />![2021-08-09-07-01-39-102737.png](./img/1628464224897-048805fa-40f8-465b-9041-ace435ceddc2.png)<br />如果想一次性对两个类别变量计算存活率，可以对这些类别变量使用`groupby()`：<br />![2021-08-09-07-01-39-187736.png](./img/1628464224907-4fd32755-a3ab-4a72-b3d7-56c86aa1aea3.png)<br />该结果展示了由Sex和Passenger Class联合起来的存活率。它存储为一个MultiIndexed Series，也就是说它对实际数据有多个索引层级。<br />这使得该数据难以读取和交互，因此更为方便的是**通过**`**unstack()**`**函数将MultiIndexed Series重塑成一个DataFrame**:<br />![2021-08-09-07-01-39-602738.png](./img/1628464224910-15a44a63-2866-43b6-9d7a-3a72fc9b1c7a.png)<br />该DataFrame包含了与MultiIndexed Series一样的数据，不同的是，现在可以用熟悉的DataFrame的函数对它进行操作。
<a name="c3HlI"></a>
## 创建数据透视表
如果经常使用上述的方法创建DataFrames，也许会发现用`**pivot_table()**`**函数更为便捷**：<br />![2021-08-09-07-01-39-679737.png](./img/1628464030470-36b753f3-3cd6-4cac-b04f-a5036b12388b.png)<br />想要使用数据透视表，需要**指定索引**(index),** 列名**(columns), **值**(values)和**聚合函数**(aggregation function)。<br />数据透视表的另一个好处是，可以**通过设置margins=True轻松地将行和列都加起来**：<br />![2021-08-09-07-01-39-796739.png](./img/1628464030470-caee717d-3955-4ca8-a715-54bf760a0708.png)<br />这个结果既显示了总的存活率，也显示了Sex和Passenger Class的存活率。<br />最后，可以创建交叉表（cross-tabulation），只需要将聚合函数由"mean"改为"count":<br />![2021-08-09-07-01-39-898753.png](./img/1628464030498-bc3efa38-ec56-408a-a57a-14780db113e7.png)<br />这个结果展示了每一对类别变量组合后的记录总数。
<a name="YeiQZ"></a>
## 连续数据转类别数据
来看一下Titanic数据集中的Age那一列：<br />![2021-08-09-07-01-40-105738.png](./img/1628464030507-8f068ffb-7549-4531-8da8-547fdbfc32d6.png)<br />它现在是连续性数据，但是如果想要将它转变成类别数据呢？<br />一个解决办法是对年龄范围打标签，比如"adult", "young adult", "child"。实现该功能的最好方式是使用`**cut()**`**函数**：<br />![2021-08-09-07-01-40-190738.png](./img/1628464030517-40d0739e-a1cb-4c88-8706-7afdd6cc00de.png)<br />这会对每个值打上标签。0到18岁的打上标签"child"，18-25岁的打上标签"young adult"，25到99岁的打上标签“adult”。<br />注意到，该数据类型为**类别变量**，该类别变量**自动排好序**了（有序的类别变量）。
<a name="BxsAv"></a>
## Style a DataFrame
上一个技巧在想要修改整个jupyter notebook中的显示会很有用。但是，一个更灵活和有用的方法是定义特定DataFrame中的格式化（style）。<br />回到stocks这个DataFrame:<br />![2021-08-09-07-01-40-458736.png](./img/1628463924088-c94ad18f-de49-4fe7-b746-d6060611ba3d.png)<br />可以**创建一个格式化字符串的字典，用于对每一列进行格式化**。然后将其传递给DataFrame的`style.format()`函数：<br />![2021-08-09-07-01-40-547736.png](./img/1628463924091-d51440f0-d266-480c-92c5-224e0b651fda.png)

注意到，Date列是month-day-year的格式，Close列包含一个`$`符号，Volume列包含逗号。<br />可以通过**链式调用函数**来应用更多的格式化：<br />![2021-08-09-07-01-40-628738.png](./img/1628463924114-e18e63cc-048e-4553-9dbe-64acb9002a8d.png)<br />现在隐藏了索引，将Close列中的最小值高亮成红色，将Close列中的最大值高亮成浅绿色。<br />这里有另一个DataFrame格式化的例子：<br />![2021-08-09-07-01-40-987735.png](./img/1628463924124-8e1bf7aa-6c3a-46ce-9201-115ddd3019d6.png)<br />Volume列现在有一个渐变的背景色，可以轻松地识别出大的和小的数值。<br />最后一个例子：<br />![2021-08-09-07-01-41-083737.png](./img/1628463924144-d0c42089-f8ee-4418-a790-cd178ac16ace.png)<br />现在，Volumn列上有一个条形图，DataFrame上有一个标题。<br />请注意，还有许多其他的选项可以用来格式化DataFrame。
<a name="s9BMs"></a>
## 额外技巧
<a name="neXmu"></a>
### **Profile a DataFrame**
假设拿到一个新的数据集，不想要花费太多力气，只是想快速地探索下。那么可以**使用pandas-profiling这个模块**。<br />在系统上安装好该模块，然后**使用**`**ProfileReport()**`**函数**，传递的参数为任何一个DataFrame。它会返回一个互动的HTML报告：

- 第一部分为该数据集的总览，以及该数据集可能出现的问题列表
- 第二部分为每一列的总结。可以点击"toggle details"获取更多信息
- 第三部分显示列之间的关联热力图
- 第四部分为缺失值情况报告
- 第五部分显示该数据及的前几行

**使用示例如下**（只显示第一部分的报告）：<br />![2021-08-09-07-01-41-174737.png](./img/1628463862290-9f25c637-a027-4b09-8ce4-04d93eb1dfaa.png)
