# 网络协议

## 网络编程

![1576332769242-8ec57bf2-7433-46dc-ba7a-27f84651384c](D:\Note\python\网络编程\图片\1576332769242-8ec57bf2-7433-46dc-ba7a-27f84651384c.png)



## OSI七层

### 物理层

主要作用是实现两台物理机之间的通信，通过二进制比特流的传输来实现，二进制数据表现为电流电压上的强弱，到达目的地再转化为二进制机器码。网卡、集线器工作在这一层。

### 数据链路层 

主要作用是把从下层接收到的数据进行**MAC地址的封装与解封装**。这一层的数据常被称为帧，在这一层工作的设备是交换机（三层交换机不在此层工作）

### 网络层

主要作用是把从下层接收到的数据进行**IP地址的封装与解封装**。在这一层工作的设备是路由器，这一层的数据常被称为数据包。

### 传输层

主要作用是把从下层接收到的数据进行**分段传输，到达目的地后再重组**。我们常把这一层的数据成为段。定义了传输数据的协议和端口号，比如：TCP（传输控制协议，传输效率低，可靠性高，用于传输对可靠性要求高且数据量大的数据）和UDP（用于数据包协议，与TCP的特性相反，传输的是对可靠性要求不高且数据量小的数据）。

### 会话层

主要作用是**在系统之间发起会话或接收会话请求**（设备之间可通过IP，也可通过MAC或主机名来互相认识）。建立会话：身份验证，权限鉴定等； 保持会话：对该会话进行维护，在会话维持期间两者可以随时使用这条会话传输局； 断开会话：当应用程序或应用层规定的超时时间到期后，OSI会话层才会释放这条会话。

### 表示层

主要作用是**对接收的数据进行解释、加密与解密、压缩与解压缩等操作**（也就是把计算机能够识别的东西转换成人能够识别的东西，比如图片、声音等）

### 应用层

主要是一些终端的应用，比如FTP（文件下载）、WEB、QQ之类的应用，方便应用程序之间进行通信。

![20170301092349308](D:\Note\python\网络编程\图片\20170301092349308.png)



## TCP请求头

![1586269556125-8f330028-c09a-45ce-a8eb-65659937cdb8](D:\Note\python\网络编程\图片\1586269556125-8f330028-c09a-45ce-a8eb-65659937cdb8.webp)



## TCP和UDP区别

+ TCP面向连接，可靠的，有序的，一对一的，以字节流方式发送数据的传输层协议，有拥塞控制和流量控制机制，保证数据传输的安全性
+ UDP是无连接的，支持一对一、一对多、多对多的的传输层协议，尽最大努力交付，不保证可靠的
+ 应用场景不同，TCP适合对效率要求相对低，但对准确性要求相对高或者是有连接的场景，一般用于文件传输（HTTP，HTTPS，FTP等协议），邮件（POP，SMTP等协议），远程登录等场景；UDP更适合对效率要求相对高，对准确性要求相对低的场景，UDP一般用于即时通信（QQ聊天），在线视频（rtsp流速度一定要快，偶尔丢包没关系），网络语音电话等场景



## TCP比UDP多消耗哪些系统资源

TCP建立连接时三次握手，断开连接时四次挥手；TCP数据包头部20字节，UDP数据包头部8字节；TCP有流量控制和拥塞控制。



## 如何理解流

首先呢，说TCP是流传输，你可以想象一下，两个管道，一个发送管道，一个接受管道。两端通过这个管道进行传输，同时发送数据就好比是水，并且这个水是有刻度的，每次发送多少都用序号标注，当接收方收到数据块，它会给发送方返回一个确认我收到了，如果一直没有收到这个确认，发送方还会进行重发，接收方也会按照这个序号，将接受到的数据进行重组，确保是发送方发过来的顺序，这就是一个可靠的流式传输。

UDP就不存在应答和缓存，就是把数据全都发送给你，你收没收到我不关心。所以文件下载肯定要用tcp，而网络聊天视频，udp就可以了，少一点数据，最多画面卡顿下。



## TCP如何保证可靠传输

主要通过6种方式，重传机制、校验和、序列号、确认应答、流量控制、拥塞控制

### 1.重传机制

涉及超时重传、快速重传、SACK

- **超时重传：**就是在发送数据时，设定一个定时器，当超过指定的时间后，如果没有收到ACK确认应答，就会重传丢失的报文段

- **快速重传：**它不以时间为驱动，而是以数据驱动，当收到三个相同的 ACK 报文时，会在定时器过期之前，就会重传丢失的报文段

### 2.校验和

其目的是为了判断数据传输过程中是否发生改动，如果有改动，则CP段会被直接丢弃。 

### 3.序列号和确认应答

序列号：每个数据包都会编号，**主要用来解决网络包乱序问题。**

确认应答：接收方会发送一个下次期望收到的序列号的数据，发送端根据这个判断之前的数据是否都已经被接收了，**用来解决不丢包的问题。**

### 4.流量控制

流量控制主要是通过动态调整滑动窗口去控制，指的是接收端的缓冲区大小，包含在ACK里，主要用来告诉发送端自己还能缓冲多少数据，进而可以控制发送端发送数据的大小和速度

#### 滑动窗口的移动规则

1. 窗口收缩：接收方在收到对端数据后，并且确认了数据的正确性，那么这些数据会被暂时存储到缓冲区，等待应用程序获取。在数据还没有被应用程序取走的时候，就会发生窗口收缩。
2. 窗口张开：窗口收缩后，应用进程一旦从缓冲区中取出数据，TCP的滑动窗口需要进行扩张。

### 5.拥塞控制

拥塞控制主要是通过动态调整拥塞窗口去控制，指的是发送端窗口的大小，它有四种算法（慢启动，拥塞控制，快恢复，快重传）

1. **慢开始：**发送方传输数据前，会慢慢的对网络状况试探，避免发送了太多数据而导致网络阻塞，这就需要设置一个慢开始门槛（ssthresh）的变量，这个变量大小由拥塞窗口和TCP通告窗口的最小值决定。假如拥塞窗口为1，那么发送方第一次就发送一个包，如果接收方返回了ACK确认，拥塞窗口就乘2，以此类推，通过指数方式增加。
2. **拥塞避免：**假如当拥塞窗口等于32时就会发生拥塞，然后设置慢开始大小为16，拥塞窗口从1开始通过指数的方式的增大，当拥塞窗口等于慢开始大小时，就改为线性增加，每次加一，预示着可能会出现网络拥塞，所以减慢速度，如果真的出现了网络拥塞，那么拥塞窗口会被置为1，慢开始大小被砍半，重新开始传输。
3. **快重传：**快速重传是当收到三个相同的 ACK 报文时，会在定时器过期之前，重传丢失的报文段。
4. **快恢复：**网络出现拥塞时，就把慢开始大小减半，然后拥塞窗口改为慢开始大小的一半，之后线性增加，而不是把拥塞窗口改为1。



**慢开始：**拥塞窗口，开始传输数据时窗口大小指数增长，如果达到快开始门槛限制或者发生拥塞，那么就会使用拥塞避免算法
**拥塞避免：**达到门限后线性增加，减少堵塞
**快重传：**一旦发现服务器向客户机发超过3次重复消息，判断消息丢失，快重传
**快恢复：**一旦堵塞，降低快开始门限值，重新开始慢开始，拥塞避免。



## 三次握手目的和本质

![1583215076976-1b43f3ef-7dd4-4853-87dd-69d889ab4401](D:\Note\python\网络编程\图片\1583215076976-1b43f3ef-7dd4-4853-87dd-69d889ab4401.png)

三次握手的主要目的是确定客户端和服务端的发送能力和接收能力都没有问题，以及同步交换双方的序列号和确认号，告知TCP窗口大小。



## 三次握手的过程

第一次握手：客户端向服务端发送SYN报文段，里面包含客户端的初始序列号（ISN）

第二次握手：服务端收到客户端发送的SYN报文段，并向客户端发送SYN报文，里面也包含自己的初始序列号（ISN）

第三次握手：客户端向服务端发送ACK报文确认建立TCP连接



## 握手为什么要三次，两次行不行

首先明确三次握手主要是为了确定客户端以及服务端的接收能力和发送能力都没问题

第一次握手：客户端发送报文，服务端接收报文，服务端就可以确认客户端的发送能力和自己的接收能力没问题

第二次握手：服务端发送报文，客户端接收报文，客户端就可以确认自己的发送能力和接收能力和服务端的接收能力以及发送能力没问题，但是服务端还没有确认客户端的接收能力是否正常

第三次握手：客户端发送报文，服务端接收报文，服务端就可以确认客户端的接收能力都没问题**（主要就是因为服务端无法确认客户端的接收能力是否正常）**



### 半连接状态

当第二次握手进行之后服务端就处于一个半连接状态，服务器会把此种状态下请求连接放在一个队列里，该队列称为半连接队列。也就是只要接收到客户端的SYN-ACK报文就可以完成连接，当服务器收到客户的确认包时，删除该条目，服务器进入ESTABLISHED状态。

Linux下默认会进行5次重发SYN-ACK包，重试的间隔时间从1s开始，下次的重试间隔时间是前一次的双倍，5次的重试时间间隔为1s, 2s, 4s, 8s, 16s, 总共31s, 称为**指数退避**，第5次发出后还要等32s才知道第5次也超时了，所以，总共需要 1s + 2s + 4s+ 8s+ 16s + 32s = 63s, TCP才会把断开这个连接。由于，SYN超时需要63秒，那么就给攻击者一个攻击服务器的机会，攻击者在短时间内发送大量的SYN包给Server(俗称SYN flood攻击)，用于耗尽Server的SYN队列。



## SYN攻击

说到SYN攻击就不得不说tcp连接的资源分配，**服务端的资源分配是在第二次握手，客户端是在第三次握手时进行的资源分配，**SYN攻击就是Client在短时间内伪造大量不存在的IP地址向Server不断地发送SYN包，Server需要回复确认包，并等待Client确认，由于IP都是假的，因此Server需要不断重发直至超时，这些伪造的SYN包会长时间占用未连接队列，导致正常的SYN请求因为队列满而被丢弃。

**监控无效连接并释放**

监控系统的半开连接和不活动连接，当达到一定阈值时就释放这些连接，从而释放系统资源。这种方法对于所有的连接一视同仁，正常连接请求也会放掉

**延缓TCB分配方法**

正常建立三次握手之后才分配TCB资源。

**使用SYN Proxy防火墙**

一种方式是客户端和防止墙建立有效性连接后，防火墙才会向内部服务器发起SYN请求。防火墙代服务器发出的SYN ACK包使用的序列号为c, 而真正的服务器回应的序列号为c', 这样，在每个数据报文经过防火墙的时候进行序列号的修改。

另一种方式是防火墙确定了连接的安全后，会发出一个safe reset命令，client会进行重新连接，这时出现的syn报文会直接放行。这样不需要修改序列号了。但是，client需要发起两次握手过程，因此建立连接的时间将会延长。



## 什么是四次挥手

第一次挥手：客户端发送一个 FIN 报文，报文中会指定一个序列号

第二次挥手：服务端收到 FIN 之后，但是数据可能还没发传完，就只会发送 ACK 报文

第三次挥手：如果传完了，就会发送 FIN 报文，报文中也会指定一个序列号

第四次挥手：客户端收到 FIN 之后，发送一个 ACK 报文应答



### TIME_WAIT

**发生在主动断开链接的一方，发送方发送最后一个ACK时，为了可靠的终止TCP全双工连接的，**它会进入TIME_WAIT状态，这个状态会持续2MSL



### 为什么需要保持2MSL？

MSL即报文最大生存时间，它是任何报文在网络上存在的最长时间，超过这个时间报文将被丢弃。**目的是为了保证上一次连接的报文已经彻底在网络中消失，不会出现与新TCP连接报文冲突的情况，以及****可靠的实现TCP全双工连接的终止**



#### 如何处理TIMEWAIT过多?

这种问题在一些爬虫服务器上比较常见，TIME_WAIT是主动关闭连接的一方保持的状态，对于爬虫服务器来说他本身就是“客户端”，在完成一个爬取任务之后，他就会发起主动关闭连接，从而进入TIME_WAIT的状态，然后在保持这个状态2MSL时间之后，彻底关闭回收资源。可以通过修改内核参数让服务器能够快速回收和重用那些TIME_WAIT的资源



### 队头阻塞

**1. TCP队头阻塞**

因为TCP数据包是有序传输，中间一个数据包丢失，会等待该数据包重传，造成后面的数据包的阻塞。

**2. HTTP队头阻塞**

HTTP队头阻塞和TCP队头阻塞完全不是一回事。

HTTP1.x采用长连接，可以在一个TCP请求上，发送多个HTTP请求。有非管道化和管道化两种方式。

**非管道化**：完全串行执行，请求->响应->请求->响应...，后一个请求必须在收到前一个请求的响应才发送，会造成队头拥塞

**管道化**：请求可以并行发出，但是响应必须串行返回，会造成队头拥塞



##### 如何解决HTTP队头阻塞

1. **并发TCP连接**（浏览器一个域名采用6-8个TCP连接，并发HTTP请求）
2. **HTTP2**.0引入了**多路复用、二进制**帧等概念，避免了HTTP层面的队头阻塞，但是不能避免TCP层面的队头阻塞



##### 如何解决TCP队头阻塞

1. TCP中的队头阻塞的产生是由TCP自身的实现机制决定的，无法避免。想要在应用程序当中避免TCP队头阻塞带来的影响，只有舍弃TCP协议。
2. 比如google推出的quic协议，在某种程度上可以说避免了TCP中的队头阻塞，因为它根本不使用TCP协议，而是在UDP协议的基础上实现了可靠传输。而UDP是面向数据报的协议，数据报之间不会有阻塞约束
3. 此外还有一个SCTP（流控制传输协议），它是和TCP、UDP在同一层次的传输协议。SCTP的多流特性也可以尽可能的避免队头阻塞的情况。

## 粘包和拆包

首先要知道TCP包是由头+内容的方式组成的，如果内容远远小于头，这样传输会很浪费，所以TCP就用了一个算法，将一个连接中的多个包合并成一个进行传输，它有一个固定大小，根据接收者的滑动窗口决定，还有在高并发的场景下，为了减少用户和服务器的请求次数会在一个请求包里包含多个请求地址

假设客户端分别发送数据包D1和D2给服务端，由于服务端一次性读取到的字节数是不确定的，所以可能存在以下几种情况。

1. 服务端分2次读取到了两个独立的包，分别是D1，D2，没有粘包和拆包
2. 服务端一次性接收了两个包，D1和D2粘在一起了，被成为TCP粘包
3. 服务端分2次读取到了两个数据包，第一次读取到了完整的D1和D2包的部分内容，第二次读取到了D2包的剩余内容，这被称为拆包
4. 服务端分2次读取到了两个数据包，第一次读取到了部分D1，第二次读取D1剩余的部分和完整的D2包，这被称为拆包
5. 如果此时服务端TCP接收滑动窗非常小，而数据包D1和D2都很大，很有可能发送第五种可能，即服务端多次才能把D1和D2接收完全，期间多次发生拆包情况

**解决策略**

固定发送信息长度，或在两个信息之间加入分隔符。

## HTTP和HTTPS

HTTP协议传输的数据都是未加密的，也就是明文的，因此使用HTTP协议传输隐私信息非常不安全，为了保证这些隐私数据能加密传输，于是设计了SSL协议用于对HTTP协议传输的数据进行加密，从而就诞生了HTTPS。简单来说，HTTPS协议是由SSL+HTTP协议构建的可进行加密传输、身份认证的网络协议，要比HTTP协议安全。

**连接建立过程**

1. 客户端向一个需要https访问的网站发起请求。
2. 服务器将证书发送给客户端进行校验，证书里面包含了其公钥，这里客户端会校验数字证书是否有效。

1. ​	a.客户端获取到了站点证书，拿到了站点的公钥

2. ​	b.要验证站点可信后，才能使用其公钥，因此客户端找到其站点证书颁发者的信息

3. ​	c.站点证书的颁发者验证了服务端站点是可信的，但客户端依然不清楚该颁发者是否可信

4. ​	d.再往上回溯，找到了认证了中间证书商的源头证书颁发者。由于源头的证书颁发者非常少，我们浏览器之前就认识了，因此可以		认为根证书颁发者是可信的

5. ​	f.一路倒推，证书颁发者可信，那么它所颁发的所有站点也是可信的，最终确定了我们所访问的服务端是可信的

3.校验成功之后，客户端会生成一个协商密钥然后使用服务器证书的公钥进行加密之后发送给服务器。

4.服务器通过使用自己的私钥解密得到这个协商密钥。

5.服务器从此开始使用这个协商密钥进行对称加密开始和客户端进行通信。

6.客户端拿到值用对称加密方式 使用协商密钥进行解密。

## HTTP1.0 1.1 2.0的主要区别

HTTP/0.9

- 只支持GET请求，并且只能请求HTML格式的资源

HTTP/1.0

- 支持长连接，但是默认短连接（每一个请求都是一个单独的连接，做不到连接的复用），支持GET、POST、 HEAD请求

HTTP/1.1

- 默认开启长连接，在一个TCP连接上可以传送多个HTTP请求和响应
- 支持管道传输，只要第一个请求发出去了，不必等其回来，就可以发第二个请求出去，可以减少整体的响应时间
- 新增了请求方式PUT、PATCH、OPTIONS、DELETE
- 请求头增加了 Host、Language,、Encoding,、Type等

HTTP/2.0

- 实现多路复用：在一个连接里面并发处理请求
- 2.0的传输是基于二进制帧的，解决了队头阻塞的问题
- 服务端有了推送功能：将客户端感兴趣的东西推给客户端，当客户端请求这些时，直接去缓存中取就行
- 首部压缩，降低开销

**区别总结**

- 1.0与1.1之间是连接模型的区别(短连接、长连接、管线化)
- 1.1与2.0之间的区别是I/O多路复用的单一长连接、服务器推送、二进制分帧、首部压缩等



## 什么时候用长连接，短连接？

1. 长连接多用于操作频繁，点对点的通讯，而且连接数不能太多情况，每次操作完后都不断开TCP连接，但并不是永久连接，一般也会有一个保持的时间。例如：数据库的连接用长连接， 如果用短连接频繁的通信会造成socket错误，而且频繁的socket创建也是对资源的浪费，比如微博、抖音等直播场景在通过短连接做完鉴权等基本认证后会重新建立长连接，服务器专门维持一个长连接池提供服务
2. 而像Web网站的http服务一般都用短链接，因为成千上万的客户端用短连接会更省一些资源，如果用长连接，每个用户都需要占用一个连接，那可想而知吧，所以并发量大，但每个用户无需频繁操作情况下需用短连接好



## 常见的HTTP状态码

- **301（一般是资源位置永久更改）**域名到期不想续费（或者发现了更适合网站的域名），想换个域名。
- **302（一般是普通的重定向需求：临时跳转）**如果客户端发的是GET请求那么没什么影响，如果客户端发POST请求，那么会被临时跳转，但是因为请求是POST，浏览器在这种情况下都会把POST变为GET请求（因为POST方法不是幂等的，浏览器也是为了安全考虑）

- **307** ：需要了解302的原理，但是有的时候不想被转成GET，**强制开启HTTPS就是会出现307**
- **501：**请求类型服务器不支持
- **502：**主要是因为后端服务器，比如uswgi响应的内容nginx无法理解或无效
- **503：**主要是因为瞬间并发量太大，导致后端服务器没有足够的资源去处理请求
- **504：**网关超时，主要是因为后端服务器处理任务超时，超过了nginx的超时时间



## 跨域

同源策略会阻止一个域的javascript脚本和另外一个域的内容进行交互。所谓同源就是两个页面具有相同的协议（protocol），主机（host）和端口号（port）

目的是为了保证用户信息的安全，防止恶意的网站窃取数据。

解决办法：

JSONP（仅仅用于get请求）

CORS（跨域资源共享）**本质是设置响应头**。**是跨源AJAX请求的根本解决方法。**相比JSONP只能发GET请求，CORS允许任何类型的请求。

1. CORS 通过 HTTP 请求中附带 Origin 的 Header 来表明自己来源域。例如 Origin 的 Header 就是 www.a.com。
2. 服务器端接收到这个请求之后，会根据一定的规则判断是否允许该来源域的请求。如果允许，服务器在返回的响应中会附带上 Access-Control-Allow-Origin 这个 Header，内容为 www.a.com 来表示允许该次跨域访问。如果服务器允许所有的跨域请求，将 Access-Control-Allow-Origin 的 Header 设置为星号（*）即可。
3. 浏览器根据是否返回了对应的 Header 来决定该跨域请求是否成功，如果没有附加对应的 Header，浏览器将会拦截该请求。如果是非简单请求，浏览器会先发送一个 OPTIONS 预请求来获取服务器的 CORS 配置，如果服务器不支持接下来的操作，浏览器也会拦截接下来的请求。



## 输入url到返回都发生了什么？

**客户端获取URL - > DNS把域名解析成IP地址 - > TCP连接 - >发送HTTP请求 - >服务器处理请求 - >返回报文 - >浏览器解析渲染页面 - > TCP断开连接**

1. 在浏览器地址栏输入www.baidu.com
2. 浏览器查看**缓存**，如果请求资源在缓存中并且新鲜，足够新鲜直接提供给客户端：检验新鲜通常有两个HTTP头进行控制`Expires`和`Cache-Control`：

- - HTTP1.0提供Expires，值为一个绝对时间表示缓存新鲜日期
  - HTTP1.1增加了Cache-Control: max-age=，值为以秒为单位的最大新鲜时间

# ![image](D:\Note\python\网络编程\图片\image.png)

1. 浏览器**解析URL**获取协议，主机，端口，path
2. 浏览器**组装一个HTTP（GET）请求报文**
3. DNS解析**获取主机ip地址**，过程如下：

1. 1. 浏览器会首先搜索浏览器自身的 DNS 缓存（缓存时间比较短，且只能容纳 1000 条缓存），看自身的缓存中是否有www.baidu.com对应的条目，而且没有过期，如果有且没有过期则解析到此结束。
   2. 本机缓存
   3. hosts文件，看看这里面有没有该域名对应的IP地址
   4. 路由器缓存
   5. ISP DNS缓存，这里肯定会有，ISP会分配给我一个DNS（如果自己本地hosts文件写了别的就不会用它，比如谷歌8.8.8.8）
   6. 本地DNS就把请求发至13个根DNS中的一个，这里的13不是13台服务器，而是13个主机名和IP地址，根DNS服务器收到请求后会判断这个顶级域名(.com)是谁来授权管理，并会返回负责.com域名服务器的NS记录（记录域名服务器，用来指定该域名由哪个DNS服务器来进行解析），一般来说也是13个主机名和IP地址。本地DNS服务器向其中一台再次发起请求，这台负责.com域的服务器收到请求后，如果自己无法解析，它就会找一个管理.com域的下一级DNS服务器地址，并会返回负责baidu.com域名服务器的NS记录（最新是5台），然后本地DNS服务器向其中一台再次发起请求，baidu.com收到之后，查了下www这台主机，然后就把IP返回给你了（baidu.com就是一个顶级域名，而www.baidu.com却不是顶级域名，他是在baidu.com 这个域里的一叫做www的主机）；但有时候解析起来也会比较复杂，可能没给返回IP地址，而是返回一个C-NAME：**www.a.shifen.com，**此时客户端还是无法解析，因为要的是IP，然后使用类似迭代的方式继续刚才的流程访问根DNS，最终返回一个**www.a.shifen.com**的A类记录类型（也是就IP地址）（现实上并不会从头迭代，因为shifen.com和baidu.com这两个域在同一台NS记录上）；如果百度使用了CDN提供商的智能DNS，浏览器再次对CNAME域名进行解析的时候，可根据不同运营商、地理位置、内部应用情况进行智能解析分配，使得用户能走最优线路访问。此次解析浏览器得到CDN缓存服务器的IP地址，向缓存服务器发出访问请求；缓存服务器根据浏览器提供的要访问的域名，通过内部专用DNS解析得到此域名的真实IP地址，再由缓存服务器向这个真实IP地址提交访问请求；缓存服务器从真实IP地址得到内容以后，一方面在本地进行保存，以备以后使用，二方面把获取的数据返回给客户端，完成数据服务过程 

2. ~~~ python
   本机向local dns请求www.baidu.com
   local dns向根域请求www.baidu.com，根域返回com.域的服务器IP
   向com.域请求www.baidu.com，com.域返回baidu.com域的服务器IP
   向baidu.com请求www.baidu.com，返回cname www.a.shifen.com和a.shifen.com域的服务器IP
   向root域请求www.a.shifen.com
   向com.域请求www.a.shife.com
   向shifen.com请求
   向a.shifen.com域请求
   拿到www.a.shifen.com的IP
   localdns返回本机www.baidu.com cname www.a.shifen.com 以及 www.a.shifen.com的IP
   ~~~

3. ​	6.传输层中TCP协议将请求报文按序号分割成多个报文段

4. ​	7.网络层把每一个报文段增加源IP地址和目标IP地址得到数据包，并根据IP协议（传输数据），ARP协议（获取MAC地址），OSPF		协议（选择最优路径），搜索服务器地址，一边中转一边传输数据

5. ​	8.数据链路层把每个数据包加上MAC地址变成数据帧

6. ​	9.物理层把数据帧变成数字信号（bit流）

7. ​	10.服务端的物理层接受bit流，数据链路层发现MAC地址是自己，去掉MAC地址给它的网络层，网络层去掉它的IP地址给出传输层

8. ​	11.传输层打开一个socket与目标IP地址，建立TCP三次握手：

9. - - 客户端发送一个TCP的**SYN=1，Seq=X**的包到服务器端口
     - 服务器发回**SYN=1， ACK=X+1， Seq=Y**的响应包
     - 客户端发送 **ACK=Y+1， Seq=Z**

​			12. TCP三次握手后传输层把数据向上传递最终到达应用层，应用层把各个数据拼接起来，向上面拿到的IP的80端口**发送HTTP请				求，**如果缓存着用户请求的资源，则直接返回给用户，如果没有就将请求转发给处理业务的负载均衡器

​			13.**这里拿阿里云的SLB举例，****负载均衡器****收到后，发现客户端使用****HTTP，但是他这里强制开启了HTTPS，所以给客				户端返回307，客户端再次向负载均衡器的443端口发****送HTTPS请求**（可以试试给http://jd.com发一个post请求，会返回				一堆html）（常规的都是和负载均衡器建立HTTPS，然后出入栈流量都经过负载均衡器，有个特例例子：LVS的DR和TUN模				式，出栈不经过负载均衡器）

​				a.  负载均衡器将证书发送给客户端进行校验。证书里面包含了其公钥。这里客户端会校验数字证书是否有效。

1. ​		b. 验证证书的合法性(盘发证书的机构是否合法，是否过期，证书中包含的网站地址是否与正在访问的地址一致等)，如果证书受			信任，则浏览器栏里面会显示一个小锁头，否则会给出证书不受信任的提示。一般的浏览器对于自己签发的证书都会给不收信			息的提示

2. ​		c.  如果证书受信任，或者用户接受了不受信任的证书，客户端会生成一个协商密钥然后使用负载均衡器证书的公钥进行加密之后			发送给负载均衡器。

3. ​		d. 负载均衡器通过使用自己的私钥解密得到这个协商密钥。

4. ​		e. 负载均衡器从此开始使用这个协商密钥进行对称加密开始和客户端进行通信。

5. ​		f. 客户端拿到值用对称加密方式 使用协商密钥进行解密得到负载均衡器发送的数据

6. **注意：**为啥是307呢？平常没见过啊

7. - - **301（一般是资源位置永久更改）**域名到期不想续费（或者发现了更适合网站的域名），想换个域名。
     - **302（一般是普通的重定向需求：临时跳转）**如果客户端发出POST请求后，收到负载均衡器的302状态码，会跟用户确认是否该重发，因为第二次POST时，但是环境可能已经发生变化（POST方法不是幂等的，他可能已经把环境改变了），POST操作会不符合用户预期。所以浏览器在这种情况下都会把POST请求变为GET请求

8. 1. 1. ​	i.未登录前先使用302重定向到登录页面,登录成功后再跳回到原来请求的页面

      2. ​	ii.像微博之类的使用短域名，用户访问后需要重定向到真实的地址之类。

9. - - **307** **只不过是针对POST方法的请求不允许更改方法，强制开启https就是会出现307，**如果向一个强制开启https的网站发送了一个http的post请求，请求会被重定向，浏览器看到是302会把请求类型转成get，所以有的时候不合理因此有了307

10. 14.CDN中的负载均衡器将包含前端页面的**响应报文通过TCP连接发送回浏览器**

11. 15.浏览器接收HTTP响应，然后根据情况选择**关闭TCP连接或者保留重用，关闭TCP连接的四次握手如下**：

12. - - 主动方发送**Fin=1， Ack=Z， Seq= X**报文
      - 被动方发送**ACK=X+1， Seq=Z**报文
      - 被动方发送**Fin=1， ACK=X， Seq=Y**报文
      - 主动方发送**ACK=Y， Seq=X**报文

13. 16.浏览器检查响应状态码：是否为1XX，3XX， 4XX， 5XX，这些情况处理与2XX不同

14. 17.对响应进行**解码**（例如gzip压缩）

15. 18.根据资源类型决定如何处理（假设资源为HTML文件）

​		19.读取页面内容（HTML解析过程中会逐步显示页面）

​			a.浏览器载入 HTML 代码，会"自上而下"逐步加载，发现 <head> 内有一个 <link> 引用外部 CSS 文件，则浏览器**立即发送				CSS文件请求**，获取浏览器返回的CSS文件；（CSS文件合并，减少HTTP请求）

​			b.如果碰到链接的静态文件资源时， 浏览器便会另开多个线程去请求下载，这是便会使用到HTTP协议的keep-alive特性了，建立				了一次HTTP连接，但是能够请求多个静态资源。

​			c.浏览器继续载入 HTML 中 <body> 部分的代码，并且 CSS 文件已经拿到手了，可以**开始渲染页面**了；（CSS文件需要放置最上				面，避免网页重新渲染）

​			d.浏览器在代码中发现一个 <img> 标签引用了一张图片，向服务器发出**请求**。**此时浏览器不会等到图片下载完，而是继续渲染				后面的代码**；（图片文件合并，减少HTTP请求）

​			e.浏览器发现了一个包含一行 JavaScript 代码的 <script> 标签，会**立即运行**该js代码；（script最好放置页面最下面）

​				i.当文档加载过程中遇到js文件，html文档会挂起渲染（加载解析渲染同步）的线程，不仅要等待文档中js文件加载完毕，还要					等待解析执行完毕，才可以恢复html文档的渲染线程。因为JS有可能会修改DOM，最为经典的document.write，这意味着，					在JS执行完成前，后续所有资源的下载可能是没有必要的，这是js阻塞后续资源下载的根本原因。所以我明平时的代码中，js					是放在html文档末尾的。

​			f.终于等到了 </html> 的到来，浏览器泪流满面……

​		20.在解析过程中，如果遇到请求外部资源时，如图片、外链的CSS、iconfont等，请求过程是异步的，并不会影响html文档进行加			载，执行js脚本的时候，前端会通过axios向后端服务器发送请求

​		21.然后经过层层解析前端代码里写的后段地址拿到真实IP，请求到达另外一个负载均衡器，这个负载均衡器地址和上面的地址一般			是不一样的，负载均衡器通过事先配置的一些算法将请求转发给后端真实的业务服务器，这个还会出现307

- - roundrobin： rr，轮询，默认
  - weight：指定轮询几率，weight和访问比率成正比。用于后端服务器性能不均的情况
  - ip_hash：每个请求按访问IP的hash分配，这样来自同一IP固定访问一个后台服务器
  - least_conn（最少连接）：自动检测最少连接最少的，然后分给他
  - url_hash：按访问的url的hash结果分配请求，是每个url定向到同一后端服务器上
  - fair：按后端服务器的响应时间来分配请求，响应时间短的优先分配

​		22.首先到达Django的wsgi，wsgi可以理解为服务端的socket，用于接收用户请求并将请求进行初次封装

1. ​	a.中间件处理请求，它会对请求校验或在请求对象中添加其他相关数据，例如：csrf、验证session、token

2. ​	b.路由匹配，根据当前请求的URL找到视图函数，如果是FBV写法，通过判断method两类型，找到对应的视图函数；如果是CBV写		法，路由系统执行CBV的as_view()，之后会自动去找dispatch方法，然后会通过dispatch反射的方式找到类中对应的方法执行

3. ​	c.在dispath执行之前，还会经过版本分析和渲染器-->在dispath方法内部，主要对request封装-->版本-->认证-->权限-->限流-->限		流-->通过反射执行视图函数

4. ​	d.到达视图函数后，执行业务逻辑代码，这里可能涉及到：ORM数据查询、View视图将数据渲染到Template模板

5. ​	e.视图函数执行完毕之后，会把数据返回给dispatch方法，由dispatch方法把数据返回经客户端

6. ​	f.中间件处理响应

7. ​	g.wsgi，将响应的内容原路返回发送给浏览器

8. ​	h.浏览器渲染

9. 23. 在进行ORM数据查询之前，会先去Redis中get，判断是否有新鲜数据，如果没有命中将会查询数据库

1. ​	a. 请求到达Mysql后，首先经过连接器（负责跟Django程序建立连接、获取权限、维持和管理连接），如果开启了长连接，并且客		户端持续有请求，那么会一直使用同一个连接

2. ​	b. 查询缓存,查询缓存有没有所执行的select的结果集.需注意,如果更新比较频繁不建议使用查询缓存query_cache_type=demand，8.0版本后去除了缓存

3. ​	c. 分析器（语法分析），通过"select"，识别出为你是要查询；通过"T"，识别出表名；通过条件"ID"，识别出ID那一列（select ID 		* from T），如果语法错误，会直接给出提示

4. ​	d. 优化器，决定用哪个索引；或者在一个语句有多表关联（join）的时候，决定各个表的连接顺序。一条查询可以有很多种执行方		式，最后都返回相同的结果，但是Mysql的优化器会根据自身算法，选择一个成本最小的

5. ​	e. 执行器，核对执行权限，调用存储引擎执行优化器选择的查询方式

6. ​	f. 返还数据，如果查询可以缓存，Mysql在这个阶段也会将结果放到查询缓存中

7. 24. 如果是一条更新的SQL

1. ​	a. 对于一条更新SQL，同样走和查询一样的流程。不过，执行更新SQL会涉及到两个重要的日志：redolog （重做日志）、binlog （归档日志）

​			《孔乙己》中，酒店掌柜有一个粉板，专门用来记录客人的赊账记录，如果赊账的人不多，那么他可以把顾客名和账目写在粉板			上。但如果赊账太多了，粉板总有挤不下的时候，这个时候，掌柜一定还有一个专门记账的账本。个人感觉掌柜很聪明。对于			MySQL，同样也有类似的处理： 

- - mysql会把变更记录先写到redo log中，并更新内存，然后在适当的时候将这个操作记录更新到磁盘中，redo log是InnoDB引擎特有的，记录的是物理日志，主要记录在“某个数据页上做了什么修改“
  - redo log可以保证数据库发生异常重启，之前提交的记录都不会丢失

​		redo log是存储引擎层的日志，bin log是server层的日志，记录的是sql语句的原始逻辑，Mysql主从就是基于bin log

​		25. 将查询到的数据写入Redis缓存