# åˆ†ç±»ç®—æ³•

![20190919152856861](./img/20190919152856861.png)

## sklearnè½¬æ¢å™¨ä¸é¢„ä¼°å™¨

### è½¬æ¢å™¨ï¼ˆç‰¹å¾å·¥ç¨‹æ—¶ä½¿ç”¨ï¼‰

- è½¬æ¢å™¨æ˜¯ç‰¹å¾å·¥ç¨‹çš„çˆ¶ç±»

- - å®ä¾‹åŒ– (å®ä¾‹åŒ–çš„æ˜¯ä¸€ä¸ªè½¬æ¢å™¨ç±»transformer)
  - è°ƒç”¨fit_transform() (å¯¹äºæ–‡æ¡£å»ºç«‹åˆ†ç±»è¯é¢‘çŸ©é˜µ, ä¸èƒ½åŒæ—¶ä½¿ç”¨)

- - - æ ‡å‡†åŒ– : ((x - mean) / std)
    - fit_transform()
    - fit() : è®¡ç®—æ¯ä¸€åˆ—çš„å¹³å‡å€¼ , æ ‡å‡†å·®
    - transform() : (x - mean) / stdè¿›è¡Œæœ€ç»ˆçš„è½¬æ¢

~~~ python
In [1]: from sklearn.preprocessing import StandardScaler

In [2]: std1 = StandardScaler()

In [3]: a = [[1,2,3], [4,5,6]]

In [4]: std1.fit_transform(a)
Out[4]:
array([[-1., -1., -1.],
       [ 1.,  1.,  1.]])

In [5]: std2 = StandardScaler()

In [6]: std2.fit(a)
Out[6]: StandardScaler(copy=True, with_mean=True, with_std=True)

In [7]: std2.transform(a)
Out[7]:
array([[-1., -1., -1.],
       [ 1.,  1.,  1.]])

# ä»ä¸­å¯ä»¥çœ‹å‡ºï¼Œfit_transformçš„ä½œç”¨ç›¸å½“äºtransformåŠ ä¸Šfitã€‚ä½†æ˜¯ä¸ºä»€ä¹ˆè¿˜è¦æä¾›å•ç‹¬çš„fitå‘¢, æˆ‘ä»¬è¿˜æ˜¯ä½¿ç”¨åŸæ¥çš„std2æ¥è¿›è¡Œæ ‡å‡†åŒ–çœ‹çœ‹

In [8]: b = [[7,8,9], [10, 11, 12]]

In [9]: std2.transform(b)
Out[9]:
array([[3., 3., 3.],
       [5., 5., 5.]])

In [10]: std2.fit_transform(b)
Out[10]:
array([[-1., -1., -1.],
       [ 1.,  1.,  1.]])

1.fitå’Œtransformæ²¡æœ‰ä»»ä½•å…³ç³»ï¼Œä»…ä»…æ˜¯æ•°æ®å¤„ç†çš„ä¸¤ä¸ªä¸åŒç¯èŠ‚ï¼Œä¹‹æ‰€ä»¥å‡ºæ¥fit_transformè¿™ä¸ªå‡½æ•°åï¼Œä»…ä»…æ˜¯ä¸ºäº†å†™ä»£ç æ–¹ä¾¿ï¼Œä¼šé«˜æ•ˆä¸€ç‚¹ã€‚
2.sklearné‡Œçš„å°è£…å¥½çš„å„ç§ç®—æ³•ä½¿ç”¨å‰éƒ½è¦fitï¼Œfitç›¸å¯¹äºæ•´ä¸ªä»£ç è€Œè¨€ï¼Œä¸ºåç»­APIæœåŠ¡ã€‚fitä¹‹åï¼Œç„¶åè°ƒç”¨å„ç§APIæ–¹æ³•ï¼Œtransformåªæ˜¯å…¶ä¸­ä¸€ä¸ªAPIæ–¹æ³•ï¼Œæ‰€ä»¥å½“ä½ è°ƒç”¨transformä¹‹å¤–çš„æ–¹æ³•ï¼Œä¹Ÿå¿…é¡»è¦å…ˆfitã€‚
3.fitåŸä¹‰æŒ‡çš„æ˜¯å®‰è£…ã€ä½¿é€‚åˆçš„æ„æ€ï¼Œå…¶å®æœ‰ç‚¹trainçš„å«ä¹‰ï¼Œä½†æ˜¯å’Œtrainä¸åŒçš„æ˜¯ï¼Œå®ƒå¹¶ä¸æ˜¯ä¸€ä¸ªè®­ç»ƒçš„è¿‡ç¨‹ï¼Œè€Œæ˜¯ä¸€ä¸ªé€‚é…çš„è¿‡ç¨‹ï¼Œè¿‡ç¨‹éƒ½æ˜¯ç¡®å®šçš„ï¼Œæœ€åå¾—åˆ°ä¸€ä¸ªå¯ç”¨äºè½¬æ¢çš„æœ‰ä»·å€¼çš„ä¿¡æ¯ã€‚
~~~



### é¢„ä¼°å™¨ï¼ˆè®­ç»ƒæ¨¡å‹æ—¶ä½¿ç”¨ï¼‰

- é¢„ä¼°å™¨ (sklearnæœºå™¨å­¦ä¹ ç®—æ³•çš„å®ç°)

- - ä¼°è®¡å™¨å·¥ä½œæµç¨‹ (estimator)

- - - å®ä¾‹åŒ–ä¸€ä¸ªestimatoré¢„ä¼°å™¨ç±»
    - estimator.fit(x_train, y_train) è®¡ç®— , è¿›è¡Œè®­ç»ƒ , è°ƒç”¨å®Œæ¯• , æ¨¡å‹ç”Ÿæˆ
    - æ¨¡å‹è¯„ä¼°

1. 1. 1. ç›´æ¥æ¯”å¯¹çœŸå®å€¼å’Œé¢„æµ‹å€¼
         y_predict = estimator.predict(x_test)
         y_test == y_predict

      2. è®¡ç®—å‡†ç¡®ç‡
         accuracy = estimator.score(x_test, y_test)

         

         **é¢„ä¼°å™¨å·¥ä½œæµç¨‹**

         ![image21](./img/image21.png)



## K-è¿‘é‚»ç®—æ³•

å¦‚æœä¸€ä¸ªæ ·æœ¬åœ¨ç‰¹å¾ç©ºé—´ä¸­çš„**kä¸ªæœ€ç›¸ä¼¼(å³ç‰¹å¾ç©ºé—´ä¸­æœ€é‚»è¿‘)çš„æ ·æœ¬ä¸­çš„å¤§å¤šæ•°å±äºæŸä¸€ä¸ªç±»åˆ«**ï¼Œåˆ™è¯¥æ ·æœ¬ä¹Ÿå±äºè¿™ä¸ªç±»åˆ«ã€‚

**æ ¸å¿ƒæ€æƒ³**ï¼šæ ¹æ®ä½ çš„"é‚»å±…"æ¨æ–­å‡ºä½ çš„ç±»åˆ«

![image22](./img/image22.png)

### 1. KNNç®—æ³•æµç¨‹æ€»ç»“

1. è®¡ç®—å·²çŸ¥ç±»åˆ«æ•°æ®é›†ä¸­çš„ç‚¹ä¸å½“å‰ç‚¹ä¹‹é—´çš„è·ç¦»
2. æŒ‰è·ç¦»é€’å¢æ¬¡åºæ’åº
3. é€‰å–ä¸å½“å‰ç‚¹è·ç¦»æœ€å°çš„kä¸ªç‚¹
4. ç»Ÿè®¡å‰kä¸ªç‚¹æ‰€åœ¨çš„ç±»åˆ«å‡ºç°çš„é¢‘ç‡
5. è¿”å›å‰kä¸ªç‚¹å‡ºç°é¢‘ç‡æœ€é«˜çš„ç±»åˆ«ä½œä¸ºå½“å‰ç‚¹çš„é¢„æµ‹åˆ†ç±»



### 2. è·ç¦»åº¦é‡

**2.1 æ¬§å¼è·ç¦»(Euclidean Distance)**

![equation1](./img/equation1.svg)

**2.2 æ›¼å“ˆé¡¿è·ç¦»(Manhattan Distance)**

![equation2](./img/equation2.svg)

**2.3 åˆ‡æ¯”é›ªå¤«è·ç¦» (Chebyshev Distance)**

![equation3](./img/equation3.svg)

**2.4 é—µå¯å¤«æ–¯åŸºè·ç¦»(Minkowski Distance)**

![equation4](./img/equation4.svg)

å…¶ä¸­pæ˜¯ä¸€ä¸ªå˜å‚æ•°ï¼š

- å½“p=1æ—¶ï¼Œå°±æ˜¯æ›¼å“ˆé¡¿è·ç¦»ï¼›
- å½“p=2æ—¶ï¼Œå°±æ˜¯æ¬§æ°è·ç¦»ï¼›
- å½“pâ†’âˆæ—¶ï¼Œå°±æ˜¯åˆ‡æ¯”é›ªå¤«è·ç¦»ã€‚

æ ¹æ®pçš„ä¸åŒï¼Œé—µæ°è·ç¦»å¯ä»¥è¡¨ç¤ºæŸä¸€ç±»/ç§çš„è·ç¦»ã€‚



**2.5 é—µæ°è·ç¦»ï¼ŒåŒ…æ‹¬æ›¼å“ˆé¡¿è·ç¦»ã€æ¬§æ°è·ç¦»å’Œåˆ‡æ¯”é›ªå¤«è·ç¦»ï¼Œéƒ½å­˜åœ¨æ˜æ˜¾çš„ç¼ºç‚¹:**

1. å°†å„ä¸ªåˆ†é‡çš„é‡çº²(scale)ï¼Œä¹Ÿå°±æ˜¯â€œå•ä½â€ç›¸åŒçš„çœ‹å¾…äº†
2. æœªè€ƒè™‘å„ä¸ªåˆ†é‡çš„åˆ†å¸ƒ(æœŸæœ›ï¼Œæ–¹å·®ç­‰)å¯èƒ½æ˜¯ä¸åŒçš„ã€‚



**2.6 â€œè¿ç»­å±æ€§â€å’Œâ€œç¦»æ•£å±æ€§â€çš„è·ç¦»è®¡ç®—**

æˆ‘ä»¬å¸¸å°†å±æ€§åˆ’åˆ†ä¸º"è¿ç»­å±æ€§" (continuous attribute)å’Œ"ç¦»æ•£å±æ€§" (categorical attribute)ï¼Œå‰è€…åœ¨å®šä¹‰åŸŸä¸Šæœ‰æ— ç©·å¤šä¸ªå¯èƒ½çš„å–å€¼ï¼Œåè€…åœ¨å®šä¹‰åŸŸä¸Šæ˜¯æœ‰é™ä¸ªå–å€¼.

- è‹¥å±æ€§å€¼ä¹‹é—´å­˜åœ¨åºå…³ç³»ï¼Œåˆ™å¯ä»¥å°†å…¶è½¬åŒ–ä¸ºè¿ç»­å€¼ï¼Œä¾‹å¦‚ï¼šèº«é«˜å±æ€§â€œé«˜â€â€œä¸­ç­‰â€â€œçŸ®â€ï¼Œå¯è½¬åŒ–ä¸º{1, 0.5, 0}ã€‚
- è‹¥å±æ€§å€¼ä¹‹é—´ä¸å­˜åœ¨åºå…³ç³»ï¼Œåˆ™é€šå¸¸å°†å…¶è½¬åŒ–ä¸ºå‘é‡çš„å½¢å¼ï¼Œä¾‹å¦‚ï¼šæ€§åˆ«å±æ€§â€œç”·â€,â€œå¥³â€ï¼Œå¯è½¬åŒ–ä¸º{(1,0), (0,1)}ã€‚



### 3. kå€¼çš„é€‰æ‹©

**Kå€¼è¿‡å°**: å®¹æ˜“å—åˆ°å¼‚å¸¸ç‚¹çš„å½±å“, **Kå€¼çš„å‡å°æ„å‘³ç€æ•´ä½“æ¨¡å‹å˜å¾—å¤æ‚ï¼Œå®¹æ˜“å‘ç”Ÿè¿‡æ‹Ÿåˆ**

**kå€¼è¿‡å¤§**: å—åˆ°æ ·æœ¬å‡è¡¡çš„é—®é¢˜, **Kå€¼çš„å¢å¤§æ„å‘³ç€æ•´ä½“çš„æ¨¡å‹å˜å¾—ç®€å•**

åœ¨**å®é™…åº”ç”¨ä¸­ï¼ŒKå€¼ä¸€èˆ¬å–ä¸€ä¸ªæ¯”è¾ƒå°çš„æ•°å€¼**ï¼Œä¾‹å¦‚é‡‡ç”¨äº¤å‰éªŒè¯æ³•æ¥é€‰æ‹©æœ€ä¼˜çš„Kå€¼ã€‚



### 4. kdæ ‘

æ ¹æ®**KNN**æ¯æ¬¡éœ€è¦é¢„æµ‹ä¸€ä¸ªç‚¹æ—¶ï¼Œæˆ‘ä»¬éƒ½éœ€è¦è®¡ç®—è®­ç»ƒæ•°æ®é›†é‡Œæ¯ä¸ªç‚¹åˆ°è¿™ä¸ªç‚¹çš„è·ç¦»ï¼Œç„¶åé€‰å‡ºè·ç¦»æœ€è¿‘çš„kä¸ªç‚¹è¿›è¡ŒæŠ•ç¥¨ã€‚**å½“æ•°æ®é›†å¾ˆå¤§æ—¶ï¼Œè¿™ä¸ªè®¡ç®—æˆæœ¬éå¸¸é«˜ï¼Œé’ˆå¯¹Nä¸ªæ ·æœ¬ï¼ŒDä¸ªç‰¹å¾çš„æ•°æ®é›†ï¼Œå…¶ç®—æ³•å¤æ‚åº¦ä¸º** ![equation5](./img/equation5.svg) ã€‚

**kdæ ‘**ï¼šä¸ºäº†é¿å…æ¯æ¬¡éƒ½é‡æ–°è®¡ç®—ä¸€éè·ç¦»ï¼Œç®—æ³•ä¼šæŠŠè·ç¦»ä¿¡æ¯ä¿å­˜åœ¨ä¸€æ£µæ ‘é‡Œï¼Œè¿™æ ·åœ¨è®¡ç®—ä¹‹å‰ä»æ ‘é‡ŒæŸ¥è¯¢è·ç¦»ä¿¡æ¯ï¼Œå°½é‡é¿å…é‡æ–°è®¡ç®—ã€‚å…¶åŸºæœ¬åŸç†æ˜¯ï¼Œ**å¦‚æœAå’ŒBè·ç¦»å¾ˆè¿œï¼ŒBå’ŒCè·ç¦»å¾ˆè¿‘ï¼Œé‚£ä¹ˆAå’ŒCçš„è·ç¦»ä¹Ÿå¾ˆè¿œ**ã€‚æœ‰äº†è¿™ä¸ªä¿¡æ¯ï¼Œå°±å¯ä»¥åœ¨åˆé€‚çš„æ—¶å€™è·³è¿‡è·ç¦»è¿œçš„ç‚¹ã€‚è¿™æ ·ä¼˜åŒ–åçš„ç®—æ³•å¤æ‚åº¦å¯é™ä½åˆ°  ![equation6](./img/equation6.svg)ã€‚

1989å¹´ï¼Œå¦å¤–ä¸€ç§ç§°ä¸º**Ball Tree**çš„ç®—æ³•ï¼Œåœ¨kd Treeçš„åŸºç¡€ä¸Šå¯¹æ€§èƒ½è¿›ä¸€æ­¥è¿›è¡Œäº†ä¼˜åŒ–ã€‚

#### 4.1 æ„é€ æ–¹æ³•

1. **æ„é€ æ ¹ç»“ç‚¹ï¼Œä½¿æ ¹ç»“ç‚¹å¯¹åº”äºKç»´ç©ºé—´ä¸­åŒ…å«æ‰€æœ‰å®ä¾‹ç‚¹çš„è¶…çŸ©å½¢åŒºåŸŸï¼›**
2. **é€šè¿‡é€’å½’çš„æ–¹æ³•ï¼Œä¸æ–­åœ°å¯¹kç»´ç©ºé—´è¿›è¡Œåˆ‡åˆ†ï¼Œç”Ÿæˆå­ç»“ç‚¹ã€‚**åœ¨è¶…çŸ©å½¢åŒºåŸŸä¸Šé€‰æ‹©ä¸€ä¸ªåæ ‡è½´å’Œåœ¨æ­¤åæ ‡è½´ä¸Šçš„ä¸€ä¸ªåˆ‡åˆ†ç‚¹ï¼Œç¡®å®šä¸€ä¸ªè¶…å¹³é¢ï¼Œè¿™ä¸ªè¶…å¹³é¢é€šè¿‡é€‰å®šçš„åˆ‡åˆ†ç‚¹å¹¶å‚ç›´äºé€‰å®šçš„åæ ‡è½´ï¼Œå°†å½“å‰è¶…çŸ©å½¢åŒºåŸŸåˆ‡åˆ†ä¸ºå·¦å³ä¸¤ä¸ªå­åŒºåŸŸï¼ˆå­ç»“ç‚¹ï¼‰ï¼›è¿™æ—¶ï¼Œå®ä¾‹è¢«åˆ†åˆ°ä¸¤ä¸ªå­åŒºåŸŸã€‚
3. **ä¸Šè¿°è¿‡ç¨‹ç›´åˆ°å­åŒºåŸŸå†…æ²¡æœ‰å®ä¾‹æ—¶ç»ˆæ­¢ï¼ˆç»ˆæ­¢æ—¶çš„ç»“ç‚¹ä¸ºå¶ç»“ç‚¹ï¼‰**ã€‚åœ¨æ­¤è¿‡ç¨‹ä¸­ï¼Œå°†å®ä¾‹ä¿å­˜åœ¨ç›¸åº”çš„ç»“ç‚¹ä¸Šã€‚

**åœ¨æ„å»ºKDæ ‘æ—¶ï¼Œå…³é”®éœ€è¦è§£å†³2ä¸ªé—®é¢˜**ï¼š

1. **é€‰æ‹©å‘é‡çš„å“ªä¸€ç»´è¿›è¡Œåˆ’åˆ†**: å¯ä»¥æ˜¯éšæœºé€‰æ‹©æŸä¸€ç»´æˆ–æŒ‰é¡ºåºé€‰æ‹©ï¼Œä½†æ˜¯**æ›´å¥½çš„æ–¹æ³•åº”è¯¥æ˜¯åœ¨æ•°æ®æ¯”è¾ƒåˆ†æ•£çš„é‚£ä¸€ç»´è¿›è¡Œåˆ’åˆ†ï¼ˆåˆ†æ•£çš„ç¨‹åº¦å¯ä»¥æ ¹æ®æ–¹å·®æ¥è¡¡é‡ï¼‰**ã€‚
2. **å¦‚ä½•åˆ’åˆ†æ•°æ®**: é€‰æ‹©è®­ç»ƒå®ä¾‹ç‚¹åœ¨åæ ‡è½´ä¸Šçš„ä¸­ä½æ•°ä¸ºåˆ‡åˆ†ç‚¹ï¼Œè¿™æ ·å¾—åˆ°çš„kdæ ‘æ˜¯å¹³è¡¡çš„ï¼ˆå¹³è¡¡äºŒå‰æ ‘ï¼šå®ƒæ˜¯ä¸€æ£µç©ºæ ‘ï¼Œæˆ–å…¶å·¦å­æ ‘å’Œå³å­æ ‘çš„æ·±åº¦ä¹‹å·®çš„ç»å¯¹å€¼ä¸è¶…è¿‡1ï¼Œä¸”å®ƒçš„å·¦å­æ ‘å’Œå³å­æ ‘éƒ½æ˜¯å¹³è¡¡äºŒå‰æ ‘ï¼‰ã€‚

#### 4.2 kdæ ‘çš„æœç´¢è¿‡ç¨‹

1. **äºŒå‰æ ‘æœç´¢æ¯”è¾ƒå¾…æŸ¥è¯¢èŠ‚ç‚¹å’Œåˆ†è£‚èŠ‚ç‚¹çš„åˆ†è£‚ç»´çš„å€¼**, (å°äºç­‰äºå°±è¿›å…¥å·¦å­æ ‘åˆ†æ”¯ï¼Œå¤§äºå°±è¿›å…¥å³å­æ ‘åˆ†æ”¯ç›´åˆ°å¶å­ç»“ç‚¹)
2. **é¡ºç€â€œæœç´¢è·¯å¾„â€æ‰¾åˆ°æœ€è¿‘é‚»çš„è¿‘ä¼¼ç‚¹**
3. **å›æº¯æœç´¢è·¯å¾„**ï¼Œå¹¶åˆ¤æ–­æœç´¢è·¯å¾„ä¸Šçš„ç»“ç‚¹çš„å…¶ä»–å­ç»“ç‚¹ç©ºé—´ä¸­æ˜¯å¦å¯èƒ½æœ‰è·ç¦»æŸ¥è¯¢ç‚¹æ›´è¿‘çš„æ•°æ®ç‚¹ï¼Œå¦‚æœæœ‰å¯èƒ½ï¼Œåˆ™éœ€è¦è·³åˆ°å…¶ä»–å­ç»“ç‚¹ç©ºé—´ä¸­å»æœç´¢
4. **é‡å¤è¿™ä¸ªè¿‡ç¨‹ç›´åˆ°æœç´¢è·¯å¾„ä¸ºç©º**



### 5. æ¡ˆä¾‹ï¼šé¸¢å°¾èŠ±ç§ç±»é¢„æµ‹

Irisæ•°æ®é›†æ˜¯å¸¸ç”¨çš„åˆ†ç±»å®éªŒæ•°æ®é›†ï¼Œç”±Fisher, 1936æ”¶é›†æ•´ç†ã€‚Irisä¹Ÿç§°é¸¢å°¾èŠ±å‰æ•°æ®é›†ï¼Œæ˜¯ä¸€ç±»å¤šé‡å˜é‡åˆ†æçš„æ•°æ®é›†ã€‚

**æ­¥éª¤åˆ†æ**

1. è·å–æ•°æ®é›†
2. æ•°æ®åŸºæœ¬å¤„ç†
3. ç‰¹å¾å·¥ç¨‹
4. æœºå™¨å­¦ä¹ (æ¨¡å‹è®­ç»ƒ)
5. æ¨¡å‹è¯„ä¼°

#### 5.1 scikit-learnæ•°æ®é›†APIä»‹ç»

##### 5.1.1 sklearn.datasets: åŠ è½½è·å–æµè¡Œæ•°æ®é›†

- datasets.load_*() : è·å–å°è§„æ¨¡æ•°æ®é›†ï¼Œæ•°æ®åŒ…å«åœ¨datasetsé‡Œ

~~~ python
sklearn.datasets.load_iris()
~~~

- datasets.fetch_*(data_home=None, subset=â€˜trainâ€™) : è·å–å¤§è§„æ¨¡æ•°æ®é›†ï¼Œéœ€è¦ä»ç½‘ç»œä¸Šä¸‹è½½ï¼Œ`data_home`è¡¨ç¤ºæ•°æ®é›†ä¸‹è½½çš„ç›®å½• ,é»˜è®¤æ˜¯ `~/scikit_learn_data/`; `subset`: è¡¨ç¤ºé€‰æ‹©è¦åŠ è½½çš„æ•°æ®é›†, 'train', 'test', 'all'ã€‚

~~~ python
sklearn.datasets.fetch_20newsgroups(data_home=None,subset=â€˜trainâ€™)
~~~



##### 5.1.2  sklearnæ•°æ®é›†è¿”å›å€¼ä»‹ç»

load å’Œ fetch è¿”å›çš„æ•°æ®ç±»å‹datasets.base.Bunch(å­—å…¸æ ¼å¼)

- dataï¼šç‰¹å¾æ•°æ®æ•°ç»„ï¼Œæ˜¯ [n_samples * n_features] çš„äºŒç»´ numpy.ndarray æ•°ç»„
- targetï¼šæ ‡ç­¾æ•°ç»„ï¼Œæ˜¯ n_samples çš„ä¸€ç»´ numpy.ndarray æ•°ç»„
- DESCRï¼šæ•°æ®æè¿°
- feature_namesï¼šç‰¹å¾å, æ–°é—»æ•°æ®,æ‰‹å†™æ•°å­—,å›å½’æ•°æ®é›†æ²¡æœ‰
- target_namesï¼šæ ‡ç­¾å



##### 5.1.3 æŸ¥çœ‹æ•°æ®åˆ†å¸ƒ

~~~ python
import seaborn as sns
import matplotlib.pyplot as plt
import pandas as pd
from sklearn.datasets import load_iris


iris = load_iris()
# æŠŠæ•°æ®è½¬æ¢æˆdataframeçš„æ ¼å¼
iris_d = pd.DataFrame(iris['data'], columns = ['Sepal_Length', 'Sepal_Width', 'Petal_Length', 'Petal_Width'])
iris_d['Species'] = iris.target
sns.lmplot(x = 'Petal_Width', y =  'Sepal_Length', data = iris_d, hue = "Species", fit_reg = False)
plt.title('é¸¢å°¾èŠ±ç§ç±»åˆ†å¸ƒå›¾')
plt.show()
~~~

![v2-22d9fd31b1cf38ea0b802a1b012cf9ba_b](./img/v2-22d9fd31b1cf38ea0b802a1b012cf9ba_b.jpg)



#### 5.2 æ•°æ®é›†çš„åˆ’åˆ†

æœºå™¨å­¦ä¹ ä¸€èˆ¬çš„æ•°æ®é›†ä¼šåˆ’åˆ†ä¸ºä¸¤ä¸ªéƒ¨åˆ†ï¼š

- è®­ç»ƒæ•°æ®ï¼šç”¨äºè®­ç»ƒï¼Œ**æ„å»ºæ¨¡å‹**
- æµ‹è¯•æ•°æ®ï¼šåœ¨æ¨¡å‹æ£€éªŒæ—¶ä½¿ç”¨ï¼Œç”¨äº**è¯„ä¼°æ¨¡å‹æ˜¯å¦æœ‰æ•ˆ**

åˆ’åˆ†æ¯”ä¾‹ï¼š

- è®­ç»ƒé›†ï¼š70% 80% 75%
- æµ‹è¯•é›†ï¼š30% 20% 25%

**æ•°æ®é›†åˆ’åˆ†api**: `sklearn.model_selection.train_test_split(arrays, *options)`

- å‚æ•°ï¼š

- - x æ•°æ®é›†çš„ç‰¹å¾å€¼
  - y æ•°æ®é›†çš„æ ‡ç­¾å€¼
  - test_size æµ‹è¯•é›†çš„å¤§å°ï¼Œä¸€èˆ¬ä¸ºfloat
  - random_state éšæœºæ•°ç§å­,ä¸åŒçš„ç§å­ä¼šé€ æˆä¸åŒçš„éšæœºé‡‡æ ·ç»“æœã€‚ç›¸åŒçš„ç§å­é‡‡æ ·ç»“æœç›¸åŒã€‚

- return

- - x_train, x_test, y_train, y_test

~~~ python
from sklearn.datasets import load_iris
from sklearn.model_selection import train_test_split

# 1ã€è·å–é¸¢å°¾èŠ±æ•°æ®é›†
iris = load_iris()
# å¯¹é¸¢å°¾èŠ±æ•°æ®é›†è¿›è¡Œåˆ†å‰²
x_train, x_test, y_train, y_test = train_test_split(iris.data, iris.target, random_state=22)
print("x_train:\n", x_train.shape)
~~~



#### 5.3 ç‰¹å¾å·¥ç¨‹-ç‰¹å¾é¢„å¤„ç†

ç‰¹å¾é¢„å¤„ç†: é€šè¿‡**ä¸€äº›è½¬æ¢å‡½æ•°**å°†ç‰¹å¾æ•°æ®**è½¬æ¢æˆæ›´åŠ é€‚åˆç®—æ³•æ¨¡å‹**çš„ç‰¹å¾æ•°æ®è¿‡ç¨‹

**ç‰¹å¾é¢„å¤„ç†API**: `sklearn.preprocessing`

##### 5.3.1 å½’ä¸€åŒ–

é€šè¿‡å¯¹åŸå§‹æ•°æ®è¿›è¡Œå˜æ¢æŠŠæ•°æ®æ˜ å°„åˆ°(é»˜è®¤ä¸º[0,1])ä¹‹é—´ 

![equation7](./img/equation7.svg)

![equation8](./img/equation8.svg)

>  ä½œç”¨äºæ¯ä¸€åˆ—ï¼Œmaxä¸ºä¸€åˆ—çš„æœ€å¤§å€¼ï¼Œminä¸ºä¸€åˆ—çš„æœ€å°å€¼,é‚£ä¹ˆXâ€™â€™ä¸ºæœ€ç»ˆç»“æœï¼Œmxï¼Œmiåˆ†åˆ«ä¸ºæŒ‡å®šåŒºé—´å€¼é»˜è®¤mxä¸º1,miä¸º0

**sklearn.preprocessing.MinMaxScaler(feature_range=(0,1)â€¦ )**

- MinMaxScalar.fit_transform(X)
- X: numpy array æ ¼å¼çš„æ•°æ® [n_samples, n_features]
- è¿”å›å€¼ï¼šè½¬æ¢åçš„å½¢çŠ¶ç›¸åŒçš„array

æœ€å¤§å€¼ä¸æœ€å°å€¼éå¸¸å®¹æ˜“å—å¼‚å¸¸ç‚¹å½±å“ï¼Œ**æ‰€ä»¥å½’ä¸€åŒ–æ–¹æ³•é²æ£’æ€§è¾ƒå·®ï¼Œåªé€‚åˆä¼ ç»Ÿç²¾ç¡®å°æ•°æ®åœºæ™¯ã€‚**



##### 5.3.2 æ ‡å‡†åŒ–

é€šè¿‡å¯¹åŸå§‹æ•°æ®è¿›è¡Œå˜æ¢æŠŠæ•°æ®å˜æ¢åˆ°å‡å€¼ä¸º0,æ ‡å‡†å·®ä¸º1èŒƒå›´å†… $$ X^{\prime}=\frac{x-\text { mean }}{\sigma} $$

 ä½œç”¨äºæ¯ä¸€åˆ—ï¼Œmeanä¸ºå¹³å‡å€¼ï¼ŒÏƒä¸ºæ ‡å‡†å·®

**sklearn.preprocessing.StandardScaler( )**

- å¤„ç†ä¹‹åæ¯åˆ—æ¥è¯´æ‰€æœ‰æ•°æ®éƒ½èšé›†åœ¨å‡å€¼0é™„è¿‘æ ‡å‡†å·®å·®ä¸º1
- StandardScaler.fit_transform(X)
- X: numpy array æ ¼å¼çš„æ•°æ® [n_samples,n_features]
- è¿”å›å€¼ï¼šè½¬æ¢åçš„å½¢çŠ¶ç›¸åŒçš„array

åœ¨å·²æœ‰æ ·æœ¬è¶³å¤Ÿå¤šçš„æƒ…å†µä¸‹æ¯”è¾ƒç¨³å®šï¼Œé€‚åˆç°ä»£å˜ˆæ‚å¤§æ•°æ®åœºæ™¯ã€‚



#### 5.4 K-è¿‘é‚»ç®—æ³•API

**sklearn.neighbors.KNeighborsClassifier(n_neighbors=5,algorithm='auto')**

**n_neighbors**ï¼šint,å¯é€‰ï¼ˆé»˜è®¤= 5ï¼‰ï¼Œk_neighborsæŸ¥è¯¢é»˜è®¤ä½¿ç”¨çš„é‚»å±…æ•°

**algorithm**ï¼š{â€˜autoâ€™ï¼Œâ€˜ball_treeâ€™ï¼Œâ€˜kd_treeâ€™ï¼Œâ€˜bruteâ€™}

- å¿«é€Ÿkè¿‘é‚»æœç´¢ç®—æ³•ï¼Œé»˜è®¤å‚æ•°ä¸ºautoï¼Œå¯ä»¥ç†è§£ä¸ºç®—æ³•è‡ªå·±å†³å®šåˆé€‚çš„æœç´¢ç®—æ³•ã€‚é™¤æ­¤ä¹‹å¤–ï¼Œç”¨æˆ·ä¹Ÿå¯ä»¥è‡ªå·±æŒ‡å®šæœç´¢ç®—æ³•ball_treeã€kd_treeã€bruteæ–¹æ³•è¿›è¡Œæœç´¢ï¼Œ
- bruteæ˜¯è›®åŠ›æœç´¢ï¼Œä¹Ÿå°±æ˜¯çº¿æ€§æ‰«æï¼Œå½“è®­ç»ƒé›†å¾ˆå¤§æ—¶ï¼Œè®¡ç®—éå¸¸è€—æ—¶ã€‚
- kd_treeï¼Œæ„é€ kdæ ‘å­˜å‚¨æ•°æ®ä»¥ä¾¿å¯¹å…¶è¿›è¡Œå¿«é€Ÿæ£€ç´¢çš„æ ‘å½¢æ•°æ®ç»“æ„ï¼Œkdæ ‘ä¹Ÿå°±æ˜¯æ•°æ®ç»“æ„ä¸­çš„äºŒå‰æ ‘ã€‚ä»¥ä¸­å€¼åˆ‡åˆ†æ„é€ çš„æ ‘ï¼Œæ¯ä¸ªç»“ç‚¹æ˜¯ä¸€ä¸ªè¶…çŸ©å½¢ï¼Œåœ¨ç»´æ•°å°äº20æ—¶æ•ˆç‡é«˜ã€‚
- ball treeæ˜¯ä¸ºäº†å…‹æœkdæ ‘é«˜ç»´å¤±æ•ˆè€Œå‘æ˜çš„ï¼Œå…¶æ„é€ è¿‡ç¨‹æ˜¯ä»¥è´¨å¿ƒCå’ŒåŠå¾„råˆ†å‰²æ ·æœ¬ç©ºé—´ï¼Œæ¯ä¸ªèŠ‚ç‚¹æ˜¯ä¸€ä¸ªè¶…çƒä½“ã€‚

~~~ python
from sklearn.datasets import load_iris
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.neighbors import KNeighborsClassifier

def knn_iris():
    """
    ç”¨KNNç®—æ³•å¯¹é¸¢å°¾èŠ±è¿›è¡Œåˆ†ç±»
    :return:
    """
    # 1ï¼‰è·å–æ•°æ®
    iris = load_iris()

    # 2ï¼‰åˆ’åˆ†æ•°æ®é›†
    x_train, x_test, y_train, y_test = train_test_split(iris.data, iris.target, random_state=22)

    # 3ï¼‰ç‰¹å¾å·¥ç¨‹ï¼šæ ‡å‡†åŒ–
    transfer = StandardScaler()
    x_train = transfer.fit_transform(x_train)
    x_test = transfer.transform(x_test)

    # 4ï¼‰KNNç®—æ³•é¢„ä¼°å™¨
    estimator = KNeighborsClassifier(n_neighbors=3)
    estimator.fit(x_train, y_train)

    # 5ï¼‰æ¨¡å‹è¯„ä¼°
    # æ–¹æ³•1ï¼šç›´æ¥æ¯”å¯¹çœŸå®å€¼å’Œé¢„æµ‹å€¼
    y_predict = estimator.predict(x_test)
    print("y_predict:\n", y_predict)
    print("ç›´æ¥æ¯”å¯¹çœŸå®å€¼å’Œé¢„æµ‹å€¼:\n", y_test == y_predict)

    # æ–¹æ³•2ï¼šè®¡ç®—å‡†ç¡®ç‡
    score = estimator.score(x_test, y_test)
    print("å‡†ç¡®ç‡ä¸ºï¼š\n", score)

    return None

y_predict:
 [0 2 1 2 1 1 1 2 1 0 2 1 2 2 0 2 1 1 1 1 0 2 0 1 2 0 2 2 2 2 0 0 1 1 1 0 0 0]
ç›´æ¥æ¯”å¯¹çœŸå®å€¼å’Œé¢„æµ‹å€¼:
 [ True  True  True  True  True  True  True  True  True  True  True  True
  True  True  True  True  True  True False  True  True  True  True  True
  True  True  True  True  True  True  True  True  True  True  True  True
  True  True]
å‡†ç¡®ç‡ä¸ºï¼š
 0.9736842105263158
~~~



### 6. KNNç®—æ³•æ€»ç»“

#### 6.1ä¼˜ç‚¹

- **ç®€å•æœ‰æ•ˆ**
- **é‡æ–°è®­ç»ƒçš„ä»£ä»·ä½**
- **é€‚åˆç±»åŸŸäº¤å‰æ ·æœ¬**
- **KNNæ–¹æ³•ä¸»è¦é å‘¨å›´æœ‰é™çš„é‚»è¿‘çš„æ ·æœ¬**,è€Œä¸æ˜¯é åˆ¤åˆ«ç±»åŸŸçš„æ–¹æ³•æ¥ç¡®å®šæ‰€å±ç±»åˆ«çš„ï¼Œå› æ­¤å¯¹äºç±»åŸŸçš„äº¤å‰æˆ–é‡å è¾ƒå¤šçš„å¾…åˆ†æ ·æœ¬é›†æ¥è¯´ï¼ŒKNNæ–¹æ³•è¾ƒå…¶ä»–æ–¹æ³•æ›´ä¸ºé€‚åˆã€‚
- **é€‚åˆå¤§æ ·æœ¬è‡ªåŠ¨åˆ†ç±»**
- è¯¥ç®—æ³•æ¯”è¾ƒ**é€‚ç”¨äºæ ·æœ¬å®¹é‡æ¯”è¾ƒå¤§çš„ç±»åŸŸçš„è‡ªåŠ¨åˆ†ç±»**ï¼Œè€Œé‚£äº›**æ ·æœ¬å®¹é‡è¾ƒå°çš„ç±»åŸŸé‡‡ç”¨è¿™ç§ç®—æ³•æ¯”è¾ƒå®¹æ˜“äº§ç”Ÿè¯¯åˆ†**ã€‚



#### 6.2 ç¼ºç‚¹

- **æƒ°æ€§å­¦ä¹ **
- KNNç®—æ³•æ˜¯æ‡’æ•£å­¦ä¹ æ–¹æ³•ï¼ˆlazy learning,åŸºæœ¬ä¸Šä¸å­¦ä¹ ï¼‰ï¼Œä¸€äº›ç§¯æå­¦ä¹ çš„ç®—æ³•è¦å¿«å¾ˆå¤š
- **ç±»åˆ«è¯„åˆ†ä¸æ˜¯è§„æ ¼åŒ–**
- ä¸åƒä¸€äº›é€šè¿‡æ¦‚ç‡è¯„åˆ†çš„åˆ†ç±»
- **è¾“å‡ºå¯è§£é‡Šæ€§ä¸å¼º**
- ä¾‹å¦‚å†³ç­–æ ‘çš„è¾“å‡ºå¯è§£é‡Šæ€§å°±è¾ƒå¼º
- **å¯¹ä¸å‡è¡¡çš„æ ·æœ¬ä¸æ“…é•¿**
- å½“æ ·æœ¬ä¸å¹³è¡¡æ—¶ï¼Œå¦‚ä¸€ä¸ªç±»çš„æ ·æœ¬å®¹é‡å¾ˆå¤§ï¼Œè€Œå…¶ä»–ç±»æ ·æœ¬å®¹é‡å¾ˆå°æ—¶ï¼Œæœ‰å¯èƒ½å¯¼è‡´å½“è¾“å…¥ä¸€ä¸ªæ–°æ ·æœ¬æ—¶ï¼Œè¯¥æ ·æœ¬çš„Kä¸ªé‚»å±…ä¸­å¤§å®¹é‡ç±»çš„æ ·æœ¬å å¤šæ•°ã€‚è¯¥ç®—æ³•åªè®¡ç®—â€œæœ€è¿‘çš„â€é‚»å±…æ ·æœ¬ï¼ŒæŸä¸€ç±»çš„æ ·æœ¬æ•°é‡å¾ˆå¤§ï¼Œé‚£ä¹ˆæˆ–è€…è¿™ç±»æ ·æœ¬å¹¶ä¸æ¥è¿‘ç›®æ ‡æ ·æœ¬ï¼Œæˆ–è€…è¿™ç±»æ ·æœ¬å¾ˆé è¿‘ç›®æ ‡æ ·æœ¬ã€‚æ— è®ºæ€æ ·ï¼Œæ•°é‡å¹¶ä¸èƒ½å½±å“è¿è¡Œç»“æœã€‚å¯ä»¥é‡‡ç”¨æƒå€¼çš„æ–¹æ³•ï¼ˆå’Œè¯¥æ ·æœ¬è·ç¦»å°çš„é‚»å±…æƒå€¼å¤§ï¼‰æ¥æ”¹è¿›ã€‚
- **è®¡ç®—é‡è¾ƒå¤§**
- ç›®å‰å¸¸ç”¨çš„è§£å†³æ–¹æ³•æ˜¯äº‹å…ˆå¯¹å·²çŸ¥æ ·æœ¬ç‚¹è¿›è¡Œå‰ªè¾‘ï¼Œäº‹å…ˆå»é™¤å¯¹åˆ†ç±»ä½œç”¨ä¸å¤§çš„æ ·æœ¬ã€‚



### 7. æ¨¡å‹é€‰æ‹©ä¸è°ƒä¼˜

#### 7.1 äº¤å‰éªŒè¯

- **ç›®çš„ï¼š****ä¸ºäº†è®©è¢«è¯„ä¼°çš„æ¨¡å‹æ›´åŠ å‡†ç¡®å¯ä¿¡**
- **å®šä¹‰**ï¼šå°†æ‹¿åˆ°çš„è®­ç»ƒæ•°æ®ï¼Œåˆ†ä¸ºè®­ç»ƒå’ŒéªŒè¯é›†ã€‚ä»¥ä¸‹å›¾ä¸ºä¾‹ï¼šå°†æ•°æ®åˆ†æˆ5ä»½ï¼Œå…¶ä¸­ä¸€ä»½ä½œä¸ºéªŒè¯é›†ã€‚ç„¶åç»è¿‡5æ¬¡(ç»„)çš„æµ‹è¯•ï¼Œæ¯æ¬¡éƒ½æ›´æ¢ä¸åŒçš„éªŒè¯é›†ã€‚å³å¾—åˆ°5ç»„æ¨¡å‹çš„ç»“æœï¼Œå–å¹³å‡å€¼ä½œä¸ºæœ€ç»ˆç»“æœã€‚åˆç§°5æŠ˜äº¤å‰éªŒè¯ã€‚

æˆ‘ä»¬ä¹‹å‰çŸ¥é“æ•°æ®åˆ†ä¸ºè®­ç»ƒé›†å’Œæµ‹è¯•é›†ï¼Œä½†æ˜¯**ä¸ºäº†è®©ä»è®­ç»ƒå¾—åˆ°æ¨¡å‹ç»“æœæ›´åŠ å‡†ç¡®ã€‚**åšä»¥ä¸‹å¤„ç†

- è®­ç»ƒé›†ï¼šè®­ç»ƒé›†+éªŒè¯é›†
- æµ‹è¯•é›†ï¼šæµ‹è¯•é›†

![image23](./img/image23.png)

**é—®é¢˜ï¼š**é‚£ä¹ˆè¿™ä¸ªåªæ˜¯å¯¹äºå‚æ•°å¾—å‡ºæ›´å¥½çš„ç»“æœï¼Œé‚£ä¹ˆæ€ä¹ˆé€‰æ‹©æˆ–è€…è°ƒä¼˜å‚æ•°å‘¢ï¼Ÿ



#### 7.2 è¶…å‚æ•°æœç´¢ - ç½‘æ ¼æœç´¢ (Grid Search)

é€šå¸¸æƒ…å†µä¸‹ï¼Œ**æœ‰å¾ˆå¤šå‚æ•°æ˜¯éœ€è¦æ‰‹åŠ¨æŒ‡å®šçš„ï¼ˆå¦‚k-è¿‘é‚»ç®—æ³•ä¸­çš„Kå€¼ï¼‰ï¼Œè¿™ç§å«è¶…å‚æ•°**ã€‚ä½†æ˜¯æ‰‹åŠ¨è¿‡ç¨‹ç¹æ‚ï¼Œæ‰€ä»¥éœ€è¦å¯¹æ¨¡å‹é¢„è®¾å‡ ç§è¶…å‚æ•°ç»„åˆã€‚**æ¯ç»„è¶…å‚æ•°éƒ½é‡‡ç”¨äº¤å‰éªŒè¯æ¥è¿›è¡Œè¯„ä¼°ã€‚æœ€åé€‰å‡ºæœ€ä¼˜å‚æ•°ç»„åˆå»ºç«‹æ¨¡å‹ã€‚**

![image24](./img/image24.png)

- API

- - sklearn.model_selection.GridSearchCV(estimator, param_grid=None,cv=None)

- - - å¯¹ä¼°è®¡å™¨çš„æŒ‡å®šå‚æ•°å€¼è¿›è¡Œè¯¦å°½æœç´¢
    - estimatorï¼šä¼°è®¡å™¨å¯¹è±¡
    - param_gridï¼šä¼°è®¡å™¨å‚æ•°(dict){â€œn_neighborsâ€:[1,3,5]}
    - cvï¼šæŒ‡å®šå‡ æŠ˜äº¤å‰éªŒè¯
    - fitï¼šè¾“å…¥è®­ç»ƒæ•°æ®
    - scoreï¼šå‡†ç¡®ç‡
    - FaceBookæ¡ˆä¾‹
    - ç»“æœåˆ†æï¼š

- - - - æœ€ä½³å‚æ•°ï¼šbest_params_
      - æœ€ä½³ç»“æœï¼šbest_score_
      - æœ€ä½³ä¼°è®¡å™¨ï¼šbest_estimator_
      - äº¤å‰éªŒè¯ç»“æœï¼šcv_results_

~~~ python
def knn_iris_gscv():
    """
    ç”¨KNNç®—æ³•å¯¹é¸¢å°¾èŠ±è¿›è¡Œåˆ†ç±»ï¼Œæ·»åŠ ç½‘æ ¼æœç´¢å’Œäº¤å‰éªŒè¯
    :return:
    """
    # 1ï¼‰è·å–æ•°æ®
    iris = load_iris()

    # 2ï¼‰åˆ’åˆ†æ•°æ®é›†
    x_train, x_test, y_train, y_test = train_test_split(iris.data, iris.target, random_state=22)

    # 3ï¼‰ç‰¹å¾å·¥ç¨‹ï¼šæ ‡å‡†åŒ–
    transfer = StandardScaler()
    x_train = transfer.fit_transform(x_train)
    x_test = transfer.transform(x_test)

    # 4ï¼‰KNNç®—æ³•é¢„ä¼°å™¨
    estimator = KNeighborsClassifier()

    # åŠ å…¥ç½‘æ ¼æœç´¢ä¸äº¤å‰éªŒè¯
    # å‚æ•°å‡†å¤‡
    param_dict = {"n_neighbors": [1, 3, 5, 7, 9, 11]}
    estimator = GridSearchCV(estimator, param_grid=param_dict, cv=10)
    estimator.fit(x_train, y_train)

    # 5ï¼‰æ¨¡å‹è¯„ä¼°
    # æ–¹æ³•1ï¼šç›´æ¥æ¯”å¯¹çœŸå®å€¼å’Œé¢„æµ‹å€¼
    y_predict = estimator.predict(x_test)
    print("y_predict:\n", y_predict)
    print("ç›´æ¥æ¯”å¯¹çœŸå®å€¼å’Œé¢„æµ‹å€¼:\n", y_test == y_predict)

    # æ–¹æ³•2ï¼šè®¡ç®—å‡†ç¡®ç‡
    score = estimator.score(x_test, y_test)
    print("å‡†ç¡®ç‡ä¸ºï¼š\n", score)

    # æœ€ä½³å‚æ•°ï¼šbest_params_
    print("æœ€ä½³å‚æ•°ï¼š\n", estimator.best_params_)
    # æœ€ä½³ç»“æœï¼šbest_score_
    print("æœ€ä½³ç»“æœï¼š\n", estimator.best_score_)
    # æœ€ä½³ä¼°è®¡å™¨ï¼šbest_estimator_
    print("æœ€ä½³ä¼°è®¡å™¨:\n", estimator.best_estimator_)
    # äº¤å‰éªŒè¯ç»“æœï¼šcv_results_
    print("äº¤å‰éªŒè¯ç»“æœ:\n", estimator.cv_results_)

    return None

y_predict:
 [0 2 1 2 1 1 1 2 1 0 2 1 2 2 0 2 1 1 1 1 0 2 0 1 2 0 2 2 2 2 0 0 1 1 1 0 0 0]
ç›´æ¥æ¯”å¯¹çœŸå®å€¼å’Œé¢„æµ‹å€¼:
 [ True  True  True  True  True  True  True  True  True  True  True  True
  True  True  True  True  True  True False  True  True  True  True  True
  True  True  True  True  True  True  True  True  True  True  True  True
  True  True]
å‡†ç¡®ç‡ä¸ºï¼š
 0.9736842105263158
æœ€ä½³å‚æ•°ï¼š
 {'n_neighbors': 3}
æœ€ä½³ç»“æœï¼š
 0.9553030303030303
æœ€ä½³ä¼°è®¡å™¨:
 KNeighborsClassifier(n_neighbors=3)
äº¤å‰éªŒè¯ç»“æœ:
 {'mean_fit_time': array([0.00089834, 0.00079894, 0.00080106, 0.0010052 , 0.00089417,
       0.00129735]), 'std_fit_time': array([0.00053816, 0.00039947, 0.00040058, 0.00044723, 0.0006968 ,
       0.00089766]), 'mean_score_time': array([0.00180643, 0.00180976, 0.00159762, 0.00139034, 0.00180302,
       0.00220156]), 'std_score_time': array([0.00075188, 0.00073786, 0.00048882, 0.00065752, 0.00059935,
       0.00107433]), 'param_n_neighbors': masked_array(data=[1, 3, 5, 7, 9, 11],
             mask=[False, False, False, False, False, False],
       fill_value='?',
            dtype=object), 'params': [{'n_neighbors': 1}, {'n_neighbors': 3}, {'n_neighbors': 5}, {'n_neighbors': 7}, {'n_neighbors': 9}, {'n_neighbors': 11}], 'split0_test_score': array([0.91666667, 0.91666667, 1.        , 1.        , 0.91666667,
       0.91666667]), 'split1_test_score': array([1., 1., 1., 1., 1., 1.]), 'split2_test_score': array([0.90909091, 0.90909091, 0.90909091, 0.90909091, 0.90909091,
       0.90909091]), 'split3_test_score': array([0.90909091, 1.        , 0.90909091, 0.90909091, 0.90909091,
       1.        ]), 'split4_test_score': array([1., 1., 1., 1., 1., 1.]), 'split5_test_score': array([0.90909091, 0.90909091, 0.90909091, 0.90909091, 0.90909091,
       0.90909091]), 'split6_test_score': array([0.90909091, 0.90909091, 0.90909091, 1.        , 1.        ,
       1.        ]), 'split7_test_score': array([0.90909091, 0.90909091, 0.81818182, 0.81818182, 0.81818182,
       0.81818182]), 'split8_test_score': array([1., 1., 1., 1., 1., 1.]), 'split9_test_score': array([1., 1., 1., 1., 1., 1.]), 'mean_test_score': array([0.94621212, 0.95530303, 0.94545455, 0.95454545, 0.94621212,
       0.95530303]), 'std_test_score': array([0.04397204, 0.0447483 , 0.06030227, 0.06098367, 0.05988683,
       0.0604591 ]), 'rank_test_score': array([4, 1, 6, 3, 4, 1])}
~~~



#### 7.3 ä¾‹é¢˜

![image25](./img/image25.png)

æ•°æ®ä»‹ç»ï¼šå°†æ ¹æ®ç”¨æˆ·çš„ä½ç½®ï¼Œå‡†ç¡®æ€§å’Œæ—¶é—´æˆ³é¢„æµ‹ç”¨æˆ·æ­£åœ¨æŸ¥çœ‹çš„ä¸šåŠ¡ã€‚

~~~ tex
train.csvï¼Œtest.csv 
row_idï¼šç™»è®°äº‹ä»¶çš„ID
xyï¼šåæ ‡
å‡†ç¡®æ€§ï¼šå®šä½å‡†ç¡®æ€§ 
æ—¶é—´ï¼šæ—¶é—´æˆ³
place_idï¼šä¸šåŠ¡çš„IDï¼Œè¿™æ˜¯æ‚¨é¢„æµ‹çš„ç›®æ ‡
~~~

> å®˜ç½‘ï¼šhttps://www.kaggle.com/navoshta/grid-knn/data

~~~ python
import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.neighbors import KNeighborsClassifier

"""
ç¼©å°æ•°æ®é›†èŒƒå›´
DataFrame.query()

å¤„ç†æ—¥æœŸæ•°æ®
pd.to_datetime
pd.DatetimeIndex

åˆ é™¤æ²¡ç”¨çš„æ—¥æœŸæ•°æ®
DataFrame.drop

å°†ç­¾åˆ°ä½ç½®å°‘äº n ä¸ªç”¨æˆ·çš„åˆ é™¤
place_count = data.groupby('place_id').count()
tf = place_count[place_count.row_id>3].reset_index()
data = data[data['place_id'].isin(tf.place_id)]

"""

def knncls():
    """
    Kè¿‘é‚»ç®—æ³•é¢„æµ‹å…¥ä½ä½ç½®ç±»åˆ«
    :return:
    """
    # ä¸€ã€å¤„ç†æ•°æ®ä»¥åŠç‰¹å¾å·¥ç¨‹
    # 1ã€è¯»å–æ”¶ï¼Œç¼©å°æ•°æ®çš„èŒƒå›´
    data = pd.read_csv("D:/Python3å¤©å¿«é€Ÿå…¥é—¨æœºå™¨å­¦é¡¹ç›®èµ„æ–™/æœºå™¨å­¦xiday2èµ„æ–™/02-ä»£ç /FBlocation/train.csv")

    # æ•°æ®é€»è¾‘ç­›é€‰æ“ä½œ df.query()
    data = data.query("x > 1.0 & x < 1.25 & y > 2.5 & y < 2.75")

    # åˆ é™¤timeè¿™ä¸€åˆ—ç‰¹å¾
    data = data.drop(['time'], axis=1)

    print(data)

    # åˆ é™¤å…¥ä½æ¬¡æ•°å°‘äºä¸‰æ¬¡ä½ç½®
    place_count = data.groupby('place_id').count()

    tf = place_count[place_count.row_id > 3].reset_index()

    data = data[data['place_id'].isin(tf.place_id)]

    # 3ã€å–å‡ºç‰¹å¾å€¼å’Œç›®æ ‡å€¼
    y = data['place_id']
    # y = data[['place_id']]

    x = data.drop(['place_id', 'row_id'], axis=1)

    # 4ã€æ•°æ®åˆ†å‰²ä¸ç‰¹å¾å·¥ç¨‹?

    # ï¼ˆ1ï¼‰ã€æ•°æ®åˆ†å‰²
    x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.3)

    # (2)ã€æ ‡å‡†åŒ–
    std = StandardScaler()

    # é˜Ÿè®­ç»ƒé›†è¿›è¡Œæ ‡å‡†åŒ–æ“ä½œ
    x_train = std.fit_transform(x_train)
    print(x_train)

    # è¿›è¡Œæµ‹è¯•é›†çš„æ ‡å‡†åŒ–æ“ä½œ
    x_test = std.fit_transform(x_test)

    # äºŒã€ç®—æ³•çš„è¾“å…¥è®­ç»ƒé¢„æµ‹
    # Kå€¼ï¼šç®—æ³•ä¼ å…¥å‚æ•°ä¸å®šçš„å€¼    ç†è®ºä¸Šï¼šk = æ ¹å·(æ ·æœ¬æ•°)
    # Kå€¼ï¼šåé¢ä¼šä½¿ç”¨å‚æ•°è°ƒä¼˜æ–¹æ³•ï¼Œå»è½®æµè¯•å‡ºæœ€å¥½çš„å‚æ•°[1,3,5,10,20,100,200]
    knn = KNeighborsClassifier(n_neighbors=1)

    # è°ƒç”¨fit()
    knn.fit(x_train, y_train)

    # é¢„æµ‹æµ‹è¯•æ•°æ®é›†ï¼Œå¾—å‡ºå‡†ç¡®ç‡
    y_predict = knn.predict(x_test)

    print("é¢„æµ‹æµ‹è¯•é›†ç±»åˆ«ï¼š", y_predict)

    print("å‡†ç¡®ç‡ä¸ºï¼š", knn.score(x_test, y_test))

    return None

# ç»“æœ
y_predict:
 [0 2 1 2 1 1 1 2 1 0 2 1 2 2 0 2 1 1 1 1 0 2 0 1 2 0 2 2 2 2 0 0 1 1 1 0 0 0]
ç›´æ¥æ¯”å¯¹çœŸå®å€¼å’Œé¢„æµ‹å€¼:
 [ True  True  True  True  True  True  True  True  True  True  True  True
  True  True  True  True  True  True False  True  True  True  True  True
  True  True  True  True  True  True  True  True  True  True  True  True
  True  True]
å‡†ç¡®ç‡ä¸ºï¼š
 0.9736842105263158
æœ€ä½³å‚æ•°ï¼š
 {'n_neighbors': 3}
æœ€ä½³ç»“æœï¼š
 0.9553030303030303
æœ€ä½³ä¼°è®¡å™¨:
 KNeighborsClassifier(n_neighbors=3)
äº¤å‰éªŒè¯ç»“æœ:
 {'mean_fit_time': array([0.00089834, 0.00079894, 0.00080106, 0.0010052 , 0.00089417,
       0.00129735]), 'std_fit_time': array([0.00053816, 0.00039947, 0.00040058, 0.00044723, 0.0006968 ,
       0.00089766]), 'mean_score_time': array([0.00180643, 0.00180976, 0.00159762, 0.00139034, 0.00180302,
       0.00220156]), 'std_score_time': array([0.00075188, 0.00073786, 0.00048882, 0.00065752, 0.00059935,
       0.00107433]), 'param_n_neighbors': masked_array(data=[1, 3, 5, 7, 9, 11],
             mask=[False, False, False, False, False, False],
       fill_value='?',
            dtype=object), 'params': [{'n_neighbors': 1}, {'n_neighbors': 3}, {'n_neighbors': 5}, {'n_neighbors': 7}, {'n_neighbors': 9}, {'n_neighbors': 11}], 'split0_test_score': array([0.91666667, 0.91666667, 1.        , 1.        , 0.91666667,
       0.91666667]), 'split1_test_score': array([1., 1., 1., 1., 1., 1.]), 'split2_test_score': array([0.90909091, 0.90909091, 0.90909091, 0.90909091, 0.90909091,
       0.90909091]), 'split3_test_score': array([0.90909091, 1.        , 0.90909091, 0.90909091, 0.90909091,
       1.        ]), 'split4_test_score': array([1., 1., 1., 1., 1., 1.]), 'split5_test_score': array([0.90909091, 0.90909091, 0.90909091, 0.90909091, 0.90909091,
       0.90909091]), 'split6_test_score': array([0.90909091, 0.90909091, 0.90909091, 1.        , 1.        ,
       1.        ]), 'split7_test_score': array([0.90909091, 0.90909091, 0.81818182, 0.81818182, 0.81818182,
       0.81818182]), 'split8_test_score': array([1., 1., 1., 1., 1., 1.]), 'split9_test_score': array([1., 1., 1., 1., 1., 1.]), 'mean_test_score': array([0.94621212, 0.95530303, 0.94545455, 0.95454545, 0.94621212,
       0.95530303]), 'std_test_score': array([0.04397204, 0.0447483 , 0.06030227, 0.06098367, 0.05988683,
       0.0604591 ]), 'rank_test_score': array([4, 1, 6, 3, 4, 1])}
~~~



## æœ´ç´ è´å¶æ–¯ç®—æ³•

- **å®šä¹‰ï¼š**é€šè¿‡æœ´ç´ è´å¶æ–¯ç®—æ³•å¾—å‡ºçš„åˆ†ç±»ç»“æœï¼Œå–æ¦‚ç‡å¤§çš„ä½œä¸ºæœ€ç»ˆçš„ç»“æœ

![image26](./img/image26.png)

![image27](./img/image27.png)

+ æ¦‚ç‡åŸºç¡€

![20190625221020254](./img/20190625221020254.png)

- æ¦‚ç‡ï¼šä¸€ä»¶äº‹æƒ…å‘ç”Ÿçš„å¯èƒ½æ€§ã€‚
- è”åˆæ¦‚ç‡å’Œæ¡ä»¶æ¦‚ç‡

- - è”åˆæ¦‚ç‡ï¼šåŒ…å«å¤šä¸ªæ¡ä»¶ï¼Œä¸”æ‰€æœ‰æ¡ä»¶åŒæ—¶æˆç«‹çš„æ¦‚ç‡

- - - è®°ä½œï¼šP(A,B)
    - ç‰¹æ€§ï¼šP(A, B) = P(A)P(B)

- - æ¡ä»¶æ¦‚ç‡ï¼šå°±æ˜¯äº‹ä»¶Aåœ¨å¦å¤–ä¸€ä¸ªäº‹ä»¶Bå·²ç»å‘ç”Ÿæ¡ä»¶ä¸‹çš„å‘ç”Ÿæ¦‚ç‡

- - - è®°ä½œï¼šP(A|B)
    - ç‰¹æ€§ï¼šP(A1,A2|B) = P(A1|B)P(A2|B)

> æ³¨æ„ï¼šæ­¤æ¡ä»¶æ¦‚ç‡çš„æˆç«‹ï¼Œ**æ˜¯ç”±äºA1,A2ç›¸äº’ç‹¬ç«‹çš„ç»“æœ**(è®°å¿†)

è¿™æ ·æˆ‘ä»¬è®¡ç®—ç»“æœä¸ºï¼š

~~~ tex
p(ç¨‹åºå‘˜, åŒ€ç§°) =  P(ç¨‹åºå‘˜)P(åŒ€ç§°) =3/7*(4/7) = 12/49 
P(äº§å“, è¶…é‡|å–œæ¬¢) = P(äº§å“|å–œæ¬¢)P(è¶…é‡|å–œæ¬¢)=1/2 *  1/4 = 1/8
~~~



### 1. è´å¶æ–¯å…¬å¼

- æœ´ç´ ï¼šå‡è®¾ç‰¹å¾ä¸å…¶ä»–ç‰¹å¾ä¹‹é—´ç›¸äº’ç‹¬ç«‹
- è´å¶æ–¯å…¬å¼

![img](https://cdn.nlark.com/yuque/__latex/78b4db2c2ecd5d100de47fb83d36656a.svg)



- - W ä¸ºç»™å®šæ–‡æ¡£çš„ç‰¹å¾å€¼ï¼ˆé¢‘æ•°ç»Ÿè®¡ã€é¢„æµ‹æ–‡æ¡£æä¾›ï¼‰ï¼ŒC ä¸ºæ–‡æ¡£ç±»åˆ«
  - å…¬å¼å¯ç†è§£ä¸ºï¼š![img](https://cdn.nlark.com/yuque/__latex/99b41357753d70f57fe6643e9ca1e278.svg)
  - P(C)ï¼šæ¯ä¸ªæ–‡æ¡£ç±»åˆ«çš„æ¦‚ç‡ï¼ˆæŸä¸ªæ–‡æ¡£ç±»åˆ«æ•°/æ€»æ–‡æ¡£æ•°é‡ï¼‰
  - P(W|C)ï¼šç»™å®šç±»åˆ«ä¸‹ç‰¹å¾ï¼ˆè¢«é¢„æµ‹æ–‡æ¡£ä¸­å‡ºç°çš„è¯ï¼‰çš„æ¦‚ç‡

- - - è®¡ç®—æ–¹æ³•ï¼šP(F1|C)=Ni/Nï¼ˆè®­ç»ƒæ–‡æ¡£ä¸­è®¡ç®—ï¼‰
    - Ni ä¸ºè¯¥ F1 è¯åœ¨ C ç±»æ‰€æœ‰æ–‡æ¡£ä¸­å‡ºç°çš„æ¬¡æ•°
    - N ä¸ºæ‰€å±ç±»Cä¸‹çš„æ–‡æ¡£æ‰€æœ‰è¯å‡ºç°çš„æ¬¡æ•°å’Œ

- - P(F1,F2...)ï¼šé¢„æµ‹æ–‡æ¡£ä¸­æ¯ä¸ªè¯çš„æ¦‚ç‡

- è®¡ç®—ç»“æœä¸º 0 æ—¶ï¼Œè§£å†³æ–¹æ³•ä¸ºæ‹‰æ™®æ‹‰æ–¯å¹³æ»‘ç³»æ•°

- - ![img](https://cdn.nlark.com/yuque/__latex/0c35cd991fb81dca09bdaf3adffba3ed.svg)
  - a ä¸ºæŒ‡å®šçš„ç³»æ•°ï¼Œä¸€èˆ¬ä¸º 1ï¼Œm ä¸ºè®­ç»ƒæ–‡æ¡£ä¸­ç»Ÿè®¡å‡ºçš„ç‰¹å¾è¯ä¸ªæ•°



### 2. æ–‡ç« åˆ†ç±»è®¡ç®—

å‡è®¾æˆ‘ä»¬ä»**è®­ç»ƒæ•°æ®é›†**å¾—åˆ°å¦‚ä¸‹ä¿¡æ¯

![image28](./img/image28.png)

è®¡ç®—ç»“æœ

~~~ tex
ç§‘æŠ€ï¼šP(ç§‘æŠ€|å½±é™¢,æ”¯ä»˜å®,äº‘è®¡ç®—) = ğ‘ƒ(å½±é™¢,æ”¯ä»˜å®,äº‘è®¡ç®—|ç§‘æŠ€)âˆ—P(ç§‘æŠ€)=(8/100)âˆ—(20/100)âˆ—(63/100)âˆ—(30/90) = 0.00456109
å¨±ä¹ï¼šP(å¨±ä¹|å½±é™¢,æ”¯ä»˜å®,äº‘è®¡ç®—) = ğ‘ƒ(å½±é™¢,æ”¯ä»˜å®,äº‘è®¡ç®—|å¨±ä¹)âˆ—P(å¨±ä¹)=(56/121)âˆ—(15/121)âˆ—(0/121)âˆ—(60/90) = 0
~~~

**é—®é¢˜ï¼š**æˆ‘ä»¬è®¡ç®—å‡ºæ¥æŸä¸ªæ¦‚ç‡ä¸º0ï¼Œåˆé€‚å—ï¼Ÿ



### 3. æ‹‰æ™®æ‹‰æ–¯å¹³æ»‘ç³»æ•°

- **ç›®çš„ï¼š**é˜²æ­¢è®¡ç®—å‡ºçš„åˆ†ç±»æ¦‚ç‡ä¸º0
- åº”ç”¨åœºæ™¯ï¼šæ–‡æœ¬åˆ†ç±»ã€å•è¯ä½œä¸ºç‰¹å¾

Niï¼šè¯¥ F1 è¯åœ¨ Cç±»åˆ«æ‰€æœ‰æ–‡æ¡£ä¸­å‡ºç°çš„æ¬¡æ•°
Nï¼šæ‰€å±ç±»åˆ« C ä¸‹çš„æ–‡æ¡£æ‰€æœ‰è¯å‡ºç°çš„æ¬¡æ•°å’Œ

![image29](./img/image29.png)

~~~ tex
P(å¨±ä¹|å½±é™¢,æ”¯ä»˜å®,äº‘è®¡ç®—) =P(å½±é™¢,æ”¯ä»˜å®,äº‘è®¡ç®—|å¨±ä¹)P(å¨±ä¹) =P(å½±é™¢|å¨±ä¹)*P(æ”¯ä»˜å®|å¨±ä¹)*P(äº‘è®¡ç®—|å¨±ä¹)P(å¨±ä¹)=(56+1/121+4)(15+1/121+4)(0+1/121+1*4)(60/90) = 0.00002
~~~

- API

- - sklearn.naive_bayes.MultinomialNB(alpha = 1.0)

- - - æœ´ç´ è´å¶æ–¯åˆ†ç±»
    - alphaï¼šæ‹‰æ™®æ‹‰æ–¯å¹³æ»‘ç³»æ•°

- æ¡ˆä¾‹ ï¼š20ç±»æ–°é—»åˆ†ç±»

~~~ python
def nb_news():
    """
    ç”¨æœ´ç´ è´å¶æ–¯ç®—æ³•å¯¹æ–°é—»è¿›è¡Œåˆ†ç±»
    :return:
    """
    # 1ï¼‰è·å–æ•°æ®
    news = fetch_20newsgroups(subset="all")

    # 2ï¼‰åˆ’åˆ†æ•°æ®é›†
    x_train, x_test, y_train, y_test = train_test_split(news.data, news.target)

    # 3ï¼‰ç‰¹å¾å·¥ç¨‹ï¼šæ–‡æœ¬ç‰¹å¾æŠ½å–-tfidf
    transfer = TfidfVectorizer()
    x_train = transfer.fit_transform(x_train)
    x_test = transfer.transform(x_test)

    # 4ï¼‰æœ´ç´ è´å¶æ–¯ç®—æ³•é¢„ä¼°å™¨æµç¨‹
    estimator = MultinomialNB()
    estimator.fit(x_train, y_train)

    # 5ï¼‰æ¨¡å‹è¯„ä¼°
    # æ–¹æ³•1ï¼šç›´æ¥æ¯”å¯¹çœŸå®å€¼å’Œé¢„æµ‹å€¼
    y_predict = estimator.predict(x_test)
    print("y_predict:\n", y_predict)
    print("ç›´æ¥æ¯”å¯¹çœŸå®å€¼å’Œé¢„æµ‹å€¼:\n", y_test == y_predict)

    # æ–¹æ³•2ï¼šè®¡ç®—å‡†ç¡®ç‡
    score = estimator.score(x_test, y_test)
    print("å‡†ç¡®ç‡ä¸ºï¼š\n", score)

    return None
~~~

**ä¼˜ç¼ºç‚¹**

- **ä¼˜ç‚¹ï¼š**
  æœ´ç´ è´å¶æ–¯æ¨¡å‹å‘æºäºå¤å…¸æ•°å­¦ç†è®ºï¼Œæœ‰ç¨³å®šçš„åˆ†ç±»æ•ˆç‡ï¼Œå¯¹ç¼ºå¤±æ•°æ®ä¸å¤ªæ•æ„Ÿï¼Œç®—æ³•ä¹Ÿæ¯”è¾ƒç®€å•ï¼Œå¸¸ç”¨äºæ–‡æœ¬åˆ†ç±»ï¼Œåˆ†ç±»å‡†ç¡®åº¦é«˜ï¼Œé€Ÿåº¦å¿«
- **ç¼ºç‚¹ï¼š**
  ç”±äºä½¿ç”¨äº†æ ·æœ¬å±æ€§ç‹¬ç«‹æ€§çš„å‡è®¾ï¼Œæ‰€ä»¥å¦‚æœç‰¹å¾å±æ€§æœ‰å…³è”æ—¶å…¶æ•ˆæœä¸å¥½

**æ€»ç»“ï¼š**æ¡ä»¶æ¦‚ç‡ã€è”åˆæ¦‚ç‡è®¡ç®—æ–¹å¼ä¸ç‰¹å¾ç‹¬ç«‹çš„å…³ç³»è´å¶æ–¯å…¬å¼çš„è®¡ç®—



## å†³ç­–æ ‘

å†³ç­–æ ‘æ€æƒ³çš„æ¥æºéå¸¸æœ´ç´ ï¼Œç¨‹åºè®¾è®¡ä¸­çš„æ¡ä»¶åˆ†æ”¯ç»“æ„å°±æ˜¯if-thenç»“æ„ï¼Œæœ€æ—©çš„å†³ç­–æ ‘å°±æ˜¯åˆ©ç”¨è¿™ç±»ç»“æ„åˆ†å‰²æ•°æ®çš„ä¸€ç§åˆ†ç±»å­¦ä¹ æ–¹æ³•

æ€ä¹ˆç†è§£è¿™å¥è¯ï¼Ÿé€šè¿‡ä¸€ä¸ªå¯¹è¯ä¾‹å­

![image30](./img/image30.png)

æƒ³ä¸€æƒ³è¿™ä¸ªå¥³ç”Ÿä¸ºä»€ä¹ˆæŠŠå¹´é¾„æ”¾åœ¨æœ€ä¸Šé¢åˆ¤æ–­ï¼ï¼ï¼ï¼ï¼ï¼ï¼ï¼ï¼

- **æ˜¯ä¸€ç§æ ‘å½¢ç»“æ„ï¼Œæœ¬è´¨æ˜¯ä¸€é¢—ç”±å¤šä¸ªåˆ¤æ–­èŠ‚ç‚¹ç»„æˆçš„æ ‘**
- **å…¶ä¸­æ¯ä¸ªå†…éƒ¨èŠ‚ç‚¹è¡¨ç¤ºä¸€ä¸ªå±æ€§ä¸Šçš„åˆ¤æ–­ï¼Œ**
- **æ¯ä¸ªåˆ†æ”¯ä»£è¡¨ä¸€ä¸ªåˆ¤æ–­ç»“æœçš„è¾“å‡ºï¼Œ**
- **æœ€åæ¯ä¸ªå¶èŠ‚ç‚¹ä»£è¡¨ä¸€ç§åˆ†ç±»ç»“æœ**ã€‚

### 1. å†³ç­–æ ‘åˆ†ç±»åŸç†

#### 1.1 ç†µ

ç‰©ç†å­¦ä¸Šï¼Œ**ç†µ Entropy** æ˜¯â€œæ··ä¹±â€ç¨‹åº¦çš„é‡åº¦ã€‚**ç³»ç»Ÿè¶Šæœ‰åºï¼Œç†µå€¼è¶Šä½ï¼›ç³»ç»Ÿè¶Šæ··ä¹±æˆ–è€…åˆ†æ•£ï¼Œç†µå€¼è¶Šé«˜**ã€‚

1948å¹´é¦™å†œæå‡ºäº†**ä¿¡æ¯ç†µ**ï¼ˆEntropyï¼‰çš„æ¦‚å¿µã€‚

##### ä¿¡æ¯ç†è®º

**ä»ä¿¡æ¯çš„å®Œæ•´æ€§ä¸Šè¿›è¡Œçš„æè¿°:**

å½“**ç³»ç»Ÿçš„æœ‰åºçŠ¶æ€ä¸€è‡´æ—¶**ï¼Œæ•°æ®è¶Šé›†ä¸­çš„åœ°æ–¹ç†µå€¼è¶Šå°ï¼Œæ•°æ®è¶Šåˆ†æ•£çš„åœ°æ–¹ç†µå€¼è¶Šå¤§ã€‚

**ä»ä¿¡æ¯çš„æœ‰åºæ€§ä¸Šè¿›è¡Œçš„æè¿°:**

å½“**æ•°æ®é‡ä¸€è‡´æ—¶**ï¼Œ**ç³»ç»Ÿè¶Šæœ‰åºï¼Œç†µå€¼è¶Šä½ï¼›ç³»ç»Ÿè¶Šæ··ä¹±æˆ–è€…åˆ†æ•£ï¼Œç†µå€¼è¶Šé«˜**ã€‚

"ä¿¡æ¯ç†µ" (information entropy)æ˜¯åº¦é‡æ ·æœ¬é›†åˆçº¯åº¦æœ€å¸¸ç”¨çš„ä¸€ç§æŒ‡æ ‡ã€‚



å‡å®šå½“å‰æ ·æœ¬é›†åˆ D ä¸­ç¬¬ k ç±»æ ·æœ¬æ‰€å çš„æ¯”ä¾‹ä¸º![equation9](./img/equation9.svg)ï¼Œ![equation10](./img/equation10.svg) ï¼ŒD ä¸ºæ ·æœ¬çš„æ‰€æœ‰æ•°é‡ï¼Œ![equation11](./img/equation11.svg) ï¼Œä¸ºç¬¬ k ç±»æ ·æœ¬çš„æ•°é‡ã€‚

åˆ™ D çš„ä¿¡æ¯ç†µå®šä¹‰ä¸ºï¼ˆlogæ˜¯ä»¥2ä¸ºåº•ï¼Œlgæ˜¯ä»¥10ä¸ºåº•ï¼‰: ![equation12](./img/equation12.svg)

å…¶ä¸­ï¼šEnt(D) çš„å€¼è¶Šå°ï¼Œåˆ™ D çš„çº¯åº¦è¶Šé«˜.



#### 1.2 å†³ç­–æ ‘çš„åˆ’åˆ†ä¾æ®ä¸€: ä¿¡æ¯å¢ç›Š

**ä¿¡æ¯å¢ç›Šï¼š**ä»¥æŸç‰¹å¾åˆ’åˆ†æ•°æ®é›†å‰åçš„ç†µçš„å·®å€¼ã€‚ç†µå¯ä»¥è¡¨ç¤ºæ ·æœ¬é›†åˆçš„ä¸ç¡®å®šæ€§ï¼Œç†µè¶Šå¤§ï¼Œæ ·æœ¬çš„ä¸ç¡®å®šæ€§å°±è¶Šå¤§ã€‚å› æ­¤å¯ä»¥**ä½¿ç”¨åˆ’åˆ†å‰åé›†åˆç†µçš„å·®å€¼æ¥è¡¡é‡ä½¿ç”¨å½“å‰ç‰¹å¾å¯¹äºæ ·æœ¬é›†åˆDåˆ’åˆ†æ•ˆæœçš„å¥½å**ã€‚

 æ³¨ï¼šä¿¡æ¯å¢ç›Šè¡¨ç¤ºå¾—çŸ¥ç‰¹å¾Xçš„ä¿¡æ¯è€Œä½¿å¾—ç±»Yçš„ä¿¡æ¯ç†µå‡å°‘çš„ç¨‹åº¦

ç‰¹å¾ a å¯¹è®­ç»ƒæ•°æ®é›† D çš„ä¿¡æ¯å¢ç›ŠGain(D,a), å®šä¹‰ä¸º**é›†åˆDçš„ä¿¡æ¯ç†µEnt(D)**ä¸**ç»™å®šç‰¹å¾aæ¡ä»¶ä¸‹Dçš„ä¿¡æ¯æ¡ä»¶ç†µ Ent(D|a) ä¹‹å·®**ï¼Œå³å…¬å¼å¦‚ä¸‹:

ä¿¡æ¯ç†µçš„è®¡ç®—ï¼š![equation13](./img/equation13.svg)

æ¡ä»¶ç†µçš„è®¡ç®—ï¼š ![equation14](./img/equation14.svg)

 å…¶ä¸­ï¼š

![equation15](./img/equation15.svg) è¡¨ç¤º a å±æ€§ä¸­ç¬¬ v ä¸ªåˆ†æ”¯èŠ‚ç‚¹åŒ…å«çš„æ ·æœ¬æ•°ï¼›

![equation16](./img/equation16.svg) è¡¨ç¤º a å±æ€§ä¸­ç¬¬ v ä¸ªåˆ†æ”¯èŠ‚ç‚¹åŒ…å«çš„æ ·æœ¬æ•°ä¸­ï¼Œç¬¬ k ä¸ªç±»åˆ«ä¸‹åŒ…å«çš„æ ·æœ¬æ•° 

![equation17](./img/equation17.svg)

ä¸€èˆ¬è€Œè¨€ï¼Œä¿¡æ¯å¢ç›Šè¶Šå¤§ï¼Œåˆ™æ„å‘³ç€**ä½¿ç”¨å±æ€§ a æ¥è¿›è¡Œåˆ’åˆ†æ‰€è·å¾—çš„"çº¯åº¦æå‡"è¶Šå¤§**ã€‚å› æ­¤ï¼Œæˆ‘ä»¬å¯ç”¨ä¿¡æ¯å¢ç›Šæ¥è¿›è¡Œå†³ç­–æ ‘çš„åˆ’åˆ†å±æ€§é€‰æ‹©ï¼Œè‘—åçš„ ID3 å†³ç­–æ ‘å­¦ä¹ ç®—æ³• [Quinlanï¼Œ 1986] å°±æ˜¯ä»¥ä¿¡æ¯å¢ç›Šä¸ºå‡†åˆ™æ¥é€‰æ‹©åˆ’åˆ†å±æ€§ã€‚

>  å…¶ä¸­ï¼ŒID3 åå­—ä¸­çš„ ID æ˜¯ Iterative Dichotomiser (è¿­ä»£äºŒåˆ†å™¨)çš„ç®€ç§°



#### 1.3 å†³ç­–æ ‘çš„åˆ’åˆ†ä¾æ®äºŒ: ä¿¡æ¯å¢ç›Šç‡

**ä¿¡æ¯å¢ç›Šå‡†åˆ™å¯¹å¯å–å€¼æ•°ç›®è¾ƒå¤šçš„å±æ€§æœ‰æ‰€åå¥½**ï¼Œä¸ºå‡å°‘è¿™ç§åå¥½å¯èƒ½å¸¦æ¥çš„ä¸åˆ©å½±å“ï¼Œè‘—åçš„ **C4.5 å†³ç­–æ ‘ç®—æ³• [Quinlan, 1993J ä¸ç›´æ¥ä½¿ç”¨ä¿¡æ¯å¢ç›Šï¼Œè€Œæ˜¯ä½¿ç”¨"å¢ç›Šç‡" (gain ratio) æ¥é€‰æ‹©æœ€ä¼˜åˆ’åˆ†å±æ€§.**

**å¢ç›Šç‡ï¼š**å¢ç›Šç‡æ˜¯ç”¨å‰é¢çš„ä¿¡æ¯å¢ç›ŠGain(D, a)å’Œå±æ€§aå¯¹åº”çš„"å›ºæœ‰å€¼"(intrinsic value) [Quinlan , 1993Jçš„æ¯”å€¼æ¥å…±åŒå®šä¹‰çš„ã€‚

![equation18](./img/equation18.svg)

![equation19](./img/equation19.svg)

>  å±æ€§ a çš„å¯èƒ½å–å€¼æ•°ç›®è¶Šå¤š(å³ V è¶Šå¤§)ï¼Œåˆ™ IV(a) çš„å€¼é€šå¸¸ä¼šè¶Šå¤§.

##### ä¸ºä»€ä¹ˆä½¿ç”¨C4.5è¦å¥½

1. **ç”¨ä¿¡æ¯å¢ç›Šç‡æ¥é€‰æ‹©å±æ€§**

å…‹æœäº†ç”¨ä¿¡æ¯å¢ç›Šæ¥é€‰æ‹©å±æ€§æ—¶åå‘é€‰æ‹©å€¼å¤šçš„å±æ€§çš„ä¸è¶³ã€‚



2. **é‡‡ç”¨äº†ä¸€ç§åå‰ªææ–¹æ³•**

é¿å…æ ‘çš„é«˜åº¦æ— èŠ‚åˆ¶çš„å¢é•¿ï¼Œé¿å…è¿‡åº¦æ‹Ÿåˆæ•°æ®



3. **å¯¹äºç¼ºå¤±å€¼çš„å¤„ç†**

åœ¨æŸäº›æƒ…å†µä¸‹ï¼Œå¯ä¾›ä½¿ç”¨çš„æ•°æ®å¯èƒ½ç¼ºå°‘æŸäº›å±æ€§çš„å€¼ã€‚å‡å¦‚ã€ˆxï¼Œc(x)ã€‰æ˜¯æ ·æœ¬é›†Sä¸­çš„ä¸€ä¸ªè®­ç»ƒå®ä¾‹ï¼Œä½†æ˜¯å…¶å±æ€§Açš„å€¼A(x)æœªçŸ¥ã€‚

å¤„ç†ç¼ºå°‘å±æ€§å€¼çš„ä¸€ç§ç­–ç•¥æ˜¯èµ‹ç»™å®ƒç»“ç‚¹næ‰€å¯¹åº”çš„è®­ç»ƒå®ä¾‹ä¸­è¯¥å±æ€§çš„æœ€å¸¸è§å€¼ï¼›

å¦å¤–ä¸€ç§æ›´å¤æ‚çš„ç­–ç•¥æ˜¯ä¸ºAçš„æ¯ä¸ªå¯èƒ½å€¼èµ‹äºˆä¸€ä¸ªæ¦‚ç‡ã€‚

ä¾‹å¦‚ï¼Œç»™å®šä¸€ä¸ªå¸ƒå°”å±æ€§Aï¼Œå¦‚æœç»“ç‚¹nåŒ…å«6ä¸ªå·²çŸ¥A=1å’Œ4ä¸ªA=0çš„å®ä¾‹ï¼Œé‚£ä¹ˆA(x)=1çš„æ¦‚ç‡æ˜¯0.6ï¼Œè€ŒA(x)=0çš„æ¦‚ç‡æ˜¯0.4ã€‚äºæ˜¯ï¼Œå®ä¾‹xçš„60\%60%è¢«åˆ†é…åˆ°A=1çš„åˆ†æ”¯ï¼Œ40\%40%è¢«åˆ†é…åˆ°å¦ä¸€ä¸ªåˆ†æ”¯ã€‚

C4.5å°±æ˜¯ä½¿ç”¨è¿™ç§æ–¹æ³•å¤„ç†ç¼ºå°‘çš„å±æ€§å€¼ã€‚



4. **å¯ä»¥å¤„ç†è¿ç»­æ•°å€¼å‹å±æ€§**



##### **C4.5ç®—æ³•çš„ä¼˜ç¼ºç‚¹**

ä¼˜ç‚¹ï¼š

äº§ç”Ÿçš„åˆ†ç±»è§„åˆ™æ˜“äºç†è§£ï¼Œå‡†ç¡®ç‡è¾ƒé«˜ã€‚

ç¼ºç‚¹ï¼š

åœ¨æ„é€ æ ‘çš„è¿‡ç¨‹ä¸­ï¼Œéœ€è¦å¯¹æ•°æ®é›†è¿›è¡Œå¤šæ¬¡çš„é¡ºåºæ‰«æå’Œæ’åºï¼Œå› è€Œå¯¼è‡´ç®—æ³•çš„ä½æ•ˆã€‚

æ­¤å¤–ï¼ŒC4.5åªé€‚åˆäºèƒ½å¤Ÿé©»ç•™äºå†…å­˜çš„æ•°æ®é›†ï¼Œå½“è®­ç»ƒé›†å¤§å¾—æ— æ³•åœ¨å†…å­˜å®¹çº³æ—¶ç¨‹åºæ— æ³•è¿è¡Œã€‚



#### 1.4 å†³ç­–æ ‘çš„åˆ’åˆ†ä¾æ®ä¸‰: åŸºå°¼å€¼å’ŒåŸºå°¼æŒ‡æ•°

CART å†³ç­–æ ‘ [Breiman et al., 1984] ä½¿ç”¨"åŸºå°¼æŒ‡æ•°" (Gini index)æ¥é€‰æ‹©åˆ’åˆ†å±æ€§.

 CART æ˜¯Classification and Regression Treeçš„ç®€ç§°ï¼Œè¿™æ˜¯ä¸€ç§è‘—åçš„å†³ç­–æ ‘å­¦ä¹ ç®—æ³•,åˆ†ç±»å’Œå›å½’ä»»åŠ¡éƒ½å¯ç”¨



**åŸºå°¼å€¼Gini(D)ï¼š**ä»æ•°æ®é›†Dä¸­éšæœºæŠ½å–ä¸¤ä¸ªæ ·æœ¬ï¼Œå…¶ç±»åˆ«æ ‡è®°ä¸ä¸€è‡´çš„æ¦‚ç‡ã€‚**æ•… Gini(D) å€¼è¶Šå°ï¼Œæ•°æ®é›†Dçš„çº¯åº¦è¶Šé«˜ã€‚**

æ•°æ®é›† D çš„çº¯åº¦å¯ç”¨åŸºå°¼å€¼æ¥åº¦é‡: 

![equation20](./img/equation20.svg)

> ![equation21](./img/equation21.svg) ï¼ŒDä¸ºæ ·æœ¬çš„æ‰€æœ‰æ•°é‡ï¼Œ$C^k$ ä¸ºç¬¬ k ç±»æ ·æœ¬çš„æ•°é‡



**åŸºå°¼æŒ‡æ•°Gini_index(D)ï¼š**ä¸€èˆ¬ï¼Œé€‰æ‹©ä½¿åˆ’åˆ†ååŸºå°¼ç³»æ•°æœ€å°çš„å±æ€§ä½œä¸ºæœ€ä¼˜åŒ–åˆ†å±æ€§ã€‚

![equation22](./img/equation22.svg)

>  CARTç®—æ³•ç›¸æ¯”C4.5ç®—æ³•çš„åˆ†ç±»æ–¹æ³•ï¼Œé‡‡ç”¨äº†ç®€åŒ–çš„äºŒå‰æ ‘æ¨¡å‹ï¼ŒåŒæ—¶ç‰¹å¾é€‰æ‹©é‡‡ç”¨äº†è¿‘ä¼¼çš„åŸºå°¼ç³»æ•°æ¥ç®€åŒ–è®¡ç®—ã€‚



#### 1.5 å†³ç­–æ ‘å˜é‡çš„ä¸¤ç§ç±»å‹

1. æ•°å­—å‹ï¼ˆNumericï¼‰ï¼šå˜é‡ç±»å‹æ˜¯æ•´æ•°æˆ–æµ®ç‚¹æ•°ï¼Œå¦‚å‰é¢ä¾‹å­ä¸­çš„â€œå¹´æ”¶å…¥â€ã€‚ç”¨â€œ>=â€ï¼Œâ€œ>â€,â€œ<â€æˆ–â€œ<=â€ä½œä¸ºåˆ†å‰²æ¡ä»¶ï¼ˆæ’åºåï¼Œåˆ©ç”¨å·²æœ‰çš„åˆ†å‰²æƒ…å†µï¼Œå¯ä»¥ä¼˜åŒ–åˆ†å‰²ç®—æ³•çš„æ—¶é—´å¤æ‚åº¦ï¼‰ã€‚
2. åç§°å‹ï¼ˆNominalï¼‰ï¼šç±»ä¼¼ç¼–ç¨‹è¯­è¨€ä¸­çš„æšä¸¾ç±»å‹ï¼Œå˜é‡åªèƒ½ä»æœ‰é™çš„é€‰é¡¹ä¸­é€‰å–ï¼Œæ¯”å¦‚å‰é¢ä¾‹å­ä¸­çš„â€œå©šå§»æƒ…å†µâ€ï¼Œåªèƒ½æ˜¯â€œå•èº«â€ï¼Œâ€œå·²å©šâ€æˆ–â€œç¦»å©šâ€ï¼Œä½¿ç”¨â€œ=â€æ¥åˆ†å‰²ã€‚



### 2. cartå‰ªæ

å‰ªæ (pruning)æ˜¯**å†³ç­–æ ‘å­¦ä¹ ç®—æ³•å¯¹ä»˜"è¿‡æ‹Ÿåˆ"çš„ä¸»è¦æ‰‹æ®µ**ã€‚

åœ¨å†³ç­–æ ‘å­¦ä¹ ä¸­ï¼Œä¸ºäº†å°½å¯èƒ½æ­£ç¡®åˆ†ç±»è®­ç»ƒæ ·æœ¬ï¼Œç»“ç‚¹åˆ’åˆ†è¿‡ç¨‹å°†ä¸æ–­é‡å¤ï¼Œæœ‰æ—¶ä¼šé€ æˆå†³ç­–æ ‘åˆ†æ”¯è¿‡å¤šï¼Œè¿™æ—¶å°±å¯èƒ½å› è®­ç»ƒæ ·æœ¬å­¦å¾—"å¤ªå¥½"äº†ï¼Œä»¥è‡´äºæŠŠè®­ç»ƒé›†è‡ªèº«çš„ä¸€äº›ç‰¹ç‚¹å½“ä½œæ‰€æœ‰æ•°æ®éƒ½å…·æœ‰çš„ä¸€èˆ¬æ€§è´¨è€Œå¯¼è‡´è¿‡æ‹Ÿåˆã€‚å› æ­¤ï¼Œå¯é€šè¿‡**ä¸»åŠ¨å»æ‰ä¸€äº›åˆ†æ”¯æ¥é™ä½è¿‡æ‹Ÿåˆçš„é£é™©**ã€‚

**å‰ªæåŸå› **

- å™ªå£°ã€æ ·æœ¬å†²çªï¼Œå³é”™è¯¯çš„æ ·æœ¬æ•°æ®
- ç‰¹å¾å³å±æ€§ä¸èƒ½å®Œå…¨ä½œä¸ºåˆ†ç±»æ ‡å‡†
- å·§åˆçš„è§„å¾‹æ€§ï¼Œæ•°æ®é‡ä¸å¤Ÿå¤§ã€‚



#### 2.1 å¸¸ç”¨çš„å‡ææ–¹æ³•

å†³ç­–æ ‘å‰ªæçš„åŸºæœ¬ç­–ç•¥æœ‰"é¢„å‰ªæ" (pre-pruning)å’Œ"åå‰ªæ"(post- pruning) ã€‚

- é¢„å‰ªææ˜¯**æŒ‡åœ¨å†³ç­–æ ‘ç”Ÿæˆè¿‡ç¨‹ä¸­ï¼Œå¯¹æ¯ä¸ªç»“ç‚¹åœ¨åˆ’åˆ†å‰å…ˆè¿›è¡Œä¼°è®¡ï¼Œè‹¥å½“å‰ç»“ç‚¹çš„åˆ’åˆ†ä¸èƒ½å¸¦æ¥å†³ç­–æ ‘æ³›åŒ–æ€§èƒ½æå‡ï¼Œåˆ™åœæ­¢åˆ’åˆ†å¹¶å°†å½“å‰ç»“ç‚¹æ ‡è®°ä¸ºå¶ç»“ç‚¹;**
- åå‰ªæåˆ™æ˜¯**å…ˆä»è®­ç»ƒé›†ç”Ÿæˆä¸€æ£µå®Œæ•´çš„å†³ç­–æ ‘ï¼Œç„¶åè‡ªåº•å‘ä¸Šåœ°å¯¹éå¶ç»“ç‚¹è¿›è¡Œè€ƒå¯Ÿ**ï¼Œè‹¥å°†è¯¥ç»“ç‚¹å¯¹åº”çš„å­æ ‘æ›¿æ¢ä¸ºå¶ç»“ç‚¹èƒ½å¸¦æ¥å†³ç­–æ ‘æ³›åŒ–æ€§èƒ½æå‡ï¼Œåˆ™å°†è¯¥å­æ ‘æ›¿æ¢ä¸ºå¶ç»“ç‚¹ã€‚

**é¢„å‰ªæ**

- åœ¨æ„å»ºæ ‘çš„è¿‡ç¨‹ä¸­ï¼ŒåŒæ—¶å‰ªæ
- é™åˆ¶èŠ‚ç‚¹æœ€å°æ ·æœ¬æ•°
- æŒ‡å®šæ•°æ®é«˜åº¦
- æŒ‡å®šç†µå€¼çš„æœ€å°å€¼

**åå‰ªæ**

- æŠŠä¸€æ£µæ ‘ï¼Œæ„å»ºå®Œæˆä¹‹åï¼Œå†è¿›è¡Œä»ä¸‹å¾€ä¸Šçš„å‰ªæ

**å¯¹æ¯”ä¸¤ç§å‰ªææ–¹æ³•**

- åå‰ªæå†³ç­–æ ‘é€šå¸¸æ¯”é¢„å‰ªæå†³ç­–æ ‘ä¿ç•™äº†æ›´å¤šçš„åˆ†æ”¯ã€‚
- ä¸€èˆ¬æƒ…å½¢ä¸‹ï¼Œåå‰ªæå†³ç­–æ ‘çš„æ¬ æ‹Ÿåˆé£é™©å¾ˆå°ï¼Œæ³›åŒ–æ€§èƒ½å¾€å¾€ä¼˜äºé¢„å‰ªæå†³ç­–æ ‘ã€‚
- ä½†åå‰ªæè¿‡ç¨‹æ˜¯åœ¨ç”Ÿæˆå®Œå…¨å†³ç­–æ ‘ä¹‹åè¿›è¡Œçš„ã€‚ å¹¶ä¸”è¦è‡ªåº•å‘ä¸Šåœ°å¯¹æ ‘ä¸­çš„æ‰€æœ‰éå¶ç»“ç‚¹è¿›è¡Œé€ä¸€è€ƒå¯Ÿï¼Œå› æ­¤å…¶è®­ç»ƒæ—¶é—´å¼€é”€æ¯”æœªå‰ªæå†³ç­–æ ‘å’Œé¢„å‰ªæå†³ç­–æ ‘éƒ½è¦å¤§å¾—å¤š.



### 3. å†³ç­–æ ‘ç®—æ³•api

~~~ python
class sklearn.tree.DecisionTreeClassifier(criterion=â€™giniâ€™, max_depth=None, random_state=None)
~~~

- criterion: ç‰¹å¾é€‰æ‹©æ ‡å‡†

"gini"æˆ–è€…"entropy"ï¼Œå‰è€…ä»£è¡¨åŸºå°¼ç³»æ•°ï¼Œåè€…ä»£è¡¨ä¿¡æ¯å¢ç›Šã€‚ä¸€é»˜è®¤"gini"ï¼Œå³CARTç®—æ³•ã€‚



- min_samples_split: å†…éƒ¨èŠ‚ç‚¹å†åˆ’åˆ†æ‰€éœ€æœ€å°æ ·æœ¬æ•°

è¿™ä¸ªå€¼é™åˆ¶äº†å­æ ‘ç»§ç»­åˆ’åˆ†çš„æ¡ä»¶ï¼Œå¦‚æœæŸèŠ‚ç‚¹çš„æ ·æœ¬æ•°å°‘äºmin_samples_splitï¼Œåˆ™ä¸ä¼šç»§ç»­å†å°è¯•é€‰æ‹©æœ€ä¼˜ç‰¹å¾æ¥è¿›è¡Œåˆ’åˆ†ã€‚ é»˜è®¤æ˜¯2. å¦‚æœæ ·æœ¬é‡ä¸å¤§ï¼Œä¸éœ€è¦ç®¡è¿™ä¸ªå€¼ã€‚å¦‚æœæ ·æœ¬é‡æ•°é‡çº§éå¸¸å¤§ï¼Œåˆ™æ¨èå¢å¤§è¿™ä¸ªå€¼ã€‚



- min_samples_leaf: å¶å­èŠ‚ç‚¹æœ€å°‘æ ·æœ¬æ•°

è¿™ä¸ªå€¼é™åˆ¶äº†å¶å­èŠ‚ç‚¹æœ€å°‘çš„æ ·æœ¬æ•°ï¼Œå¦‚æœæŸå¶å­èŠ‚ç‚¹æ•°ç›®å°äºæ ·æœ¬æ•°ï¼Œåˆ™ä¼šå’Œå…„å¼ŸèŠ‚ç‚¹ä¸€èµ·è¢«å‰ªæã€‚ é»˜è®¤æ˜¯1,å¯ä»¥è¾“å…¥æœ€å°‘çš„æ ·æœ¬æ•°çš„æ•´æ•°ï¼Œæˆ–è€…æœ€å°‘æ ·æœ¬æ•°å æ ·æœ¬æ€»æ•°çš„ç™¾åˆ†æ¯”ã€‚å¦‚æœæ ·æœ¬é‡ä¸å¤§ï¼Œä¸éœ€è¦ç®¡è¿™ä¸ªå€¼ã€‚å¦‚æœæ ·æœ¬é‡æ•°é‡çº§éå¸¸å¤§ï¼Œåˆ™æ¨èå¢å¤§è¿™ä¸ªå€¼ã€‚



- max_depth: å†³ç­–æ ‘æœ€å¤§æ·±åº¦

å†³ç­–æ ‘çš„æœ€å¤§æ·±åº¦ï¼Œé»˜è®¤å¯ä»¥ä¸è¾“å…¥ï¼Œå¦‚æœä¸è¾“å…¥çš„è¯ï¼Œå†³ç­–æ ‘åœ¨å»ºç«‹å­æ ‘çš„æ—¶å€™ä¸ä¼šé™åˆ¶å­æ ‘çš„æ·±åº¦ã€‚ä¸€èˆ¬æ¥è¯´ï¼Œæ•°æ®å°‘æˆ–è€…ç‰¹å¾å°‘çš„æ—¶å€™å¯ä»¥ä¸ç®¡è¿™ä¸ªå€¼ã€‚å¦‚æœæ¨¡å‹æ ·æœ¬é‡å¤šï¼Œç‰¹å¾ä¹Ÿå¤šçš„æƒ…å†µä¸‹ï¼Œæ¨èé™åˆ¶è¿™ä¸ªæœ€å¤§æ·±åº¦ï¼Œå…·ä½“çš„å–å€¼å–å†³äºæ•°æ®çš„åˆ†å¸ƒã€‚å¸¸ç”¨çš„å¯ä»¥å–å€¼10-100ä¹‹é—´



- random_state: éšæœºæ•°ç§å­



### 4. æ³°å¦å°¼å…‹å·ä¹˜å®¢ç”Ÿå­˜é¢„æµ‹

æ¡ˆä¾‹ï¼š[https://www.kaggle.com/c/titanic/overview](http://link.zhihu.com/?target=https%3A//www.kaggle.com/c/titanic/overview)

æ•°æ®ï¼š[http://biostat.mc.vanderbilt.edu/wiki/pub/Main/DataSets/titanic.txt](http://link.zhihu.com/?target=http%3A//biostat.mc.vanderbilt.edu/wiki/pub/Main/DataSets/titanic.txt)

ç»è¿‡è§‚å¯Ÿæ•°æ®å¾—åˆ°:

- **1 ä¹˜åç­æ˜¯æŒ‡ä¹˜å®¢ç­ï¼ˆ1ï¼Œ2ï¼Œ3ï¼‰ï¼Œæ˜¯ç¤¾ä¼šç»æµé˜¶å±‚çš„ä»£è¡¨ã€‚**
- **2 å…¶ä¸­ageæ•°æ®å­˜åœ¨ç¼ºå¤±ã€‚**

~~~ python
import pandas as pd
import numpy as np
from sklearn.feature_extraction import DictVectorizer
from sklearn.model_selection import train_test_split
from sklearn.tree import DecisionTreeClassifier, export_graphviz


# 1ã€è·å–æ•°æ®
titan = pd.read_csv("http://biostat.mc.vanderbilt.edu/wiki/pub/Main/DataSets/titanic.txt")
# 2.æ•°æ®åŸºæœ¬å¤„ç†
# 2.1 ç¡®å®šç‰¹å¾å€¼,ç›®æ ‡å€¼
x = titan[["pclass", "age", "sex"]]
y = titan["survived"]
# 2.2 ç¼ºå¤±å€¼å¤„ç†
x['age'].fillna(x['age'].mean(), inplace=True)
# 2.3 æ•°æ®é›†åˆ’åˆ†
x_train, x_test, y_train, y_test = train_test_split(x, y, random_state=22)
# 3. ç‰¹å¾å·¥ç¨‹(å­—å…¸ç‰¹å¾æŠ½å–)
# ç‰¹å¾ä¸­å‡ºç°ç±»åˆ«ç¬¦å·ï¼Œéœ€è¦è¿›è¡Œone-hotç¼–ç å¤„ç†(DictVectorizer)
# å¯¹äºxè½¬æ¢æˆå­—å…¸æ•°æ®x.to_dict(orient="records")
# [{"pclass": "1st", "age": 29.00, "sex": "female"}, {}]
transfer = DictVectorizer(sparse=False)
x_train = transfer.fit_transform(x_train.to_dict(orient="records"))
x_test = transfer.fit_transform(x_test.to_dict(orient="records"))
# 4.å†³ç­–æ ‘æ¨¡å‹è®­ç»ƒå’Œæ¨¡å‹è¯„ä¼°
# 4.æœºå™¨å­¦ä¹ (å†³ç­–æ ‘)
estimator = DecisionTreeClassifier(criterion="entropy", max_depth=5)
estimator.fit(x_train, y_train)
# 5.æ¨¡å‹è¯„ä¼°
estimator.score(x_test, y_test)
estimator.predict(x_test)
~~~



### 5. å›å½’å†³ç­–æ ‘

å†³ç­–æ ‘ä¹Ÿå¯ä»¥åˆ†ä¸ºä¸¤å¤§ç±»å‹ï¼š

- **åˆ†ç±»å†³ç­–æ ‘å’Œå›å½’å†³ç­–æ ‘ã€‚**
- **å‰è€…ä¸»è¦ç”¨äºå¤„ç†ç¦»æ•£å‹æ•°æ®ï¼Œåè€…ä¸»è¦ç”¨äºå¤„ç†è¿ç»­å‹æ•°æ®ã€‚**



#### 5.1 åŸç†æ¦‚è¿°

ä¸ç®¡æ˜¯å›å½’å†³ç­–æ ‘è¿˜æ˜¯åˆ†ç±»å†³ç­–æ ‘ï¼Œéƒ½ä¼šå­˜åœ¨ä¸¤ä¸ªæ ¸å¿ƒé—®é¢˜ï¼š

- å¦‚ä½•é€‰æ‹©åˆ’åˆ†ç‚¹ï¼Ÿ
- å¦‚ä½•å†³å®šå¶èŠ‚ç‚¹çš„è¾“å‡ºå€¼ï¼Ÿ

ä¸€ä¸ªå›å½’æ ‘å¯¹åº”ç€è¾“å…¥ç©ºé—´ï¼ˆå³ç‰¹å¾ç©ºé—´ï¼‰çš„ä¸€ä¸ªåˆ’åˆ†ä»¥åŠåœ¨åˆ’åˆ†å•å…ƒä¸Šçš„è¾“å‡ºå€¼ã€‚åˆ†ç±»æ ‘ä¸­ï¼Œæˆ‘ä»¬é‡‡ç”¨ä¿¡æ¯è®ºä¸­çš„æ–¹æ³•ï¼Œé€šè¿‡è®¡ç®—é€‰æ‹©æœ€ä½³åˆ’åˆ†ç‚¹ã€‚

è€Œåœ¨å›å½’æ ‘ä¸­ï¼Œé‡‡ç”¨çš„æ˜¯å¯å‘å¼çš„æ–¹æ³•ã€‚**å‡å¦‚æˆ‘ä»¬æœ‰nä¸ªç‰¹å¾ï¼Œæ¯ä¸ªç‰¹å¾æœ‰**![equation23](./img/equation23.svg) **ä¸ªå–å€¼ï¼Œé‚£æˆ‘ä»¬éå†æ‰€æœ‰ç‰¹å¾ï¼Œå°è¯•è¯¥ç‰¹å¾æ‰€æœ‰å–å€¼ï¼Œå¯¹ç©ºé—´è¿›è¡Œåˆ’åˆ†ï¼Œç›´åˆ°å–åˆ°ç‰¹å¾ j çš„å–å€¼ sï¼Œä½¿å¾—æŸå¤±å‡½æ•°æœ€å°ï¼Œè¿™æ ·å°±å¾—åˆ°äº†ä¸€ä¸ªåˆ’åˆ†ç‚¹ã€‚**æè¿°è¯¥è¿‡ç¨‹çš„å…¬å¼å¦‚ä¸‹ï¼š

![equation24](./img/equation24.svg)

 å‡è®¾å°†è¾“å…¥ç©ºé—´åˆ’åˆ†ä¸ºMä¸ªå•å…ƒï¼š![equation25](./img/equation25.svg) é‚£ä¹ˆæ¯ä¸ªåŒºåŸŸçš„è¾“å‡ºå€¼å°±æ˜¯ï¼š![equation26](./img/equation26.svg) ä¹Ÿå°±æ˜¯è¯¥åŒºåŸŸå†…æ‰€æœ‰ç‚¹yå€¼çš„å¹³å‡æ•°ã€‚



#### 5.2 ç®—æ³•æè¿°

-  è¾“å…¥ï¼šè®­ç»ƒæ•°æ®é›†D:
-  è¾“å‡ºï¼šå›å½’æ ‘f(x).
-  åœ¨è®­ç»ƒæ•°æ®é›†æ‰€åœ¨çš„è¾“å…¥ç©ºé—´ä¸­ï¼Œé€’å½’çš„å°†æ¯ä¸ªåŒºåŸŸåˆ’åˆ†ä¸ºä¸¤ä¸ªå­åŒºåŸŸå¹¶å†³å®šæ¯ä¸ªå­åŒºåŸŸä¸Šçš„è¾“å‡ºå€¼ï¼Œæ„å»ºäºŒå‰å†³ç­–æ ‘ï¼š
-  ï¼ˆ1ï¼‰é€‰æ‹©æœ€ä¼˜åˆ‡åˆ†ç‰¹å¾jä¸åˆ‡åˆ†ç‚¹sï¼Œæ±‚è§£

![equation27](./img/equation27.svg)

éå†ç‰¹å¾$j$, å¯¹å›ºå®šçš„åˆ‡åˆ†ç‰¹å¾$j$æ‰«æåˆ‡åˆ†ç‚¹$s$,é€‰æ‹©ä½¿å¾—ä¸Šå¼è¾¾åˆ°æœ€å°å€¼çš„å¯¹$(j,s)$.



-  ï¼ˆ2ï¼‰ç”¨é€‰å®šçš„å¯¹$(j,s)$åˆ’åˆ†åŒºåŸŸå¹¶å†³å®šç›¸åº”çš„è¾“å‡ºå€¼ï¼š

![equation28](./img/equation28.svg)



-  ï¼ˆ3ï¼‰ç»§ç»­å¯¹ä¸¤ä¸ªå­åŒºåŸŸè°ƒç”¨æ­¥éª¤ï¼ˆ1ï¼‰å’Œï¼ˆ2ï¼‰ï¼Œç›´è‡³æ»¡è¶³åœæ­¢æ¡ä»¶ã€‚



-  ï¼ˆ4ï¼‰å°†è¾“å…¥ç©ºé—´åˆ’åˆ†ä¸ºMä¸ªåŒºåŸŸR_1, R_2,..., R_M*R*1,*R*2,...,*RM*, ç”Ÿæˆå†³ç­–æ ‘ï¼š

![equation29](./img/equation29.svg)



#### 5.3 å›å½’å†³ç­–æ ‘å’Œçº¿æ€§å›å½’å¯¹æ¯”

~~~ python
import numpy as np
import matplotlib.pyplot as plt
from sklearn.tree import DecisionTreeRegressor
from sklearn import linear_model


# ç”Ÿæˆæ•°æ®
x = np.array(list(range(1, 11))).reshape(-1, 1)
y = np.array([5.56, 5.70, 5.91, 6.40, 6.80, 7.05, 8.90, 8.70, 9.00, 9.05])
# è®­ç»ƒæ¨¡å‹
model1 = DecisionTreeRegressor(max_depth=1)
model2 = DecisionTreeRegressor(max_depth=3)
model3 = linear_model.LinearRegression()
model1.fit(x, y)
model2.fit(x, y)
model3.fit(x, y)
# æ¨¡å‹é¢„æµ‹
X_test = np.arange(0.0, 10.0, 0.01).reshape(-1, 1)  # ç”Ÿæˆ1000ä¸ªæ•°,ç”¨äºé¢„æµ‹æ¨¡å‹
X_test.shape
y_1 = model1.predict(X_test)
y_2 = model2.predict(X_test)
y_3 = model3.predict(X_test)
# ç»“æœå¯è§†åŒ–
plt.figure(figsize=(10, 6), dpi=100)
plt.scatter(x, y, label="data")
plt.plot(X_test, y_1,label="max_depth=1")
plt.plot(X_test, y_2, label="max_depth=3")
plt.plot(X_test, y_3, label='liner regression')
plt.xlabel("data")
plt.ylabel("target")
plt.title("Decision Tree Regression")
plt.legend()
plt.show()
~~~

![v2-c80650d45ca8154497f9a4761f744e20_b](./img/v2-c80650d45ca8154497f9a4761f744e20_b.jpg)

**æ€»ç»“**

- ä¼˜ç‚¹ï¼šç®€å•çš„ç†è§£å’Œè§£é‡Šï¼Œæ ‘å¯è§†åŒ–
- ç¼ºç‚¹ï¼šå†³ç­–æ ‘å­¦ä¹ è€…å¯ä»¥åˆ›å»ºä¸èƒ½å¾ˆå¥½æ¨å¹¿æ•°æ®çš„è¿‡äºå¤æ‚çš„æ ‘ï¼Œè¿™è¢«ç§°ä¸ºè¿‡æ‹Ÿåˆ

**æ”¹è¿›**ï¼šå‡æ cart ç®—æ³•ï¼›éšæœºæ£®æ—

**åº”ç”¨åœºæ™¯**ï¼šä¼ä¸šé‡è¦å†³ç­–ï¼Œç”±äºåˆ†æèƒ½åŠ›å¾ˆå¥½ï¼Œåœ¨å†³ç­–è¿‡ç¨‹åº”ç”¨è¾ƒå¤šï¼Œå¯ä»¥é€‰æ‹©ç‰¹å¾



## éšæœºæ£®æ—

- é›†æˆå­¦ä¹ æ–¹æ³•
  é€šè¿‡å»ºç«‹å‡ ä¸ªæ¨¡å‹ç»„åˆæ¥è§£å†³å•ä¸€é¢„æµ‹é—®é¢˜ï¼Œå®ƒçš„å·¥ä½œåŸç†æ˜¯ç”Ÿæˆå¤šä¸ªåˆ†ç±»å™¨/æ¨¡å‹ï¼Œå„è‡ªç‹¬ç«‹çš„å­¦ä¹ å’Œåšå‡ºé¢„æµ‹ï¼Œè¿™äº›é¢„æµ‹æœ€åç»“åˆæˆç»„åˆé¢„æµ‹ï¼Œå› æ­¤ä¼˜äºä»»ä½•ä¸€ä¸ªå•åˆ†ç±»åšå‡ºçš„é¢„æµ‹



- éšæœºæ£®æ—
  æ˜¯ä¸€ä¸ªåŒ…å«å¤šä¸ªå†³ç­–æ ‘çš„åˆ†ç±»å™¨ï¼Œå¹¶ä¸”å…¶è¾“å‡ºçš„ç±»åˆ«æ˜¯ç”±ä¸ªåˆ«æ ‘è¾“å‡ºçš„ç±»åˆ«çš„ä¼—æ•°è€Œå®šï¼Œä¾‹å¦‚, å¦‚æœä½ è®­ç»ƒäº†5ä¸ªæ ‘, å…¶ä¸­æœ‰4ä¸ªæ ‘çš„ç»“æœæ˜¯True, 1ä¸ªæ•°çš„ç»“æœæ˜¯False, é‚£ä¹ˆæœ€ç»ˆæŠ•ç¥¨ç»“æœå°±æ˜¯True



- éšæœºæ£®æ—åŸç†è¿‡ç¨‹ä¸¤ä¸ªéšæœº

- - è®­ç»ƒé›†éšæœº - N ä¸ªæ ·æœ¬ä¸­éšæœºæœ‰æ”¾å›çš„æŠ½å– N ä¸ªæ ·æœ¬
    bootstrap-éšæœºæœ‰æ”¾å›æŠ½æ ·
  - ç‰¹å¾éšæœº - M ä¸ªç‰¹å¾ä¸­æŠ½å– m ä¸ªç‰¹å¾
    M >> mï¼šé™ç»´

- 

- API

- - class sklearn.ensemble.RandomForestClassifier(n_estimators=10, criterion=â€™giniâ€™, max_depth=None, bootstrap=True, random_state=None, min_samples_split=2)

- - - éšæœºæ£®æ—åˆ†ç±»å™¨
    - n_estimatorsï¼šintegerï¼Œoptionalï¼ˆdefault = 10ï¼‰æ£®æ—é‡Œçš„æ ‘æœ¨æ•°é‡120,200,300,500,800,1200
    - criteriaï¼šstringï¼Œå¯é€‰ï¼ˆdefault =â€œginiâ€ï¼‰åˆ†å‰²ç‰¹å¾çš„æµ‹é‡æ–¹æ³•
    - max_depthï¼šintegeræˆ–Noneï¼Œå¯é€‰ï¼ˆé»˜è®¤=æ— ï¼‰æ ‘çš„æœ€å¤§æ·±åº¦ 5,8,15,25,30
    - max_features="autoâ€,æ¯ä¸ªå†³ç­–æ ‘çš„æœ€å¤§ç‰¹å¾æ•°é‡

- - - - If "auto", then `max_features=sqrt(n_features)`.
      - If "sqrt", then `max_features=sqrt(n_features)` (same as "auto").
      - If "log2", then `max_features=log2(n_features)`.
      - If None, then `max_features=n_features`.

- - - bootstrapï¼šbooleanï¼Œoptionalï¼ˆdefault = Trueï¼‰æ˜¯å¦åœ¨æ„å»ºæ ‘æ—¶ä½¿ç”¨æ”¾å›æŠ½æ ·
    - min_samples_split:èŠ‚ç‚¹åˆ’åˆ†æœ€å°‘æ ·æœ¬æ•°
    - min_samples_leaf:å¶å­èŠ‚ç‚¹çš„æœ€å°æ ·æœ¬æ•°

- - è¶…å‚æ•°ï¼šn_estimator, max_depth, min_samples_split,min_samples_leaf

- 

- éšæœºæ£®æ—é¢„æµ‹æ¡ˆä¾‹
  éšæœºæ£®æ—å¯¹æ³°å¦å°¼å…‹å·ä¹˜å®¢ç”Ÿå­˜è¿›è¡Œé¢„æµ‹

~~~ python
from sklearn.model_selection import train_test_split
from sklearn.feature_extraction import DictVectorizer
import pandas as pd
from sklearn.ensemble import RandomForestClassifier
from sklearn.model_selection import GridSearchCV


def decision():
    """
    éšæœºæ£®æ—å¯¹æ³°å¦å°¼å…‹å·è¿›è¡Œé¢„æµ‹ç”Ÿæ­»æƒ…å†µ
    """
    
    # 1ã€è·å–æ•°æ®
    titanic = pd.read_csv("http://biostat.mc.vanderbilt.edu/wiki/pub/Main/DataSets/titanic.txt")
    
    # ç­›é€‰ç‰¹å¾å€¼å’Œç›®æ ‡å€¼
    x = titanic[["pclass", "age", "sex"]]
    y = titanic["survived"]
    
    # 2ã€æ•°æ®å¤„ç†
    # 2.1 ç¼ºå¤±å€¼å¤„ç†
    x["age"].fillna(x["age"].mean(), inplace=True)
    
    # 2.2 è½¬æ¢æˆå­—å…¸
    x = x.to_dict(orient="records")
    
    # 3ã€æ•°æ®é›†åˆ’åˆ†
    x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.25)
    
    # 4ã€å­—å…¸ç‰¹å¾æŠ½å–
    transfer = DictVectorizer()
    x_train = transfer.fit_transform(x_train)
    x_test = transfer.transform(x_test)
    
    # éšæœºæ£®æ—
    estimator = RandomForestClassifier()
    
    # æ·»åŠ ç½‘æ ¼æœç´¢ä¸äº¤å‰éªŒè¯
    # å‚æ•°å‡†å¤‡
    param_dict = {"n_estimators": [20, 30, 40, 50, 60, 100], "max_depth":[5, 8, 15, 25, 30]}
    GridSearchCV(estimator, param_grid=param_dict, cv=3)
    estimator.fit(x_train, y_train)

    # æ¨¡å‹è¯„ä¼°
    # æ–¹æ³•1 : ç›´æ¥å¯¹æ¯”çœŸå®å€¼å’Œé¢„æµ‹å€¼
    y_predict = estimator.predict(x_test)
    print("y_predict  : \n", y_predict)
    print("ç›´æ¥å¯¹æ¯”çœŸå®å€¼å’Œé¢„æµ‹å€¼ : \n", y_test == y_predict)

    # æ–¹æ³•2 : è®¡ç®—å‡†ç¡®ç‡
    score = estimator.score(x_test, y_test)
    print("å‡†ç¡®ç‡ : \n", score)

    # print("æœ€ä½³å‚æ•° : \n", estimator.best_params_)
    # print("æœ€ä½³ç»“æœ : \n", estimator.best_score_)
    # print("æœ€ä½³ä¼°è®¡å™¨ : \n", estimator.best_estimator_)
    # print("äº¤å‰éªŒè¯ç»“æœ : \n", estimator.cv_results_)

    return None
~~~

æ€»ç»“

- å…·æœ‰æå¥½çš„å‡†ç¡®ç‡
- èƒ½å¤Ÿæœ‰æ•ˆçš„è¿è¡Œåœ¨å¤§æ•°æ®é›†ä¸Šï¼Œå¤„ç†å…·æœ‰é«˜ç»´ç‰¹å¾çš„æ•°æ®è¾“å…¥æ ·æœ¬ï¼Œè€Œä¸”ä¸éœ€è¦é™ç»´