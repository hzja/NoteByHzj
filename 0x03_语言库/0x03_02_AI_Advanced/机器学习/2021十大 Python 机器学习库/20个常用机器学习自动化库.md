<a name="UsizL"></a>
## AutoML
AutoML是指自动机器学习。它说明了如何在组织和教育水平上自动化机器学习的端到端过程。机器学习模型基本上包括以下步骤：

- 数据读取和合并，使其可供使用。
- 数据预处理是指数据清理和数据整理。
- 优化功能和模型选择过程的位置。
- 将其应用于应用程序以预测准确的值。

最初，所有这些步骤都是手动完成的。但是现在随着AutoML的出现，这些步骤可以实现自动化。AutoML当前分为三类：

- 用于自动参数调整的AutoML（相对基本的类型）
- 用于非深度学习的AutoML，例如AutoSKlearn。此类型主要应用于数据预处理，自动特征分析，自动特征检测，自动特征选择和自动模型选择。
- 用于深度学习/神经网络的AutoML，包括NAS和ENAS以及用于框架的Auto-Keras。
<a name="YtDAL"></a>
### 为什么需要AutoML？
机器学习的需求日益增长。组织已经在应用程序级别采用了机器学习。仍在进行许多改进，并且仍然有许多公司正在努力为机器学习模型的部署提供更好的解决方案。<br />为了进行部署，企业需要有一个经验丰富的数据科学家团队，他们期望高薪。即使企业确实拥有优秀的团队，通常也需要更多的经验而不是AI知识来决定哪种模型最适合企业。机器学习在各种应用中的成功导致对机器学习系统的需求越来越高。即使对于非专家也应该易于使用。AutoML倾向于在ML管道中自动执行尽可能多的步骤，并以最少的人力保持良好的模型性能。
<a name="N5FNK"></a>
### AutoML三大优点

- 它通过自动化最重复的任务来提高效率。这使数据科学家可以将更多的时间投入到问题上，而不是模型上。
- 自动化的ML管道还有助于避免由手工作业引起的潜在错误。
- AutoML是朝着机器学习民主化迈出的一大步，它使每个人都可以使用ML功能。
<a name="eEne2"></a>
## **auto-sklearn**
![](https://cdn.nlark.com/yuque/0/2023/jpeg/396745/1688951754990-dd8a0360-3e49-463c-a8ef-80b0810f671a.jpeg#averageHue=%23b8cba6&clientId=u72b9ff35-6f18-4&from=paste&id=uf4aaf57b&originHeight=226&originWidth=948&originalType=url&ratio=2.5&rotation=0&showTitle=false&status=done&style=none&taskId=u484bd090-179c-4fe4-bcc4-8e17d37220f&title=)<br />auto-sklearn是一种自动机器学习工具包，是scikit-learn估计器的直接替代品。Auto-SKLearn将机器学习用户从算法选择和超参数调整中解放出来。它包括功能设计方法，例如一站式，数字功能标准化和PCA。该模型使用SKLearn估计器来处理分类和回归问题。Auto-SKLearn创建管道并使用贝叶斯搜索来优化该渠道。在ML框架中，通过贝叶斯推理为超参数调整添加了两个组件：元学习用于使用贝叶斯初始化优化器，并在优化过程中评估配置的自动集合构造。<br />Auto-SKLearn在中小型数据集上表现良好，但无法生成在大型数据集中具有最先进性能的现代深度学习系统。
<a name="s7OJN"></a>
### 例子
```python
import sklearn.model_selection
import sklearn.datasets
import sklearn.metrics

import autosklearn.regression

def main():
    X, y = sklearn.datasets.load_boston(return_X_y=True)
    feature_types = (['numerical'] * 3) + ['categorical'] + (['numerical'] * 9)
    X_train, X_test, y_train, y_test = \
    sklearn.model_selection.train_test_split(X, y, random_state=1)

    automl = autosklearn.regression.AutoSklearnRegressor(
        time_left_for_this_task=120,
        per_run_time_limit=30,
        tmp_folder='/tmp/autosklearn_regression_example_tmp',
        output_folder='/tmp/autosklearn_regression_example_out',
    )
    automl.fit(X_train, y_train, dataset_name='boston',
               feat_type=feature_types)

    print(automl.show_models())
predictions = automl.predict(X_test)
print("R2 score:", sklearn.metrics.r2_score(y_test, predictions))

if __name__ == '__main__':
    main()
```
<a name="NaRym"></a>
## **FeatureTools**
![](https://cdn.nlark.com/yuque/0/2023/jpeg/396745/1688951754965-de22c309-6651-4dbb-878f-02ef31afcc28.jpeg#averageHue=%23fae7c7&clientId=u72b9ff35-6f18-4&from=paste&id=uf2ddf677&originHeight=186&originWidth=800&originalType=url&ratio=2.5&rotation=0&showTitle=false&status=done&style=none&taskId=u65dadbab-fc31-4361-9660-fce11c08a11&title=)<br />它是用于自动功能工程的python库。
<a name="F4Zvp"></a>
### 安装
用pip安装
```bash
python -m pip install featuretools
```
或通过conda上的Conda-forge频道：
```bash
conda install -c conda-forge featuretools
```
<a name="Q5fBh"></a>
### **附加组件**
可以运行以下命令单独安装或全部安装附件
```bash
python -m pip install featuretools[complete]
```
更新检查器—接收有关FeatureTools新版本的自动通知
```bash
python -m pip install featuretools[update_checker]
```
TSFresh基本体-在Featuretools中使用tsfresh中的60多个基本体
```bash
python -m pip install featuretools[tsfresh]
```
<a name="btIbU"></a>
### 例子
```python
import featuretools as ft
es = ft.demo.load_mock_customer(return_entityset=True)
es.plot()
```
![](https://cdn.nlark.com/yuque/0/2023/jpeg/396745/1688951754967-81c84d62-c1d5-4b58-8c2c-2d70c0bf6ff2.jpeg#averageHue=%23ebebeb&clientId=u72b9ff35-6f18-4&from=paste&id=u0042a1d6&originHeight=473&originWidth=483&originalType=url&ratio=2.5&rotation=0&showTitle=false&status=done&style=none&taskId=u30d6856d-186e-449c-aaa8-1849610f511&title=)<br />Featuretools可以为任何"目标实体"自动创建一个特征表
```python
feature_matrix, features_defs = ft.dfs(entityset=es,  
                                       target_entity="customers")
feature_matrix.head(5)
```
![](https://cdn.nlark.com/yuque/0/2023/jpeg/396745/1688951755007-2b4ec32d-a41b-457d-a684-a221cc688d74.jpeg#averageHue=%23f3f4f6&clientId=u72b9ff35-6f18-4&from=paste&id=u931c9e59&originHeight=222&originWidth=1045&originalType=url&ratio=2.5&rotation=0&showTitle=false&status=done&style=none&taskId=u47cc3690-0922-4c1b-9f16-28b84c09ec7&title=)<br />官方网站：[https://featuretools.alteryx.com/cn/stable/](https://featuretools.alteryx.com/cn/stable/)
<a name="aAjOI"></a>
## **MLBox**
![](https://cdn.nlark.com/yuque/0/2023/jpeg/396745/1688951755032-f1ab5876-b8ec-41db-8335-8af3a9cedc6f.jpeg#averageHue=%23e9e9e8&clientId=u72b9ff35-6f18-4&from=paste&id=u951f25cf&originHeight=163&originWidth=699&originalType=url&ratio=2.5&rotation=0&showTitle=false&status=done&style=none&taskId=u06bfbe25-2c31-468d-8d0a-e2ade83f975&title=)<br />MLBox是功能强大的自动化机器学习python库。<br />根据官方文档，它具有以下功能：

- 快速读取和分布式数据预处理/清理/格式化
- 高度强大的功能选择和泄漏检测以及精确的超参数优化
- 最新的分类和回归预测模型（深度学习，堆叠，LightGBM等）
- 使用模型解释进行预测，MLBox已在Kaggle上进行了测试，并显示出良好的性能。
- 管道
<a name="tPjyS"></a>
### **MLBox体系结构**
MLBox主软件包包含3个子软件包：

- 预处理：读取和预处理数据
- 优化：测试或优化各种学习者
- 预测：预测测试数据集上的目标

官方网站：[https://github.com/AxeldeRomblay/MLBox](https://github.com/AxeldeRomblay/MLBox)
<a name="DYFfa"></a>
## **TPOT**
TPOT代表基于树的管道优化工具，它使用遗传算法优化机器学习管道.TPOT建立在scikit-learn的基础上，并使用自己的回归器和分类器方法。TPOT探索了数千种可能的管道，并找到最适合数据的管道。<br />TPOT通过智能地探索成千上万的可能管道来找到最适合数据的管道，从而使机器学习中最繁琐的部分自动化。<br />TPOT建立在scikit-learn的基础上，因此它生成的所有代码都应该看起来很熟悉……无论如何，如果熟悉scikit-learn。<br />TPOT仍在积极开发中。<br />下面是分类和回归问题的两个例子：
<a name="lnEQZ"></a>
### **分类**
这是具有手写数字数据集光学识别功能的示例。
```python
from tpot import TPOTClassifier
from sklearn.datasets import load_digits
from sklearn.model_selection import train_test_split
digits = load_digits()
X_train, X_test, y_train, y_test = train_test_split(digits.data, 
                                                    digits.target,
                                                    train_size=0.75, 
                                                    test_size=0.25, 
                                                    random_state=42)
tpot = TPOTClassifier(generations=5, population_size=50,
                      verbosity=2, random_state=42)
tpot.fit(X_train, y_train)
print(tpot.score(X_test, y_test))
tpot.export('tpot_digits_pipeline.py')
```
此代码将发现达到98％的测试精度的管道。应将相应的Python代码导出到tpot_digits_pipeline.py文件，其外观类似于以下内容：
```python
import numpy as np
import pandas as pd
from sklearn.ensemble import RandomForestClassifier
from sklearn.linear_model import LogisticRegression
from sklearn.model_selection import train_test_split
from sklearn.pipeline import make_pipeline, make_union
from sklearn.preprocessing import PolynomialFeatures
from tpot.builtins import StackingEstimator
from tpot.export_utils import set_param_recursive
# NOTE: Make sure that the outcome column is labeled 'target' in the data file
tpot_data = pd.read_csv('PATH/TO/DATA/FILE', sep='COLUMN_SEPARATOR', dtype=np.float64)
features = tpot_data.drop('target', axis=1)
training_features, testing_features, training_target, testing_target = \
train_test_split(features, tpot_data['target'], random_state=42)
# Average CV score on the training set was: 0.9799428471757372
exported_pipeline = make_pipeline(
    PolynomialFeatures(degree=2, include_bias=False, interaction_only=False),
    StackingEstimator(estimator=LogisticRegression(C=0.1, dual=False, penalty="l1")),
    RandomForestClassifier(bootstrap=True, criterion='entropy',
                           max_features=0.35000000000000003, 
                           min_samples_leaf=20, min_samples_split=19, 
                           n_estimators=100)
)
# Fix random state for all the steps in exported pipeline
set_param_recursive(exported_pipeline.steps, 'random_state', 42)
exported_pipeline.fit(training_features, training_target)
results = exported_pipeline.predict(testing_features)
```
<a name="DXImF"></a>
### **回归**
TPOT可以优化管道以解决回归问题。以下是使用波士顿房屋价格数据集的最小工作示例。
```python
from tpot import TPOTRegressor
from sklearn.datasets import load_boston
from sklearn.model_selection import train_test_split
housing = load_boston()
X_train, X_test, y_train, y_test = train_test_split(
    housing.data, 
    housing.target,
    train_size=0.75,
    test_size=0.25, 
    random_state=42)
tpot = TPOTRegressor(generations=5, population_size=50,
                     verbosity=2, random_state=42)
tpot.fit(X_train, y_train)
print(tpot.score(X_test, y_test))
tpot.export('tpot_boston_pipeline.py')
```
这将导致流水线达到约12.77均方误差（MSE），tpot_boston_pipeline.py中的Python代码应类似于：
```python
import numpy as np
import pandas as pd
from sklearn.ensemble import ExtraTreesRegressor
from sklearn.model_selection import train_test_split
from sklearn.pipeline import make_pipeline
from sklearn.preprocessing import PolynomialFeatures
from tpot.export_utils import set_param_recursive
# NOTE: Make sure that the outcome column is labeled 'target' in the data file
tpot_data = pd.read_csv('PATH/TO/DATA/FILE', 
                        sep='COLUMN_SEPARATOR', 
                        dtype=np.float64)
features = tpot_data.drop('target', axis=1)
training_features, testing_features, training_target, testing_target = \
train_test_split(features, tpot_data['target'], random_state=42)
# Average CV score on the training set was: -10.812040755234403
exported_pipeline = make_pipeline(
    PolynomialFeatures(degree=2, include_bias=False, interaction_only=False),
    ExtraTreesRegressor(bootstrap=False, max_features=0.5, 
                        min_samples_leaf=2, min_samples_split=3, 
                        n_estimators=100)
)
# Fix random state for all the steps in exported pipeline
set_param_recursive(exported_pipeline.steps, 'random_state', 42)
exported_pipeline.fit(training_features, training_target)
results = exported_pipeline.predict(testing_features)
```
Github链接：[https://github.com/EpistasisLab/tpot](https://github.com/EpistasisLab/tpot)
