<a name="ZNqMP"></a>
## 网络结构
<a name="XHTnl"></a>
### 单层网络

在学习RNN之前，首先要了解一下最基本的单层网络，它的结构如图：

![循环神经网络1.jpg](./img/1594208952331-3d63aaf3-a170-40e5-a4f9-9091aa1dd2e3.jpeg)

输入是![](./img/9dd4e461268c8034f5c8564e155c67a6.svg)，经过变换![](./img/ef5f803ab47334935a096430b3fc9cef.svg)和激活函数![](./img/8fa14cdd754f91cc6554c9e71929cce7.svg)得到输出![](./img/415290769594460e2e485922904f345d.svg)。相信大家对这个已经非常熟悉了。

<a name="b787140b"></a>
### 经典的RNN结构（N vs. N）

在实际应用中，我们还会遇到很多序列形的数据，比如：

![循环神经网络2.jpg](./img/1594209045700-4222ac2d-0842-4724-9cfc-23004f971e7e.jpeg)

- 自然语言处理问题。![](./img/aa687da0086c1ea060a8838e24611319.svg)可以看做是第一个单词，![](./img/8732099f74d777a67257cb2f04ead3d8.svg)可以看做是第二个单词，依次类推。
- 语音处理。此时，![](./img/de95d53b85506f74b051965f747e0445.svg)是每帧的声音信号。
- 时间序列问题。例如每天的股票价格等等。

序列形的数据就不太好用原始的神经网络处理了。为了建模序列问题，RNN引入了隐状态![](./img/2510c39011c5be704182423e3a695e91.svg)（hidden state）的概念，![](./img/2510c39011c5be704182423e3a695e91.svg)可以对序列形的数据提取特征，接着再转换为输出。先从![](./img/de8465d723217241a3096b8763f598fe.svg)的计算开始看：

![循环神经网络3.jpg](./img/1594209111806-231828b8-7325-43fe-a701-577375520507.jpeg)

图示中记号的含义是：

- 圆圈或方块表示的是向量。
- 一个箭头表示对该向量做一次变换。上图中![](./img/91923b083a33516b2ae173d6a93c2573.svg)和![](./img/aa687da0086c1ea060a8838e24611319.svg)分别有一个箭头连接，就表示对![](./img/91923b083a33516b2ae173d6a93c2573.svg)和![](./img/aa687da0086c1ea060a8838e24611319.svg)各做了一次变换。

在很多论文中也会出现类似的记号，初学的时候很容易搞乱，但只要把握住以上两点，就可以比较轻松地理解图示背后的含义。

![](./img/096cb9d94c653880be7ef740c2fb0dbd.svg)的计算和![](./img/de8465d723217241a3096b8763f598fe.svg)类似。要注意的是，在计算时，每一步使用的参数![](./img/4c614360da93c0a041b22e537de151eb.svg)，![](./img/61e9c06ea9a85a5088a499df6458d276.svg)，![](./img/92eb5ffee6ae2fec3ad71c777531578f.svg)都是一样的，也就是说每个步骤的参数都是共享的，这是RNN的重要特点，一定要牢记。

![循环神经网络4.jpg](./img/1594209307480-7d00d916-20f8-44a6-98ba-0a1705627c26.jpeg)

依次计算剩下来的（使用相同的参数![](./img/4c614360da93c0a041b22e537de151eb.svg)，![](./img/61e9c06ea9a85a5088a499df6458d276.svg)，![](./img/92eb5ffee6ae2fec3ad71c777531578f.svg)）：

![循环神经网络5.jpg](./img/1594209348102-050a2554-2f92-4c85-9fc6-27ec89219047.jpeg)

我们这里为了方便起见，只画出序列长度为4的情况，实际上，这个计算过程可以无限地持续下去。 我们目前的RNN还没有输出，得到输出值的方法就是直接通过![](./img/2510c39011c5be704182423e3a695e91.svg)进行计算：

![循环神经网络6.jpg](./img/1594209373118-c3104757-6e8b-46bd-9707-fd33bb908ddf.jpeg)

正如之前所说，一个箭头就表示对对应的向量做一次类似于![](./img/0d64a8a7911499f8381c0bcd7b75a832.svg)的变换，这里的这个箭头就表示对![](./img/de8465d723217241a3096b8763f598fe.svg)进行一次变换，得到输出![](./img/4764360e2689c701dfb8b917ba7638ac.svg)。剩下的输出类似进行（使用和![](./img/4764360e2689c701dfb8b917ba7638ac.svg)同样的参数![](./img/5206560a306a2e085a437fd258eb57ce.svg)和![](./img/4a8a08f09d37b73795649038408b5f33.svg)）：

![循环神经网络7.jpg](./img/1594209452425-fbb4bc4a-ebc4-409f-a663-96f4ff64db6b.jpeg)

OK！大功告成！这就是最经典的RNN结构，我们像搭积木一样把它搭好了。它的输入是![](./img/555cd1621a55204bccb1729027075f5b.svg)，输出为![](./img/198348ead1aa8653217dcd85c495ce1e.svg)，也就是说，输入和输出序列必须要是等长的。由于这个限制的存在，经典RNN的适用范围比较小，但也有一些问题适合用经典的RNN结构建模，如：

- 计算视频中每一帧的分类标签。因为要对每一帧进行计算，因此输入和输出序列等长。
- 输入为字符，输出为下一个字符的概率。这就是著名的[Char RNN](http://karpathy.github.io/2015/05/21/rnn-effectiveness/)，Char RNN可以用来生成文章，诗歌，甚至是代码，非常有意思。

<a name="6f0ff196"></a>
### N vs. 1

有的时候，我们要处理的问题输入是一个序列，输出是一个单独的值而不是序列，应该怎样建模呢？实际上，我们只在最后一个![](./img/2510c39011c5be704182423e3a695e91.svg)上进行输出变换就可以了：

![循环神经网络8.jpg](./img/1594209516247-2be0ff48-d0f8-41af-b612-1767ded26642.jpeg)

这种结构通常用来处理序列分类问题。如输入一段文字判别它所属的类别，输入一个句子判断其情感倾向，输入一段视频并判断它的类别等等。

<a name="693fefb1"></a>
### 1 vs. N

输入不是序列而输出为序列的情况怎么处理？我们可以只在序列开始进行输入计算：

![循环神经网络9.jpg](./img/1594209541394-4d2a9634-0176-4300-b7e8-df28a94f2837.jpeg)

还有一种结构是把输入信息![](./img/02129bb861061d1a052c592e2dc6b383.svg)作为每个阶段的输入：

![循环神经网络10.jpg](./img/1594209574066-daf4f649-a701-4856-8ba2-270d4f0c92ee.jpeg)

下图省略了一些![](./img/02129bb861061d1a052c592e2dc6b383.svg)的圆圈，是一个等价表示：

![循环神经网络11.jpg](./img/1594209617484-9cd51b97-415a-40fe-b709-543edef96842.jpeg)

这种1 VS N的结构可以处理的问题有：

- 从图像生成文字（image caption），此时输入的![](./img/02129bb861061d1a052c592e2dc6b383.svg)就是图像的特征，而输出的![](./img/415290769594460e2e485922904f345d.svg)序列就是一段句子
- 从类别生成语音或音乐等

<a name="19fcd212"></a>
### Seq2Seq或Encoder-Decoder（N vs. M）

下面我们来介绍RNN最重要的一个变种：N vs M。这种结构又叫Encoder-Decoder模型，也可以称之为Seq2Seq模型。原始的N vs. N RNN要求序列等长，然而我们遇到的大部分问题序列都是不等长的，如机器翻译中，源语言和目标语言的句子往往并没有相同的长度。

为此，Encoder-Decoder结构先将输入数据编码成一个上下文向量![](./img/4a8a08f09d37b73795649038408b5f33.svg)：

![循环神经网络12.jpg](./img/1594209660350-b74e1bff-695d-4fbd-9024-268404b49e8a.jpeg)

得到![](./img/4a8a08f09d37b73795649038408b5f33.svg)有多种方式，最简单的方法就是把Encoder的最后一个隐状态赋值给![](./img/4a8a08f09d37b73795649038408b5f33.svg)，还可以对最后的隐状态做一个变换得到![](./img/4a8a08f09d37b73795649038408b5f33.svg)，也可以对所有的隐状态做变换。拿到![](./img/4a8a08f09d37b73795649038408b5f33.svg)之后，就用另一个RNN网络对其进行解码，这部分RNN网络被称为Decoder。具体做法就是将![](./img/4a8a08f09d37b73795649038408b5f33.svg)当做之前的初始状态![](./img/91923b083a33516b2ae173d6a93c2573.svg)输入到Decoder中：

![循环神经网络13.jpg](./img/1594209718335-443b9edd-a740-404f-b0b3-cbe4e90bd08d.jpeg)

还有一种做法是将![](./img/4a8a08f09d37b73795649038408b5f33.svg)当做每一步的输入：

![循环神经网络14.jpg](./img/1594209746704-a3f46c68-6d4e-49fd-9aeb-98c52d9dcdcc.jpeg)

由于这种Encoder-Decoder结构不限制输入和输出的序列长度，因此应用的范围非常广泛，比如：

- 机器翻译。Encoder-Decoder的最经典应用，事实上这一结构就是在机器翻译领域最先提出的
- 文本摘要。输入是一段文本序列，输出是这段文本序列的摘要序列。
- 阅读理解。将输入的文章和问题分别编码，再对其进行解码得到问题的答案。
- 语音识别。输入是语音信号序列，输出是文字序列。
- ... ... ...

---

<a name="6ROJs"></a>
## 网络计算
<a name="yW5Ku"></a>
### 前向传播

现在我们研究每个时间步都有输出，并且隐藏单元之间有循环连接的循环网络的前向传播公式，即下图

![循环神经网络15.png](./img/1594209937217-f107a094-ac98-431a-8107-87a985734f15.png)

这幅图描述了在序列索引号![](./img/e358efa489f58062f10dd7316b65649e.svg)附近RNN的模型。其中：

- ![](./img/df9ed87e836e463cd086106035aef441.svg)代表在序列![](./img/e358efa489f58062f10dd7316b65649e.svg)时训练样本的输入。![](./img/b2e102dbadf86ad5f14f1431a8c37f55.svg)和![](./img/b0335cb5ff7ba1667845bf522077afb9.svg)代表在序列索引号![](./img/f3e90ce87a25538f5a4be79a0a7c0fa5.svg)和![](./img/43c98a64bcde4857b095743482e04281.svg)时训练样本的输入。
- ![](./img/7ddb4d2d45df22e2e98e6cc504f84787.svg)代表在序列![](./img/e358efa489f58062f10dd7316b65649e.svg)时模型的隐藏状态。![](./img/7ddb4d2d45df22e2e98e6cc504f84787.svg)是由![](./img/df9ed87e836e463cd086106035aef441.svg)和![](./img/c94af4bec72c7e4e9e8f713c23232809.svg)共同决定。
- ![](./img/8c4d6f1775020db40e7f11387a98b5ab.svg)代表在序列![](./img/e358efa489f58062f10dd7316b65649e.svg)时模型的输出。![](./img/8c4d6f1775020db40e7f11387a98b5ab.svg)只由模型当前的隐藏状态![](./img/7ddb4d2d45df22e2e98e6cc504f84787.svg)决定。
- ![](./img/3d9ccffc800b57feea658aef54997556.svg)代表在序列![](./img/e358efa489f58062f10dd7316b65649e.svg)时模型的损失函数。
- ![](./img/cc685401bcf131ce4e9f980be319daac.svg)代表在序列![](./img/e358efa489f58062f10dd7316b65649e.svg)时训练样本序列的真实输出。
- ![](./img/f9f49c7f43b0cf3a53af5de93670a077.svg)这三个矩阵是我们的模型的线性关系参数，它在整个RNN网络中是共享的。也正因为是共享的，它体现了RNN的模型的“循环反馈”的思想。

有了上面的模型，RNN的前向传播算法就很容易得到了：

对于任意一个序列索引号![](./img/e358efa489f58062f10dd7316b65649e.svg)，我们隐藏状态![](./img/7ddb4d2d45df22e2e98e6cc504f84787.svg)由![](./img/df9ed87e836e463cd086106035aef441.svg)和![](./img/c94af4bec72c7e4e9e8f713c23232809.svg)得到：

![](./img/8a345b1d68a86aed4bb9dbeb6db1847e.svg)

其中![](./img/a2ab7d71a0f07f388ff823293c147d21.svg)为RNN的激活函数，一般为tanh，[RNN为什么采用tanh而不是ReLU](https://www.zhihu.com/question/61265076/answer/186347780)，![](./img/92eb5ffee6ae2fec3ad71c777531578f.svg)为线性关系的偏倚。

序列索引号![](./img/e358efa489f58062f10dd7316b65649e.svg)时的模型的输出![](./img/8c4d6f1775020db40e7f11387a98b5ab.svg)的表达式比较简单：

![](./img/4f29f728944c9fb3cde6ba9109dd488c.svg)

在最终在序列索引号![](./img/e358efa489f58062f10dd7316b65649e.svg)时我们的预测输出为：

![](./img/0d56228ac99c7a8a36cf3d3118c854c9.svg)

通常RNN是分类模型，所以上面这个激活函数![](./img/88207bc086c9d879c22807479d29a9e2.svg)一般是softmax。

通过损失函数![](./img/3d9ccffc800b57feea658aef54997556.svg)，比如对数似然损失函数，我们可以量化模型在当前位置的损失，即![](./img/fa4e04067b77cfdc467e93b93128db42.svg)和![](./img/cc685401bcf131ce4e9f980be319daac.svg)差距

<a name="xEJao"></a>
### 反向传播

RNN反向传播算法的思路和DNN是一样的，即通过梯度下降法一轮轮的迭代，得到合适的RNN模型参数![](./img/9e6d285122b69c9be04d0f72b5fb8681.svg)。由于我们是基于时间反向传播，所以RNN的反向传播有时也叫做BPTT（back-propagation through time）。当然这里的BPTT和DNN也有很大的不同点，即这里所有的![](./img/9e6d285122b69c9be04d0f72b5fb8681.svg)在序列的各个位置是共享的，反向传播时我们更新的是相同的参数。

为了简化描述，这里的损失函数我们为对数损失函数，输出的激活函数为softmax函数，隐藏层的激活函数为tanh函数。对于RNN，由于我们在序列的每个位置都有损失函数，因此最终的损失![](./img/d20caec3b48a1eef164cb4ca81ba2587.svg)为：

![](./img/e2e6aaa6738592b9dbb7791d13e7d643.svg)

由![](./img/4f29f728944c9fb3cde6ba9109dd488c.svg)，可计算![](./img/320f4bd58c6372053121bc249fe15cfd.svg)的梯度：

![](./img/6d4effa64e6d859c4d56b70a6a38d789.svg)<br />![](./img/0fb9e8c31349056d16952742f0d7691a.svg)

对于![](./img/4a8a08f09d37b73795649038408b5f33.svg)的求导，，由于激活函数是softmax，损失函数是对数损失，因此该推导过程与[深度学习（二）：DNN损失函数和激活函数的选择](https://blog.csdn.net/anshuai_aw1/article/details/84666595)里的公式（4）完全一样。

对于![](./img/5206560a306a2e085a437fd258eb57ce.svg)的求导，为什么![](./img/31512fd1a11eca7ffea94a0845c2c203.svg)会放在后面，那是因为在实际矩阵求导得链式法则里面，对于两步的链式法则：

（1）如果是**标量对矩阵求导**改成链式法则，那么求导得后半部分不用提前。比如![](./img/26d63478e01213a317db1123c14d2759.svg)，![](./img/b3a9f7c7e22a9f6ac359493f5db60902.svg)，![](./img/415290769594460e2e485922904f345d.svg)为标量，![](./img/92e6e966ba9009c07fcd84c2d5f9a6eb.svg)为矩阵，则：![](./img/f4d31935e67c07a77065dacde722a67f.svg)

（2）如果是**标量对向量求导**改成链式法则，那么求导得后半部分不用提前。比如![](./img/26d63478e01213a317db1123c14d2759.svg)，![](./img/b3a9f7c7e22a9f6ac359493f5db60902.svg)，![](./img/415290769594460e2e485922904f345d.svg)为标量，![](./img/92e6e966ba9009c07fcd84c2d5f9a6eb.svg)为向量，则：![](./img/a3dea697f613e24c273ea019b8226fbb.svg)

但是![](./img/abbc2f464e886fd7ac047843aa7c83f8.svg)的梯度计算就比较复杂了。从RNN的模型可以看出，在反向传播时，在某一序列位置![](./img/e358efa489f58062f10dd7316b65649e.svg)的梯度损失由当前位置的输出对应的梯度损失和序列索引位置![](./img/f3e90ce87a25538f5a4be79a0a7c0fa5.svg)时的梯度损失两部分共同决定。对于![](./img/61e9c06ea9a85a5088a499df6458d276.svg)在某一序列位置![](./img/e358efa489f58062f10dd7316b65649e.svg)的梯度损失需要反向传播一步步的计算。我们定义序列索引![](./img/e358efa489f58062f10dd7316b65649e.svg)位置的隐藏状态的梯度为

![](./img/a818e6602d8ff2c77b4096e70be70dd4.svg)

这里我们可以像DNN一样从![](./img/8680cca8c65ec8ed738ad012274c737d.svg)递推![](./img/bdc754d8fab41fde84cf4972b43a98c4.svg)<br />![](./img/e8b2a8d253b271c915dc9c002f4076e8.svg)<br />![](./img/a9c6e1ea64b6bbb66004572025f14d09.svg)

上面第一个公式中两部分相加的原因是：

![](./img/6b5ffb0ec0b9d497cec8c416148174a0.svg)    ![](./img/b0b495f01c36539f5b4730c3f8872af1.svg)

所以![](./img/d20caec3b48a1eef164cb4ca81ba2587.svg)对![](./img/7ddb4d2d45df22e2e98e6cc504f84787.svg)求导时，要分别经过![](./img/8c4d6f1775020db40e7f11387a98b5ab.svg)和![](./img/68cdb063b712f1abbfb9fb55ee8873a5.svg)对![](./img/7ddb4d2d45df22e2e98e6cc504f84787.svg)进行求导。

![](./img/e639619b837264a85fde76fb81c6a079.svg)的导数是![](./img/374f2cfc9182f68ff4f171e0e205cac8.svg)，这是显然的。重点是![](./img/4d47790df7fd11ca38432785b8ace20c.svg)的导数怎么求。根据公式

![](./img/8a345b1d68a86aed4bb9dbeb6db1847e.svg)

在前面我们假设隐含层的激活函数是tanh，即![](./img/9008ec1194310ee34476696bf91cec14.svg)，它的导数为![](./img/0a0ffe79642525533d8c1e382acc946c.svg)。结合[深度学习（一）：DNN前向传播算法和反向传播算法](https://blog.csdn.net/anshuai_aw1/article/details/84615935)中公式（12），有

![](./img/2d4c137cdedb4ada64f50ee74bbe4ee9.svg)

这里是双曲正切激活函数，矩阵中对角线元素表示向量中各个值的导数，可以去掉哈达马乘积，转化为矩阵乘法

对于![](./img/3e13fbbb753493c11fe0e82aa92ce1ee.svg)，正确的运算顺序应该是先![](./img/b9b8e4ba993827528722b758d9fa399e.svg)（注意这里的哈德玛乘积的意思，即![](./img/7b8b965ad4bca0e41ab51de7b31363a1.svg)个元素对应位置相乘，并非![](./img/cf205bf19d67d9f03972f2ae9ff39649.svg)乘以![](./img/cf1193335575230a1a03e9457c55b6f7.svg)），然后再用![](./img/38d04439dc07f53e1769841958502dc1.svg)与上面的结果运算。即先进行哈德玛乘积。

有了![](./img/bdc754d8fab41fde84cf4972b43a98c4.svg)，计算![](./img/abbc2f464e886fd7ac047843aa7c83f8.svg)就容易了，这里给出对应的梯度计算表达式：

![](./img/f605e0e4cbd694a8538788c195a59ede.svg)<br />![](./img/5c1dd162085d0a519fcfab4889dca11d.svg)<br />![](./img/542c201c1e17ad9354c0b35f2aed5683.svg)

<a name="d99ae3b1"></a>
## 双向RNN

前为止我们考虑的所有循环神经网络有一个“因果”结构，意味着在时刻![](./img/e358efa489f58062f10dd7316b65649e.svg)的状态只能从过去的序列![](./img/6acd9c58c0c3eba9b8abf644bd9b9b23.svg)以及当前的输入![](./img/df9ed87e836e463cd086106035aef441.svg)捕获信息。然而，在许多应用中，我们要输出的![](./img/cc685401bcf131ce4e9f980be319daac.svg)的预测可能依赖于整个输入序列。例如，在语音识别中，由于协同发音，当前声音作为音素的正确解释可能取决于未来几个音素，甚至潜在的可能取决于未来的几个词，因为词与附近的词之间的存在语义依赖：如果当前的词有两种声学上的合理的解释，我们可能要在更远的未来（和过去）寻找信息区分它们。这在手写识别和许多其他序列到序列学习的任务中也是如此。

双向循环神经网络（或双向RNN）为满足这种需要而被发明。顾名思义，双向RNN结合时间上从序列起点开始移动的RNN和另一个时间上从序列末尾开始移动的RNN。下图展示了典型的双向RNN，其中![](./img/7ddb4d2d45df22e2e98e6cc504f84787.svg)代表通过时间向前移动的子RNN的状态，![](./img/ededcb90b8071069a783dea14b4aad14.svg)代表通过时间向后移动的子RNN的状态。这允许输出单元![](./img/8c4d6f1775020db40e7f11387a98b5ab.svg)能够计算同时依赖于过去和未来且对时刻![](./img/e358efa489f58062f10dd7316b65649e.svg)的输入值最敏感的表示，而不必指定![](./img/e358efa489f58062f10dd7316b65649e.svg)周围固定大小的窗口。

![循环神经网络16.png](./img/1594260886226-9ec9c075-38bd-4dc4-8826-b96b905e5d68.png)

这个想法可以自然地扩展到![](./img/c81e728d9d4c2f636f067f89cc14862c.svg)维输入，如图像，由四个RNN组成，每一个沿着四个方向中的一个计算：上、下、左、右。如果RNN能够学习到承载长期信息，那在![](./img/c81e728d9d4c2f636f067f89cc14862c.svg)维网格每个点![](./img/5270ae675fac24f97e172dcd9b18fa92.svg)的输出![](./img/5f85be5adfe009a3c47a850d65c84013.svg)就能计算一个能捕捉到大多局部信息但仍依赖于长期输入的表示。相比卷积网络，应用于图像的RNN计算成本通常更高，但允许同一特征图的特征之间存在长期横向的相互作用。实际上，对于这样的RNN，前向传播公式可以写成表示使用卷积的形式，计算自底向上到每一层的输入（在整合横向相互作用的特征图的循环传播之前）。

<a name="Source"></a>
## Source
[https://zhuanlan.zhihu.com/p/28054589](https://zhuanlan.zhihu.com/p/28054589)<br />[https://blog.csdn.net/anshuai_aw1/article/details/85163572](https://blog.csdn.net/anshuai_aw1/article/details/85163572)<br />[https://blog.csdn.net/anshuai_aw1/article/details/84666595](https://blog.csdn.net/anshuai_aw1/article/details/84666595)<br />[https://blog.csdn.net/anshuai_aw1/article/details/84615935](https://blog.csdn.net/anshuai_aw1/article/details/84615935)
