深度前馈网络(前馈神经网络或者多层感知机)，是典型的深度学习模型。[http://playground.tensorflow.org/](http://playground.tensorflow.org/)

前馈神经网络之所以被称作网络，是因为它们通常用许多不同函数复合在一起来表示。该模型与一个有向无环图相关联，而图描述了函数是如何复合在一起的。例如，我们有三个函数![](./img/08f7ba51a24f15b334b4429434f79f4a.svg)、![](./img/55873f46509fffb2a72fa7d850c2a308.svg)和![](./img/68e66c8dc6112bf24c5e9b3a4dae44f2.svg)连接在一个链上以形成![](./img/b67130b494021cc038bf0bd90931b105.svg)。在这种情况下，

- ![](./img/08f7ba51a24f15b334b4429434f79f4a.svg)被称为网络的**第一层**，![](./img/55873f46509fffb2a72fa7d850c2a308.svg)被称为**第二层**，以此类推。链的全长称为模型的**深度**。正是因为这个术语才出现了“深度学习”这个名字。
- 前馈网络的最后一层被称为**输出层**。
- 每个样本![](./img/9dd4e461268c8034f5c8564e155c67a6.svg)都伴随着一个标签![](./img/205240d6e6e3b1eb6e7c5f11e579c7eb.svg)。训练样本直接指明了输出层在每一点![](./img/9dd4e461268c8034f5c8564e155c67a6.svg)上必须产生一个接近![](./img/415290769594460e2e485922904f345d.svg)的值。但是训练数据并没有直接指明其他层应该怎么做，因为训练数据并没有给出这些层中的每一层所需的输出，所以这些层被称为**隐藏层**。

这些网络之所以被称为神经网络，是因为受到神经科学的启发。网络中的每个隐藏层通常都是向量值的。这些隐藏层的维数决定了模型的**宽度**。向量的每个元素都可以被视为起到类似一个神经元的作用。除了将层想象成向量到向量的单个函数，我们也可以把层想象成由许多并行操作的**单元**组成，每个单元表示一个向量到标量的函数。每个单元在某种意义上类似一个神经元，它接收的输入来源于许多其他的单元，并计算它自己的激活值。

一种理解前馈网络的方式是从线性模型开始，并考虑如何克服它的局限性。线性模型，例如逻辑回归和线性回归，无论是通过闭式解还是凸优化，它们都能高效且可靠地拟合。线性模型也有明显缺陷，那就是模型的能力被局限在线性函数里，所以它无法理解任何两个输入变量间的相互作用。

为了扩展线性模型来表示![](./img/9dd4e461268c8034f5c8564e155c67a6.svg)的非线性函数，我们可以不把线性模型用于![](./img/9dd4e461268c8034f5c8564e155c67a6.svg)本身，而是用在一个变换后的输入![](./img/163cde00287e629f33dae509a8414505.svg)上。这里![](./img/163cde00287e629f33dae509a8414505.svg)是一个非线性变换。例如核技巧，得到一个基于隐含地使用![](./img/1ed346930917426bc46d41e22cc525ec.svg)映射的非线性学习算法。我们可认为![](./img/1ed346930917426bc46d41e22cc525ec.svg)提供了一组描述![](./img/9dd4e461268c8034f5c8564e155c67a6.svg)的特征，或者认为它提供了![](./img/9dd4e461268c8034f5c8564e155c67a6.svg)的一个新的表示。剩下的问题就是如何选择映射![](./img/1ed346930917426bc46d41e22cc525ec.svg)：

- 使用一个通用![](./img/1ed346930917426bc46d41e22cc525ec.svg)，例如无限维的![](./img/1ed346930917426bc46d41e22cc525ec.svg)，它隐含地用在基于RBF核的核机器上。如果![](./img/163cde00287e629f33dae509a8414505.svg)具有足够高的维数，我们总是有足够的能力来拟合训练集，但是对于测试集的泛化往往不佳。非常通用的特征映射通常只基于局部光滑的原则，并且没有将足够的先验信息进行编码来解决高级问题。
- 另一种选择是手动设计![](./img/1ed346930917426bc46d41e22cc525ec.svg)。在深度学习出现以前，这一直是主流方法。这种方法对于每个单独的任务都需要人们大量的努力，并且不同领域之间很难迁移。
- 深度学习的策略是去学习![](./img/1ed346930917426bc46d41e22cc525ec.svg)。在这种方法中，我们有一个模型![](./img/1d72e967d65c71c1223cf4e682b84286.svg)我们现在有两种参数：用于从一大类函数中学习![](./img/1ed346930917426bc46d41e22cc525ec.svg)的参数![](./img/2554a2bb846cffd697389e5dc8912759.svg)，以及用于将![](./img/163cde00287e629f33dae509a8414505.svg)映射到所需的输出的参数![](./img/f1290186a5d0b1ceab27f4e77c0c5d68.svg)。这是深度前馈网络的一个例子，其中![](./img/1ed346930917426bc46d41e22cc525ec.svg)定义了一个一个隐藏层。这是三种方法中唯一一种放弃训练问题的凸性的方法，但是利大于弊。在这种方法中，我们将表示参数化为![](./img/37ed9b0a40e6d8c6a045b7964a523c9d.svg)，并且使用优化算法来寻找![](./img/2554a2bb846cffd697389e5dc8912759.svg)，使它能够得到一个好的表示。
