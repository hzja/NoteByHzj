# 模型
## 一生三
基于小学数学知识我们可知![](./img/378a1b3c4cc62e63c5c66edadf0ce5b4.svg)是一条直线，确定了![](./img/df976ff7fcf17d60490267d18a1e3996.svg)和![](./img/d29c2e5f4926e5b0e9a95305650f6e54.svg)就可以在图上画出一条直线。算法最基础本质的任务其实就是：**确定参数**![](./img/df976ff7fcf17d60490267d18a1e3996.svg)**和**![](./img/d29c2e5f4926e5b0e9a95305650f6e54.svg)**，找到这条直线**。如下图，

- 左图(分类)：一条最合适的线区分两种点，比如横轴为体重，纵轴为身高，红蓝为男女
- 右图(回归)：一条线拟合点的趋势，比如0-20岁体重变化

![分类](./img/1676369330319-3defa5c5-3c98-41fd-9c4b-41d72cc74ca7.png "分类")![回归](./img/1676379618273-3217bd9f-ba20-4168-8c4a-450f0f164a4b.png "回归")

从一元推广到多元(多个![](./img/712ecf7894348e92d8779c3ee87eeeb0.svg)，即有多个自变量)，我们把斜率![](./img/df976ff7fcf17d60490267d18a1e3996.svg)换成权重![](./img/c9b08ae6d9fed72562880f75720531bc.svg)，![](./img/bf98c0ddcbe9c1e535f767c78c3aa813.svg)换成函数![](./img/3818937ac554603003e6727783932e9f.svg)表示：

![](./img/dfefb01ac30516bc7009faaadab77257.svg)

一切的起点就是![](./img/95ad841d9246fc7919a80c26c217872b.svg)，只不过做了不同方面的优化

- ![](./img/0ff70ab130c5d08171396ccc7f2ff807.svg)，对![](./img/d29c2e5f4926e5b0e9a95305650f6e54.svg)做优化，引出了[岭回归](https://www.yuque.com/angsweet/machine-learning/ji-qi-xue-xi_ji-qi-xue-xi_xian-xing-mo-xing#a3929cd4)、[Lasso](https://www.yuque.com/angsweet/machine-learning/ji-qi-xue-xi_ji-qi-xue-xi_xian-xing-mo-xing#a3929cd4)、[弹性网络](https://www.yuque.com/angsweet/machine-learning/ji-qi-xue-xi_ji-qi-xue-xi_xian-xing-mo-xing#a3929cd4)等模型
- ![](./img/6b7a8100bbc5ba49c42857b40077f69b.svg)，对![](./img/f2f2ff5930e59ba7833fad13e384dcc0.svg)做优化，引出了[SVM](https://www.yuque.com/angsweet/machine-learning/ji-qi-xue-xi_ji-qi-xue-xi_zhi-chi-xiang-liang-ji)、[FM](https://www.yuque.com/angsweet/machine-learning/bcfpcs#Hyc1X)、[FFM](https://www.yuque.com/angsweet/machine-learning/bcfpcs#4JrZP)等模型
- ![](./img/20c7af7fa8f329d58045ad5a26c8496a.svg)，在外部添加映射(激活)函数，引出了[LR](https://www.yuque.com/angsweet/machine-learning/ji-qi-xue-xi_ji-qi-xue-xi_xian-xing-mo-xing#6993c24f)、[DNN(MLP)](https://www.yuque.com/angsweet/machine-learning/cugayd)等模型



## 非线性
这里针对第一种(对![](./img/d29c2e5f4926e5b0e9a95305650f6e54.svg)做优化)暂时不做展开，重点讲一下后两种，因为我们问题变了，或者说实际问题要比上面图里举得例子复杂得多，比如下图，需要一条曲线才能分开两类点，即大多数实际问题都是非线性的，需要非线性方法解决，后两种优化即可实现非线性变化

![image.png](./img/1676369342485-68644794-ac0d-4bd8-b12a-4f07b808f627.png)



### 升维度
![](./img/6b7a8100bbc5ba49c42857b40077f69b.svg)，对![](./img/f2f2ff5930e59ba7833fad13e384dcc0.svg)做优化，既然二维解决不了问题，那就升维度，像下面的北京四合院，想画出右下图绿线区分阴影和红门怎么画，二维非线性，但可能升到三维就是线性了

![image.png](./img/1676380756146-3058d463-4b3c-4077-9b42-946e6fc13024.png)![image.png](./img/1676380778273-d01d07b4-7011-4e45-804f-74ced094bdfd.png)![image.png](./img/1676380794413-2289de12-62a2-46ba-9dbf-58567f778914.png)<br />组合自变量特征，根据组合方式不同即为不同模型：

   - [SVM](https://www.yuque.com/angsweet/machine-learning/ji-qi-xue-xi_ji-qi-xue-xi_zhi-chi-xiang-liang-ji)：![](./img/71ab2106d261afd892c7cc12fbf52a6e.svg)，![](./img/9a9e98a117f4839e96cac1caae47e71b.svg)为特征组合参数
   - [FM](https://www.yuque.com/angsweet/machine-learning/bcfpcs#Hyc1X)：![](./img/c81b3213c98036c7dd5b3e55f336c97f.svg)，![](./img/a0ba7207f6a43b51bd8296613a9e2306.svg)为特征向量内积
   - [FFM](https://www.yuque.com/angsweet/machine-learning/bcfpcs#4JrZP)：![](./img/af9aaafc33b0ffb3b72250725b66cd0a.svg)，![](./img/b91fa0b63bfbb71fa154593017ba5acc.svg)为特征场矩阵

![SVM](./img/1676381589629-375cdf96-36eb-4823-a3a1-b50d432c42ac.png "SVM")![FM](./img/1676381568586-a0b40822-43c7-4bb6-b366-7eac6439caca.png "FM")![FFM](./img/1676381650000-473cd77c-7810-477c-b417-9e8941764b9b.png "FFM")

### 拆任务
![](./img/20c7af7fa8f329d58045ad5a26c8496a.svg)，在外部添加映射(激活)函数，即将线性的输出通过特定的映射(激活)函数![](./img/788df1ba344b3092def7590d1be6b4d4.svg)映射到另一维度，从而实现非线性变化，[多个这种非线性模块组合在一起理论上就能解决所有问题(万能近似定理)](https://www.yuque.com/angsweet/machine-learning/shen-du-xue-xi_shen-du-xue-xi_readme)：

   - [LR](https://www.yuque.com/angsweet/machine-learning/ji-qi-xue-xi_ji-qi-xue-xi_xian-xing-mo-xing#6993c24f)：![](./img/20c7af7fa8f329d58045ad5a26c8496a.svg)，![](./img/788df1ba344b3092def7590d1be6b4d4.svg)为sigmoid![](./img/3e9b40a6f895944da6aab573b736f77a.svg)，代入即![](./img/77d6080d3fe23fbc7edf4905e44ceed9.svg)
   - [DNN](https://www.yuque.com/angsweet/machine-learning/cugayd)：![](./img/20c7af7fa8f329d58045ad5a26c8496a.svg)，![](./img/788df1ba344b3092def7590d1be6b4d4.svg)为ReLU等[激活函数](https://www.yuque.com/angsweet/machine-learning/shen-du-xue-xi_shen-du-xue-xi_shen-du-qian-kui-wang-luo_ji-huo-han-shu)，多个连接即DNN，如下图

![playground.tensorflow.org](./img/1676427705268-a85d669f-f94b-4825-8e3f-c4ef6374e897.gif "playground.tensorflow.org")

## 殊同归
实践上将两者相结合，发现效果有进一步提升，引出了目前互联网公司主流的两个推荐模型

   - [wide&deep](https://www.yuque.com/angsweet/machine-learning/qhvt6g)：LR+DNN
   - [deepFM](https://www.yuque.com/angsweet/machine-learning/gzs4s6)：FM+DNN

![wide&deep](./img/1604474608850-b4cdfdf9-a9e9-4474-acc1-7d7edf769d83.jpeg "wide&deep")![deepFM](./img/1608262322635-4cb26645-06c4-4fb0-ac7d-47db98a3e102.jpeg "deepFM")

---


# 求参
就像最开始说的，![](./img/378a1b3c4cc62e63c5c66edadf0ce5b4.svg)是一条直线，确定了![](./img/df976ff7fcf17d60490267d18a1e3996.svg)和![](./img/d29c2e5f4926e5b0e9a95305650f6e54.svg)就可以在图上画出一条直线。算法最基础本质的任务其实就是：**确定参数**![](./img/df976ff7fcf17d60490267d18a1e3996.svg)**和**![](./img/d29c2e5f4926e5b0e9a95305650f6e54.svg)**，找到这条直线**。这一部分我们聊一聊怎么确定参数![](./img/df976ff7fcf17d60490267d18a1e3996.svg)和，这里直接以最火的深度学习模型做讲解，更详细的论述见[深度学习](https://www.yuque.com/angsweet/machine-learning/shen-du-xue-xi_shen-du-xue-xi_readme)

## 深度学习
![playground.tensorflow.org](./img/1676427705268-a85d669f-f94b-4825-8e3f-c4ef6374e897.gif "playground.tensorflow.org")
### 多层结构
![image.png](./img/1688613920350-acaab5d5-c0e7-4bb5-b2e0-6cd9579edf92.png)
### 链式法则

![image.png](./img/1688613803290-31109511-e2a4-48cb-91e8-3460d7ca5246.png)

### 前馈传播
![image.png](./img/1688613854908-187abf22-0359-45e8-913e-124dbcaefba1.png)
### 反向传播
![image.png](./img/1688613873983-31cd0e66-6be5-479f-8b48-ad43cdf4fca9.png)
## 梯度下降

![牛顿法](./img/1676864647030-f4d913eb-13ac-442c-9c93-66e9d1af7b28.gif "牛顿法")



# 数据

我们了解了模型，就需要有数据输入去喂给模型，让其通过数据的学习，学到人为解决问题的经验。

