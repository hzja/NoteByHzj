<a name="KwpYW"></a>
# 建模
```python
# 在应用RFormula和转换Dataframe之后，我们现在需要根据这些数据开发机器学习模型。
# 我想为这个任务应用一个随机森林回归。让我们导入一个在pyspark.ml中定义的随机森林回归器。
# 然后建立一个叫做rf的模型。我将使用随机森林算法的默认参数。
from pyspark.ml.regression import RandomForestRegressor
rf = RandomForestRegressor()

# 在创建一个模型rf之后，我们需要将train1数据划分为train_cv和test_cv进行交叉验证。
# 这里，我们将train1数据区域划分为train_cv的70%和test_cv的30%。
(train_cv, test_cv) = train1.randomSplit([0.7, 0.3])

# 在train_cv上建立模型，在test_cv上进行预测。结果将保存在predictions中。
model1 = rf.fit(train_cv)
predictions = model1.transform(test_cv)
```
<a name="jiUIP"></a>
# 评估
```python
# 让我们评估对test_cv的预测，看看rmse和mse是多少。
# 为了评估模型，我们需要从pyspark.ml.evaluation中导入RegressionEvaluator。
# 我们必须为此创建一个对象。有一种方法叫 evaluate for evaluator ，它对模型求值。
# 我们需要为此指定度量标准。
from pyspark.ml.evaluation import RegressionEvaluator
evaluator = RegressionEvaluator()
mse = evaluator.evaluate(predictions,{evaluator.metricName:"mse" })
import numpy as np
np.sqrt(mse), mse
(3832.4796474051345, 14687900.247774584)

# 经过计算，我们可以看到我们的rmse是3827.767295494888。
# 现在，我们将在所有的train1数据集上再次训练一个模型。
model = rf.fit(train1)
predictions1 = model.transform(test1)

# 预测之后，我们得到测试集预测结果，并将其保存成csv文件。
df = predictions1.selectExpr("User_ID as User_ID", "Product_ID as Product_ID", 'prediction as Purchase')
df.toPandas().to_csv('./BlackFriday/submission.csv')
# 写入csv文件后(submission.csv)。我们可以上传我们的第一个解决方案来查看分数，
# 我得到的分数是3844.20920145983。
```
<a name="TGEz6"></a>
# Source
[https://zhuanlan.zhihu.com/p/52753778](https://zhuanlan.zhihu.com/p/52753778)
