# åŸåˆ›
ï¼š  [è®ºæ–‡é˜…è¯»] (14)è‹±æ–‡è®ºæ–‡å®éªŒè¯„ä¼°ï¼ˆEvaluationï¼‰å¦‚ä½•æ’°å†™åŠç²¾å¥æ‘˜æŠ„ï¼ˆä¸Šï¼‰â€”â€”ä»¥å…¥ä¾µæ£€æµ‹ç³»ç»Ÿ(IDS)ä¸ºä¾‹

# [è®ºæ–‡é˜…è¯»] (14)è‹±æ–‡è®ºæ–‡å®éªŒè¯„ä¼°ï¼ˆEvaluationï¼‰å¦‚ä½•æ’°å†™åŠç²¾å¥æ‘˜æŠ„ï¼ˆä¸Šï¼‰â€”â€”ä»¥å…¥ä¾µæ£€æµ‹ç³»ç»Ÿ(IDS)ä¸ºä¾‹

ã€Šå¨œç’‹å¸¦ä½ è¯»è®ºæ–‡ã€‹ç³»åˆ—ä¸»è¦æ˜¯ç£ä¿ƒè‡ªå·±é˜…è¯»ä¼˜ç§€è®ºæ–‡åŠå¬å–å­¦æœ¯è®²åº§ï¼Œå¹¶åˆ†äº«ç»™å¤§å®¶ï¼Œå¸Œæœ›æ‚¨å–œæ¬¢ã€‚ç”±äºä½œè€…çš„è‹±æ–‡æ°´å¹³å’Œå­¦æœ¯èƒ½åŠ›ä¸é«˜ï¼Œéœ€è¦ä¸æ–­æå‡ï¼Œæ‰€ä»¥è¿˜è¯·å¤§å®¶æ‰¹è¯„æŒ‡æ­£ï¼Œéå¸¸æ¬¢è¿å¤§å®¶ç»™æˆ‘ç•™è¨€è¯„è®ºï¼Œå­¦æœ¯è·¯ä¸ŠæœŸå¾…ä¸æ‚¨å‰è¡Œï¼ŒåŠ æ²¹ã€‚

<font color="red">**å‰ä¸€ç¯‡ä»ä¸ªäººè§’åº¦ä»‹ç»è‹±æ–‡è®ºæ–‡æ¨¡å‹è®¾è®¡ï¼ˆModel Designï¼‰å¦‚ä½•æ’°å†™ã€‚è¿™ç¯‡æ–‡ç« å°†ä»ä¸ªäººè§’åº¦ä»‹ç»è‹±æ–‡è®ºæ–‡å®éªŒè¯„ä¼°ï¼ˆEvaluationï¼‰éƒ¨åˆ†ï¼Œå³Experimental Evaluationæˆ–Experimental studyï¼Œä¸»è¦ä»¥å…¥ä¾µæ£€æµ‹ç³»ç»Ÿä¸ºä¾‹ï¼ˆIntrusion Detection Systemï¼‰ï¼Œè¯¦ç»†çš„å¯¹æ¯”åˆ†æä¸‹ç¯‡ä»‹ç»ã€‚ä¸€æ–¹é¢è‡ªå·±è‹±æ–‡å¤ªå·®ï¼Œåªèƒ½é€šè¿‡æœ€åœŸçš„åŠæ³•æ…¢æ…¢æå‡ï¼Œå¦ä¸€æ–¹é¢æ˜¯è‡ªå·±çš„ä¸ªäººå­¦ä¹ ç¬”è®°ï¼Œå¹¶åˆ†äº«å‡ºæ¥å¸Œæœ›å¤§å®¶æ‰¹è¯„å’ŒæŒ‡æ­£ã€‚å¸Œæœ›è¿™ç¯‡æ–‡ç« å¯¹æ‚¨æœ‰æ‰€å¸®åŠ©ï¼Œè¿™äº›å¤§ä½¬æ˜¯çœŸçš„å€¼å¾—æˆ‘ä»¬å»å­¦ä¹ ï¼ŒçŒ®ä¸Šå°å¼Ÿçš„è†ç›–~fightingï¼**</font>

#### æ–‡ç« ç›®å½•

è¿™é‡Œé€‰æ‹©çš„è®ºæ–‡å¤šæ•°ä¸ºè¿‘ä¸‰å¹´çš„CCF Aå’ŒäºŒåŒºä»¥ä¸Šä¸ºä¸»ï¼Œå°¤å…¶æ˜¯é¡¶ä¼šé¡¶åˆŠã€‚å½“ç„¶ï¼Œä½œè€…èƒ½åŠ›æœ‰é™ï¼Œåªèƒ½ç»“åˆè‡ªå·±çš„å®åŠ›å’Œå®é™…é˜…è¯»æƒ…å†µå‡ºå‘ï¼Œä¹Ÿå¸Œæœ›è‡ªå·±èƒ½ä¸æ–­è¿›æ­¥ï¼Œæ¯ä¸ªéƒ¨åˆ†éƒ½ä¼šæŒç»­è¡¥å……ã€‚å¯èƒ½äº”å¹´åå¹´åï¼Œä¹Ÿä¼šè¯¦ç»†åˆ†äº«ä¸€ç¯‡è‹±æ–‡è®ºæ–‡å¦‚ä½•æ’°å†™ï¼Œç›®å‰ä¸»è¦ä»¥å­¦ä¹ å’Œç¬”è®°ä¸ºä¸»ã€‚å¤§ä½¬è¿˜è¯·é£˜è¿‡O(âˆ©_âˆ©)O

**å‰æ–‡èµæï¼š**

---


## ä¸€.å®éªŒè¯„ä¼°å¦‚ä½•æ’°å†™

è®ºæ–‡å¦‚ä½•æ’°å†™å› äººè€Œå¼‚ï¼Œä½œè€…ä»…åˆ†äº«è‡ªå·±çš„è§‚ç‚¹ï¼Œæ¬¢è¿å¤§å®¶æå‡ºæ„è§ã€‚ç„¶è€Œï¼ŒåšæŒé˜…è¯»æ‰€ç ”ç©¶é¢†åŸŸæœ€æ–°å’Œç»å…¸è®ºæ–‡ï¼Œè¿™ä¸ªå¤§å®¶åº”è¯¥ä¼šèµæˆï¼Œå¦‚æœèƒ½åšåˆ°ç›¸å…³é¢†åŸŸæ–‡çŒ®å¦‚æ•°å®¶çï¼Œå°±ç¦»ä½ æ’°å†™ç¬¬ä¸€ç¯‡è‹±æ–‡è®ºæ–‡æ›´è¿‘ä¸€æ­¥äº†ã€‚

åœ¨å®éªŒè®¾è®¡ä¸­ï¼Œé‡ç‚¹æ˜¯å¦‚ä½•é€šè¿‡å®éªŒè¯´æœå®¡ç¨¿è€å¸ˆï¼ŒèµåŒä½ çš„åˆ›æ–°ç‚¹ï¼Œä½“ç°ä½ è®ºæ–‡çš„ä»·å€¼ã€‚å¥½çš„å›¾è¡¨èƒ½æ›´å¥½åœ°è¡¨è¾¾ä½ è®ºæ–‡çš„ideaï¼Œå› æ­¤æˆ‘ä»¬éœ€è¦å­¦ä¹ ä¼˜ç§€è®ºæ–‡ï¼Œä¸€ä¸ªæƒŠå–œçš„å®éªŒæ›´æ˜¯è®ºæ–‡æˆåŠŸçš„å…³é”®ã€‚æ³¨æ„ï¼Œå®‰å…¨è®ºæ–‡å·²ç»ä¸å†æ˜¯å¯¹æ¯”PRFçš„é˜¶æ®µäº†ï¼Œä¸€å®šè¦è®©å®éªŒæ”¯æ’‘ä½ æ•´ä¸ªè®ºæ–‡çš„æ¡†æ¶ã€‚åŒæ—¶ï¼Œå¤šè¯»å¤šå†™æ˜¯åŸºæ“ï¼Œå…±å‹‰ï¼

### 1.è®ºæ–‡æ€»ä½“æ¡†æ¶åŠå®éªŒæ’°å†™

è¯¥éƒ¨åˆ†å›é¡¾å’Œå‚è€ƒå‘¨è€å¸ˆçš„åšå£«è¯¾ç¨‹å†…å®¹ï¼Œæ„Ÿè°¢è€å¸ˆçš„åˆ†äº«ã€‚å…¸å‹çš„è®ºæ–‡æ¡†æ¶åŒ…æ‹¬ä¸¤ç§ï¼ˆThe typical â€œanatomyâ€ of a paperï¼‰ï¼Œå¦‚ä¸‹æ‰€ç¤ºï¼š

<mark>ç¬¬ä¸€ç§æ ¼å¼ï¼šç†è®ºç ”ç©¶</mark>

<mark>ç¬¬äºŒç§æ ¼å¼ï¼šç³»ç»Ÿç ”ç©¶</mark>

<mark>å®éªŒè¯„ä¼°ä»‹ç»ï¼ˆEvaluationï¼‰</mark>

---


### 2.å®éªŒè¯„ä¼°æ’°å†™

è¯¥éƒ¨åˆ†ä¸»è¦æ˜¯å­¦ä¹ æ˜“è‰è€å¸ˆä¹¦ç±ã€Šå­¦æœ¯å†™ä½œåŸæ¥æ˜¯è¿™æ ·ã€‹ï¼Œåé¢æˆ‘ä¹Ÿä¼šåˆ†äº«æˆ‘çš„æƒ³æ³•ï¼Œå…·ä½“å¦‚ä¸‹ï¼š

ç»“æœä¸æ–¹æ³•ä¸€ç§æ˜¯ç›¸å¯¹å®¹æ˜“å†™ä½œçš„éƒ¨åˆ†ï¼Œå…¶å†…å®¹å…¶å®å°±æ˜¯ä½ å¯¹æ”¶é›†æ¥çš„æ•°æ®åšäº†ä»€ä¹ˆæ ·çš„åˆ†æã€‚å¯¹äºç›¸å¯¹ç®€å•çš„ç»“æœï¼ˆ3ä¸ªåˆ†æä»¥å†…ï¼‰ï¼ŒæŒ‰éƒ¨å°±ç­åœ°å†™å°±å¥½ã€‚æœ‰ä¸“ä¸šæ–‡çŒ®çš„ç§¯ç´¯ï¼Œç›¸ä¿¡éš¾åº¦ä¸å¤§ã€‚å†™èµ·æ¥æ¯”è¾ƒå›°éš¾çš„æ˜¯å¤æ‚æ•°æ®çš„ç»“æœï¼Œæ¯”å¦‚åŒ…æ‹¬10ä¸ªåˆ†æï¼Œå›¾ç‰‡å°±æœ‰ä¸ƒå…«å¼ ã€‚è¿™æ—¶å€™å¯¹ç»“æœçš„ç»„ç»‡å°±éå¸¸é‡è¦äº†ã€‚è€å¸ˆæ¨èã€Š10æ¡ç®€å•è§„åˆ™ã€‹ä¸€æ–‡ä¸­æ¨èçš„ <mark>ç»“è®ºé©±åŠ¨ï¼ˆconclusion-drivenï¼‰</mark> æ–¹æ³•ã€‚

> 
<font color="red">**ä¸ªäººæ„Ÿè§‰ï¼š**<br/> å®éªŒéƒ¨åˆ†åŒæ ·é‡è¦ï¼Œä½†æ›´é‡è¦æ˜¯å¦‚ä½•é€šè¿‡å®éªŒç»“æœã€å¯¹æ¯”å®éªŒã€å›¾è¡¨æè¿°æ¥æ”¯æ’‘ä½ çš„åˆ›æ–°ç‚¹ï¼Œè®©å®¡ç¨¿è€å¸ˆè§‰å¾—ï¼Œå°±åº”è¯¥è¿™ä¹ˆåšï¼Œamazingçš„å·¥ä½œã€‚ä½œä¸ºåˆå­¦è€…ï¼Œæˆ‘ä»¬å¯èƒ½è¿˜ä¸èƒ½åšåˆ°éå¸¸å®Œç¾çš„å®éªŒï¼Œä½†ä¸€å®šè¦è®©æ–‡ç« çš„å®éªŒè¶³å¤Ÿè¯¦ç»†ï¼ŒåŠ›äº‰åƒè¯¥é¢†åŸŸçš„é¡¶çº§æœŸåˆŠæˆ–ä¼šè®®ä¸€æ ·ï¼Œå¹¶ä¸”èƒ½å¤Ÿå¾ˆå¥½çš„å’Œè®ºæ–‡ä¸»é¢˜ç›¸å¥‘åˆï¼Œè¿™æœ‰è¿™æœ‰ï¼Œæ–‡ç« çš„ä»·å€¼ä¹Ÿä½“ç°å‡ºæ¥äº†ã€‚</font>


**åœ¨æ•°æ®å¤„ç†çš„è¿‡ç¨‹ä¸­ï¼Œæ¢³ç†ã€æ€»ç»“è‡ªå·±çš„ä¸»è¦å‘ç°ï¼Œä»¥è¿™äº›å‘ç°ä¸ºå¤§çº²ï¼ˆå°æ ‡é¢˜ï¼‰ï¼Œæ¥ç»„ç»‡ç»“æœçš„å†™ä½œ**ï¼ˆè€Œä¸æ˜¯ä¼ ç»Ÿä¸ŠæŒ‰ç…§è‡ªå·±æ•°æ®å¤„ç†çš„é¡ºåºæ¥ç»„ç»‡ï¼‰ã€‚ä»¥ä½œè€…å‘è¡¨è®ºæ–‡ä¸ºä¾‹ï¼Œä»–ä»¬ä½¿ç”¨äº†è¿™ç§æ–¹æ³•æ¥ç»„ç»‡ç»“æœéƒ¨åˆ†ï¼Œåˆ†ä¸ºå››ä¸ªå°æ ‡é¢˜ï¼Œæ¯ä¸ªå°æ ‡é¢˜ä¸‹åˆ—å‡ºç›¸åº”çš„åˆ†æåŠç»“æœã€‚

å¦‚æœè¿˜æœ‰å…¶ä»–ç»“æœä¸èƒ½å½’å…¥ä»»ä½•ä¸€ä¸ªç»“è®ºï¼Œé‚£å°±è¯´æ˜è¿™ä¸ªç»“æœå¹¶ä¸é‡è¦ï¼Œ<mark>æ²¡æœ‰å¯¹å½¢æˆæ–‡ç« çš„ç»“è®ºåšå‡ºä»€ä¹ˆè´¡çŒ®ï¼Œè¿™æ—¶å€™æœæ–­èˆå¼ƒï¼ˆæˆ–æ”¾åˆ°è¡¥å……ææ–™ä¸­ï¼‰æ˜¯æ˜æ™ºçš„é€‰æ‹©</mark>ã€‚

å¦å¤–ï¼Œ<mark>åŒä¸€ç§ç»“æœå¯èƒ½æœ‰ä¸åŒçš„å‘ˆç°æ–¹å¼ï¼Œå¯ä»¥ä¾æ®ä½ çš„ç ”ç©¶ç›®çš„æ¥é‡‡ç”¨ä¸åŒçš„æ–¹å¼</mark>ã€‚æˆ‘åœ¨ä¿®æ”¹å­¦ç”Ÿæ–‡ç« æ—¶é‡åˆ°æ¯”è¾ƒå¤šçš„ä¸€ä¸ªé—®é¢˜æ˜¯é‡‡ç”¨å¥‡æ€ªçš„æ–¹å¼ï¼Œçªå‡ºäº†ä¸é‡è¦çš„ç»“æœã€‚ä¸¾ä¾‹ï¼š

> 
ç¤ºä¾‹å¥å­ï¼š<br/> The two groups were similar at the 2nd, 4th, and 8th trials; They differed from each other in the remaining trials. <br/><br/> è¿™å¥è¯æœ‰ä¸¤ä¸ªæ¯”è¾ƒæ˜æ˜¾çš„é—®é¢˜ï¼š(1)ç›¸ä¼¼çš„è¯•æ¬¡å¹¶ä¸æ˜¯é‡ç‚¹ï¼Œé‡ç‚¹æ˜¯å¤§éƒ¨åˆ†çš„è¯•æ¬¡æ˜¯æœ‰å·®å¼‚çš„ï¼Œä½†æ˜¯è¿™ä¸ªé‡ç‚¹æ²¡æœ‰è¢«çªå‡ºï¼Œåè€Œä»…æœ‰çš„ä¸‰ä¸ªä¸€æ ·çš„è¯•æ¬¡çªå‡ºäº†ã€‚(2)è¯­è¨€çš„æ¨¡ç³Šï¼Œdifferçš„ä½¿ç”¨æ¥æ¥çš„æ¨¡ç³Šæ€§ï¼ˆä¸çŸ¥é“æ˜¯æ›´å¥½è¿˜æ˜¯æ›´å·®ï¼‰ã€‚<br/> ä¿®æ”¹å¦‚ä¸‹ï¼š<br/> Four-year-olds outperformed 3-year-olds in most trials, except the 2nd, 4th, and 8th trials, in which they performed similarly.


<font color="red">**å¯¹äºç»“æœçš„å‘ˆç°ï¼Œä½œå›¾æ˜¯ç‰¹åˆ«é‡è¦çš„ï¼Œä¸€å¼ å¥½å›¾èƒœè¿‡åƒè¨€ä¸‡è¯­**ã€‚</font> ä½†æˆ‘ä¸æ˜¯ä½œå›¾æ–¹é¢çš„ä¸“å®¶ï¼Œå¦‚æœä½ éœ€è¦è¿™æ–¹é¢çš„æŒ‡å¯¼ï¼Œå»ºè®®ä½ é˜…è¯»ã€Š10ä¸ªç®€å•è§„åˆ™ï¼Œåˆ›é€ æ›´ä¼˜å›¾å½¢ã€‹ï¼Œæ–‡ä¸­ä¸ºæ€ä¹ˆåšå‡ºä¸€å¼ å¥½å›¾æä¾›äº†éå¸¸å…¨é¢è€Œæœ‰ç”¨çš„æŒ‡å¯¼ã€‚

---


### 3.è®¨è®ºæ’°å†™

è¯¥éƒ¨åˆ†ä¸»è¦æ˜¯å­¦ä¹ æ˜“è‰è€å¸ˆä¹¦ç±ã€Šå­¦æœ¯å†™ä½œåŸæ¥æ˜¯è¿™æ ·ã€‹ï¼Œåé¢æˆ‘ä¹Ÿä¼šåˆ†äº«æˆ‘çš„æƒ³æ³•ï¼Œå…·ä½“å¦‚ä¸‹ï¼š

è®¨è®ºæ˜¯ä¸€ä¸ªéå¸¸å¤´ç–¼çš„éƒ¨åˆ†ã€‚å…ˆæ¥è®²è®²è®¨è®ºçš„å†™æ³•ï¼Œåœ¨å‰é¢å¼ºè°ƒäº†ä»å¤§çº²å¼€å§‹å†™çš„å¥½å¤„ï¼Œä»å¤§çº²å¼€å§‹å†™æ˜¯ä¸€ç§è‡ªä¸Šè€Œä¸‹çš„å†™æ³•ï¼Œåœ¨å†™å¤§çº²çš„è¿‡ç¨‹ä¸­ç¡®å®šä¸»é¢˜å¥ï¼Œç„¶åå†ç¡®å®šå…¶ä»–å†…å®¹ã€‚è¿˜æœ‰ä¸€ç§æ–¹æ³•æ˜¯è‡ªä¸‹è€Œä¸Šåœ°å†™ï¼Œå°±æ˜¯å…ˆéšå¿ƒæ‰€ä»¥åœ°å†™ç¬¬ä¸€ç¨¿ï¼Œä»ç¬”è®°å¼€å§‹å†™ï¼Œç„¶åå¯¹è¿™äº›ç¬”è®°è¿›è¡Œæ¢³ç†å’Œå½’çº³ï¼Œæç‚¼ä¸»é¢˜å¥ã€‚<mark>è€å¸ˆé€šå¸¸æ··åˆä¸¤ç§å†™æ³•ï¼Œå…ˆä»é›¶æ˜Ÿçš„ç‚¹è¿›è¡Œå½’çº³ï¼ˆå†™å‰è¨€æ—¶å¯¹æ–‡çŒ®è§‚ç‚¹åšç¬”è®°ï¼Œå†™è®¨è®ºæ—¶å¯¹ç»“æœçš„å‘ç°åšç¬”è®°ï¼‰ï¼Œä¹‹åé€šè¿‡æ¢³ç†ï¼Œæ•´ç†å‡ºå¤§çº²ï¼Œå†ä»å¤§çº²å¼€å§‹å†™ä½œã€‚</mark>

æ¯”å¦‚æˆ‘å¯¹æŸç¯‡æ–‡ç« çš„è®¨è®ºéƒ¨åˆ†åšè¿‡ç›¸å…³ç¬”è®°ï¼Œç„¶åå¯¹è¿™äº›ç‚¹è¿›è¡Œæ¢³ç†å’Œå½’çº³ï¼Œå†ç»“åˆå‰æ²¿æå‡ºæ¥çš„ä¸‰ä¸ªç ”ç©¶é—®é¢˜å½¢æˆè®¨è®ºçš„å¤§çº²ï¼Œå¦‚ä¸‹ï¼š

åœ¨(1)åˆ°(4)æ®µçš„è®¨è®ºä¸­ï¼Œè¦å…ˆæ€»ç»“è‡ªå·±æœ€é‡è¦çš„å‘ç°ï¼Œä¸è¦å¿˜è®°å›é¡¾å‰è¨€ä¸­æå‡ºçš„å®éªŒé¢„æœŸï¼Œè¯´æ˜ç»“æœæ˜¯å¦ç¬¦åˆè‡ªå·±çš„é¢„æœŸã€‚ç„¶åå›é¡¾å‰äººç ”ç©¶ä¸è‡ªå·±çš„ç ”ç©¶å‘ç°æ˜¯å¦ä¸€è‡´ï¼Œå¦‚æœä¸ä¸€è‡´ï¼Œå°±å¯ä»¥è®¨è®ºå¯èƒ½çš„åŸå› ï¼ˆå–æ ·ã€å®éªŒæ–¹æ³•çš„ä¸åŒç­‰ï¼‰ã€‚

æ­¤å¤–è¿˜éœ€è¦æ³¨æ„ï¼Œå¾ˆå¤šå­¦ç”ŸæŠŠè®¨è®ºçš„é‡ç‚¹æ”¾åœ¨äº†ä¸å‰äººç ”ç©¶ä¸ä¸€è‡´çš„ç»“æœå’Œè‡ªå·±çš„å±€é™æ€§ä¸Šï¼Œè¿™äº›æ˜¯éœ€è¦å†™çš„ï¼Œ<font color="red">**ä½†æ˜¯æœ€é‡è¦çš„æ˜¯çªå‡ºè‡ªå·±ç ”ç©¶çš„è´¡çŒ®**</font>ã€‚

è®¨è®ºä¸­æœ€å¸¸å‡ºç°çš„é—®é¢˜å°±æ˜¯æŠŠç»“æœé‡Œçš„è¯æ¢ä¸ªè¯´æ³•å†è¯´ä¸€éã€‚å…¶å®è®¨è®ºéƒ¨åˆ†ç»™äº†æˆ‘ä»¬ä¸€ä¸ªä»æ›´é«˜å±‚é¢æ¢³ç†å’Œè§£è¯»ç ”ç©¶ç»“æœçš„æœºä¼šã€‚æ›´é‡è¦çš„æ˜¯ï¼Œéœ€è¦æ˜ç¡®æå‡ºè‡ªå·±çš„ç ”ç©¶è´¡çŒ®ï¼Œè¿›ä¸€æ­¥å¼ºè°ƒç ”ç©¶çš„é‡è¦æ€§ã€æ„ä¹‰ä»¥åŠåˆ›æ–°æ€§ã€‚å› æ­¤ï¼Œä¸è¦åœç•™åœ¨å°±äº‹è®ºäº‹çš„ç»“æœæè¿°ä¸Šã€‚<mark>è¯»è€…è¯»å®Œç»“æœåï¼Œå¾ˆå®¹æ˜“äº§ç”Ÿâ€œso whatâ€çš„é—®é¢˜â€”â€”â€œæ˜¯çš„ï¼Œä½ å‘ç°äº†è¿™äº›ï¼Œé‚£åˆæ€ä¹ˆæ ·å‘¢ï¼Ÿâ€ã€‚</mark>

è¿™æ—¶å€™ï¼Œæœ€é‡è¦çš„æ˜¯å‘Šè¯‰è¯»è€…ç ”ç©¶çš„å¯ç¤ºï¼ˆimplicationï¼‰â€”â€”ä½ çš„å‘ç°è¯´æ˜äº†ä»€ä¹ˆï¼ŒåŠ æ·±äº†å¯¹ä»€ä¹ˆé—®é¢˜çš„ç†è§£ï¼Œå¯¹æœªè§£å†³çš„é—®é¢˜æä¾›äº†ä»€ä¹ˆæ–°çš„è§£å†³æ–¹æ³•ï¼Œæ­ç¤ºäº†ä»€ä¹ˆæ–°çš„æœºåˆ¶ã€‚è¿™ä¹Ÿæ˜¯å½±å“ç¨¿ä»¶å½•ç”¨çš„æœ€é‡è¦éƒ¨åˆ†ï¼Œæ‰€ä»¥ä¸€å®šè¦èŠ±æœ€å¤šæ—¶é—´å’Œç²¾åŠ›æ¥å†™è¿™ä¸ªéƒ¨åˆ†ã€‚

ç”¨å‰æ–‡æåˆ°çš„â€œæœºå™¨äººâ€æ–‡ç« çš„ç»“è®ºä½œä¸ºä¾‹å­ï¼Œè¯´æ˜å¦‚ä½•æ€»ç»“å’Œå‡åè‡ªå·±çš„ç»“è®ºã€‚

> 
Overall, our study contributes several promising preliminary findings on the potential involvement of humanoid robots in social rules training for children with ASD. Our results also shed light for the direction of future research, which should address whether social learning from robots can be generalized to a universal case (e.g., whether distrusting/deceiving the robot contributes to an equivalent effect on distrusting/deceiving a real person); a validation test would be required in future work to test whether children with ASD who manage to distrust and deceive a robot are capable of doing the same to a real person.


---


### 4.å®éªŒè¯„ä¼°æ’°å†™ä¹‹ä¸ªäººç†è§£

é¦–å…ˆæˆ‘ä»¬è¦æ¸…æ¥šå®éªŒå†™ä½œçš„ç›®çš„ï¼Œé€šè¿‡è¯¦ç»†å‡†ç¡®çš„æ•°æ®é›†ã€ç¯å¢ƒã€å®éªŒæè¿°ï¼Œä»¿ä½›èƒ½è®©åˆ«äººæ¨¡ä»¿å‡ºæ•´ä¸ªå®éªŒçš„è¿‡ç¨‹ï¼Œæ›´è®©è¯»è€…æˆ–å®¡ç¨¿è€å¸ˆä¿¡æœç ”ç©¶æ–¹æ³•çš„ç§‘å­¦æ€§ï¼Œå¢åŠ ç»“æœæ•°æ®çš„å‡†ç¡®æ€§å’Œæœ‰æ•ˆæ€§ã€‚

å¦‚æœæˆ‘ä»¬çš„å®éªŒèƒ½å‘ç°æŸäº›æœ‰è¶£çš„ç»“è®ºä¼šéå¸¸æ£’ï¼›å¦‚æœæˆ‘ä»¬çš„è®ºæ–‡å°±æ˜¯æ–°é—®é¢˜å¹¶æœ‰å¯¹åº”çš„è§£å†³æ–¹æ³•ï¼ˆåˆ›æ–°æ€§å¼ºï¼‰ï¼Œåˆ™å®éªŒéœ€è¦æ”¯æ’‘å¯¹åº”çš„è´¡çŒ®æˆ–ç³»ç»Ÿï¼Œè¯´æœå®¡ç¨¿è€å¸ˆï¼›å¦‚æœä¸Šè¿°éƒ½ä¸èƒ½å®ç°ï¼Œæˆ‘ä»¬å°½é‡ä¿è¯å®éªŒè¯¦ç»†ï¼Œå¹¶é€šè¿‡å¯¹æ¯”å®éªŒï¼ˆbaselineå¯¹æ¯”ï¼‰æ¥å·©å›ºæˆ‘ä»¬çš„è§‚ç‚¹å’Œæ–¹æ³•ã€‚

åˆ‡å‹¿åªæ˜¯ç®€å•åœ°å¯¹å‡†ç¡®ç‡ã€å¬å›ç‡æ¯”è¾ƒï¼Œæ¯ä¸ªå®éªŒç»“æœéƒ½åº”è¯¥ç»“åˆç ”ç©¶èƒŒæ™¯å’Œè®ºæ–‡ä¸»æ—¨è¿›è¡Œè¯´æ˜ï¼Œæœ‰å¼€æºæ•°æ®é›†çš„æ›´å¥½ï¼Œæ²¡æœ‰çš„æ•°æ®é›†å»ºè®®å¼€æºï¼Œé‡è¦çš„æ˜¯è¯´æœå®¡ç¨¿è€å¸ˆè®¤å¯ä½ çš„å·¥ä½œã€‚åŒæ—¶ï¼Œå®éªŒæ­¥éª¤çš„æè¿°ä¹Ÿéå¸¸é‡è¦ï¼ŒåŒ…æ‹¬å®éªŒçš„å›¾è¡¨ã€ç ”ç©¶ç»“è®ºã€ç®€æ˜æ‰¼è¦çš„æè¿°ï¼ˆç»™å‡ºç²¾è¯»ï¼‰ç­‰ã€‚

åœ¨æ—¶æ€æ–¹é¢ï¼Œç”±äºæ˜¯æè¿°å·²ç»å‘ç”Ÿçš„å®éªŒè¿‡ç¨‹ï¼Œä¸€èˆ¬ç”¨è¿‡å»æ—¶æ€ï¼Œä¹Ÿæœ‰ç°åœ¨æ—¶ã€‚å¤§éƒ¨åˆ†æœŸåˆŠå»ºè®®ç”¨è¢«åŠ¨å¥æè¿°å®éªŒè¿‡ç¨‹ï¼Œä½†æ˜¯ä¹Ÿæœ‰ä¸€äº›æœŸåˆŠé¼“åŠ±ç”¨ä¸»åŠ¨å¥ï¼Œå› æ­¤ï¼Œåœ¨æŠ•ç¨¿å‰ï¼Œå¯ä»¥åœ¨æœŸåˆŠä¸»é¡µä¸ŠæŸ¥çœ‹â€œInstructions to Authorsâ€ç­‰æŠ•ç¨¿æŒ‡å¯¼æ€§æ–‡æ¡£æ¥æ˜ç¡®è¦æ±‚ã€‚ä¸€èµ·åŠ æ²¹å–”~

ä¸‹é¢ç»“åˆå‘¨è€å¸ˆçš„åšå£«è‹±è¯­è¯¾ç¨‹ï¼Œæ€»ç»“å®éªŒéƒ¨åˆ†æˆ‘ä»¬åº”è¯¥æ€ä¹ˆè¡¨è¾¾ã€‚

<font color="red">**å›¾/è¡¨çš„åä¸ªå…³é”®ç‚¹(10 key points)**</font>

è¯´æ˜éƒ¨åˆ†è¦å°½é‡æŠŠç›¸åº”å›¾è¡¨çš„å†…å®¹è¡¨è¾¾æ¸…æ¥š

å›¾çš„è¯´æ˜ä¸€èˆ¬åœ¨å›¾çš„ä¸‹è¾¹ï¼›è¡¨çš„è¯´æ˜ä¸€èˆ¬åœ¨è¡¨çš„ä¸Šè¾¹ï¼›è¡¨ç¤ºæ•´ä½“æ•°æ®çš„åˆ†å¸ƒè¶‹åŠ¿çš„å›¾ä¸éœ€å¤ªå¤§ï¼›è¡¨ç¤ºä¸åŒæ–¹æ³•é—´ç»†å¾®å·®åˆ«çš„å›¾ä¸èƒ½å¤ªå°ã€‚

å‡ ä¸ªå›¾å¹¶æ’æ”¾åœ¨ä¸€èµ·ï¼Œå¦‚æœæœ‰å¯æ¯”æ€§ï¼Œå¹¶æ’å›¾çš„x/yè½´çš„å–å€¼èŒƒå›´æœ€å¥½ä¸€è‡´ï¼Œåˆ©äºæ¯”<br/> è¾ƒã€‚

å®éªŒç»“æœè·Ÿbaselineåœ¨ç»å¯¹æ•°å€¼ä¸Šå·®åˆ«ä¸å¤§ï¼Œç”¨åˆ—è¡¨åŠ é»‘ä½“å­—ï¼›å®éªŒç»“æœè·Ÿbaselineåœ¨ç»å¯¹æ•°å€¼ä¸Šå·®åˆ«è¾ƒå¤§ï¼Œç”¨æŸ±çŠ¶å›¾/æŠ˜çº¿å›¾è§†è§‰è¡¨ç°åŠ›æ›´å¥½ã€‚

æŠ˜çº¿å›¾è¦é€‰æ‹©é€‚å½“çš„é¢œè‰²å’Œå›¾æ ‡ï¼Œé¢œè‰²é€‰æ‹©è¦è€ƒè™‘é»‘ç™½æ‰“å°çš„æ•ˆæœï¼›æŠ˜çº¿å›¾çš„å›¾æ ‡é€‰æ‹©è¦æœ‰é’ˆå¯¹æ€§ï¼Œæ¯”å¦‚å¯¹æ¯”A, A+ï¼ŒB, B+å››ç§æ–¹æ³•ã€‚

---


### 5.æ•´ä½“ç»“æ„æ’°å†™è¡¥å……

åŒæ—¶ï¼Œæ¨¡å‹è®¾è®¡æ•´ä½“ç»“æ„å’Œå†™ä½œç»†èŠ‚è¡¥å……å‡ ç‚¹ï¼šï¼ˆå¼•ç”¨å‘¨è€å¸ˆåšå£«è¯¾ç¨‹ï¼Œå—ç›ŠåŒªæµ…ï¼‰

---


## äºŒ.å…¥ä¾µæ£€æµ‹ç³»ç»Ÿè®ºæ–‡å®éªŒè¯„ä¼°å¥å­

### ç¬¬1éƒ¨åˆ†ï¼šå¼•å…¥

**è¯¥éƒ¨åˆ†åœ¨å®éªŒè¯„ä¼°ç¯èŠ‚ä¸»è¦ä½œä¸ºå¼•å…¥ï¼Œé€šå¸¸æ˜¯ä»‹ç»å®éªŒæ¨¡å—ç”±å“ªå‡ éƒ¨åˆ†ç»„æˆã€‚åŒæ—¶ï¼Œæœ‰äº›è®ºæ–‡ä¼šç›´æ¥ç»™å‡ºå®éªŒçš„å„ä¸ªå°æ ‡é¢˜ï¼Œè¿™æ—¶ä¼šçœç•¥è¯¥éƒ¨åˆ†ã€‚**

<mark>In this section, we employ four datasets and experimentally evaluate four aspects of WATSON: 1) the explicability of inferred event semantics; 2) the accuracy of behavior abstraction; 3) the overall experience and manual workload reduction in attack investigation; and 4) the performance overhead.</mark>

<mark>In this section, we prototype Whisper and evaluate its performance by using 42 real-world attacks. In particular, the experiments will answer the three questions:</mark>

<mark>We first describe the testbed and data sets we use in the experiment. Then we evaluate the system by comparing it with other classical intrusion detection systems on a series of critical axes such as detection rate, false alarm rate, detection time, query time and storage overhead.</mark>

<mark>In this section, we evaluate our approach with the following major goals:</mark>

<mark>In this section, we start analyzing the MUD profile of real consumer IoT devices that we have generated, and highlight attack types that can be prevented. Then, we will use traces collected in our lab, when we launched a number of volumetric attacks to four of IoT devices, to show how our system can detect these attacks using off-the-shelf IDS in an operational environment.</mark>

<mark>In this section, we present the implementation of BiDLSTM and discuss the experimental findings. We compare the modelâ€™s performance with state-of-the-art methods trained and tested on the same dataset (i.e., the NSL-KDD dataset). Also, we present a comparison of results with some recently published methods on the NSL-KDD dataset.</mark>

<mark>In this section, we performed two major experiments (named Experiment1 and Experiment2) to explore the performance of disagreement-based semi-supervised learning and our DAS-CIDS in the aspects of detection performance and alarm filtration. In this work, we use the WEKA platform (WEKA) to help extract various classifiers like J48 and Random Forest to avoid implementation variations, which is an open-source software providing a set of machine learning algorithms.</mark>

<mark>In this experimental study, we exhibit the impact of the proposed methodology and select the informative features subset from the given intrusion dataset, that can classify the network traffics into normal or attacks for the intrusion detection. Two diagnostic studies were conducted to verify the impact of the proposed method, such as precision-recall analysis and ROC-AUC analysis, which is helpful in the analysis of probabilistic prediction for binary and multi-class classification problems. The main objectives of these experiments are summarized below,</mark>

---


### ç¬¬2éƒ¨åˆ†ï¼šæ•°æ®é›†ä»‹ç»

**è¯¥éƒ¨åˆ†ä¸»è¦ä»‹ç»å®éªŒæ•°æ®é›†ï¼Œé€šå¸¸åŒ…æ‹¬æ•°æ®é›†çš„ç»„æˆåŠç‰¹å¾åˆ†å¸ƒæƒ…å†µï¼Œç»“åˆè¡¨æ ¼æè¿°æ•ˆæœæ›´å¥½ã€‚åŒæ—¶ï¼Œå¦‚æœæœ‰å…¬ç”¨æ•°æ®é›†ï¼ˆAIç±»è¾ƒå¤šï¼‰ï¼Œå»ºè®®å¤šä¸ªæ•°æ®é›†å¯¹æ¯”ï¼Œå¹¶ä¸”ä¸ç»å…¸çš„è®ºæ–‡æ–¹æ³•æˆ–baselinesæ¯”è¾ƒï¼›å¦‚æœæ˜¯è‡ªèº«æ•°æ®é›†ï¼Œå»ºè®®å¼€æºï¼Œä½†å…¶å¯¹æ¯”å®éªŒè¾ƒéš¾ï¼Œæ€ä¹ˆè¯´æœå®¡ç¨¿äººç›¸ä¿¡ä½ çš„æ•°æ®é›†æ˜¯å…³é”®ã€‚**

> 
(1) Chuanpu Fu, et al. Realtime Robust Malicious Traffic Detection via Frequency Domain Analysis. CCS.


<mark>Datasets. The datasets used in our experiments are shown in Table 4. We use three recent datasets from the WIDE MAWI Gigabit backbone network [69]. In the training phase, we use 20% benign traffic to train the machine learning algorithms. We use the first 20% packets in MAWI 2020.06.10 dataset to calculate the encoding vector via solving the SMT problem (see Section 4.2). Meanwhile, we replay four groups of malicious traffic combined with the benign traffic on the testbed:</mark>

> 
(2) Ning Wang, et al. MANDA: On Adversarial Example Detection for Network Intrusion Detection System. INFOCOM.


<mark>NSL-KDD: We use the internet traffic dataset, NSL-KDD [45] (also used in AE attacks in IDS [9], but [9] dose not consider problem-space validity), for our evaluation. In NSL-KDD, each sample contains four groups of entries including Intrinsic Characteristics, Content Characteristics, Time-based Characteristics, and Host-based Characteristics. There are four categories of intrusion: DoS, Probing, Remote-to-Local (R2L), and User-to-Root (U2R) of which each contains more attack sub-categories. There are 24 sub-categories of attacks in the training set and 38 sub-categories of attacks are in test set (i.e., 14 sub-categories of attacks are unseen in the training set). There are 125,973 training records and 22,544 testing records. In our experiments, we only show the evaluations on an IDS model for discriminating DoS attacks from normal traffic since the results for the other three attacks are similar. The total number of entries for each record is 41 (in problem-space) which are further processed into 121 numerical features as an input-space (feature-space) vector.</mark>

<mark>MNIST: We also evaluate our approach on an image dataset, MNIST [46], to demonstrate its applicability. The images in MNIST are handwritten digits from 0 to 9. The corresponding digit of an image is used as its label. Each class has 6,000 training samples and 1,000 test samples. Therefore, the whole MNIST dataset has 60,000 training samples and 10,000 test samples. All the images have the same size of 28 Ã— 28 and are in grey-level.</mark>

> 
(3) Mohammed A. Ambusaidi, et al. Building an Intrusion Detection System Using a Filter-Based Feature Selection Algorithm. IEEE TRANSACTIONS ON COMPUTERS.


<mark>Currently, there are only a few public datasets available for intrusion detection evaluation. Among these datasets, the KDD Cup 99 dataset, NSL-KDD dataset and Kyoto 2006+ dataset have been commonly used in the literature to assess the performance of IDSes. According to the review by Tsai et al. [43], the majority of the IDS experiments were performed on the KDD Cup 99 datasets. In addition, these datasets have different data sizes and various numbers of features which provide comprehensive tests in validating feature selection methods. Therefore, in order to facilitate a fair and rational comparison with other state-of-the-art detection approaches, we have selected these three datasets to evaluate the performance of our detection system.</mark>

<mark>The KDD Cup 99 dataset is one of the most popular and comprehensive intrusion detection datasets and is widely applied to evaluate the performance of intrusion detection systems [43]. It consists of five different classes, which are normal and four types of attack (i.e., DoS, Probe, U2R and R2L). It contains training data with approximately five million connection records and test data with about two million connection records. Each record in these datasets is labeled as either normal or an attack, and it has 41 different quantitative and qualitative features.</mark>

<mark>The NSL-KDD is a new revised version of the KDD Cup 99 that has been proposed by Tavallaee et al. in [24]. This dataset addresses some problems included in the KDD Cup 99 dataset such as a huge number of redundant records in KDD Cup 99 data. As in the case of the KDD Cup 99 dataset, each record in the NSL-KDD dataset is composed of 41 different quantitative and qualitative features.</mark>

> 
(4) Jun Zeng, et al. WATSON: Abstracting Behaviors from Audit Logs via Aggregation of Contextual Semantics. NDSS.


<mark>We evaluate WATSON on four datasets: a benign dataset, a malicious dataset, a background dataset, and the DARPA TRACE dataset. The first three datasets are collected from ssh sessions on five enterprise servers running Ubuntu 16.04 (64-bit). The last dataset is collected on a network of hosts running Ubuntu 14.04 (64-bit). The audit log source is Linux Audit [9].</mark>

<mark>In the benign dataset, four users independently complete seven daily tasks, as described in Table I. Each user performs a task 150 times in 150 sessions. In total, we collect 17 (expected to be 4Ã—7 = 28) classes of benign behaviors because different users may conduct the same operations to accomplish tasks. Note that there are user-specific artifacts, like launched commands, between each time the task is performed. For our benign dataset, there are 55,296,982 audit events, which make up 4,200 benign sessions.</mark>

<mark>In the malicious dataset, following the procedure found in previous works [2], [10], [30], [53], [57], [82], we simulate3 eight attacks from real-world scenarios as shown in Table II. Each attack is carefully performed ten times by two security engineers on the enterprise servers. In order to incorporate the impact of typical noisy enterprise environments [53], [57], we continuously execute extensive ordinary user behaviors and underlying system activities in parallel to the attacks. For our malicious dataset, there are 37,229,686 audit events, which make up 80 malicious sessions.</mark>

<mark>In the background dataset, we record behaviors of developers and administrators on the servers for two weeks. To ensure the correctness of evaluation, we manually analyze these sessions and only incorporate sessions without behaviors in Table I and Table II into the dataset. For our background dataset, there are 183,336,624 audit events, which make up 1,000 background sessions.</mark>

â€¦

<mark>In general, our experimental behaviors for abstraction are comprehensive as compared to behaviors in real-world systems. Particularly, the benign behaviors are designed based upon basic system activities [84] claimed to have drawn attention in cybersecurity study; the malicious behaviors are either selected from typical attack scenarios in previous work or generated by a red team with expertise in instrumenting and collecting data for attack investigation.</mark>

> 
(5) S. Krishnaveni, et al. Efficient feature selection and classification through ensemble method for network intrusion detection on cloud computing. Cluster Computing.


<mark>The datasets applied in this proposed work are the following: (1) Real-time Honeypot Dataset (2) Kyoto 2006+ Dataset and (3) NSL-KDD.</mark>

> 
(6) Neha Gupta, et al. LIO-IDS: Handling class imbalance using LSTM and improved one-vs-one technique in intrusion detection system. Computer Networks.


<mark>This section discusses the three intrusion detection datasets that have been used in this paper for experimentation purposes. This includes NSL-KDD, CIDDS-001, and CICIDS2017 datasets.</mark>

<mark>The NSL-KDD (Network Socket Layer â€“ Knowledge Discovery in Databases) dataset was developed in 2009 as the successor of the KDD 1999 dataset [46]. The NSL-KDD dataset overcame the drawbacks of the KDD dataset by removing several redundant and duplicate samples in training and testing datasets. It was created to maximize prediction difficulty, and this characteristic makes it a preferred choice by researchers even today [47]. NSL-KDD consists of separate training and testing datasets containing network traffic samples represented by 41 attributes. Each instance has a label corresponding to the normal class or one of the 22 attack types. These attack types are grouped into four major attack classes, namely Denial of Service (DoS), Probe, Remote to Local (R2L), and User to Root (U2R). Table 3 shows the number of samples present in various classes of the NSL-KDD dataset. The uneven distribution of samples in different classes of this dataset makes it an appropriate choice for testing the proposed LIO-IDS.</mark>

<mark>The CICIDS2017 dataset was developed by Sharafaldin et al. [49] by generating and capturing network traffic for a duration of five days. The dataset consists of normal traffic samples and traffic samples generated from fourteen different types of attacks. The authors utilized the B-profile system to imitate benign human activities on the web and generate normal traffic from HTTP, HTTPS, FTP, and SSH protocols. Different categories of attacks were generated using various tools available on the Internet. The original CICIDS2017 dataset consists of eight CSV files containing 22,73,097 normal samples and 5,57,646 attack samples. Each traffic sample consists of 80 features that were captured using the CICFlowMeter tool. Due to the huge size of the original dataset, a subset of the CICIDS2017 dataset was selected for experimentation in this paper. The details of the selected subsets have been shown in Table 5.</mark>

<mark>The intrusion detection datasets selected in this paper consist of categorical as well as numerical attribute values. To bring these values in a uniform format, dataset pre-processing was performed on both of them. This process has been explained in the following sub-section.</mark>

> 
(7) Yakubu Imrana, et al. A bidirectional LSTM deep learning approach for intrusion detection. Expert Systems With Applications.


<mark>The NSL-KDD dataset (Tavallaee et al., 2009; UNB, 2009) is one of the bench-marked datasets for evaluating Intrusion Detection Systems (IDS). It is an enhanced form of the KDDCup â€™99 dataset (Dua &amp; Graff, 2017). The dataset comprises a training set (KDDTrain+) with 125,973 traffic samples and two separate test sets (i.e., KDDTest+ and KDDTestâˆ’21). The KDDTest+ has 22,544 traffic samples, and the KDDTestâˆ’21 has 11,850 samples. Additionally, to make the intrusion detection more realistic, the test datasets include many attacks that do not appear in the training set (see Table 2). Thus, adding to the 22 types of attacks in the training set, 17 more different attack types exist in the test set.</mark>

<mark>The NSL-KDD dataset contains 41 features, including 3 non-numeric (i.e., ğ‘ğ‘Ÿğ‘œğ‘¡ğ‘œğ‘ğ‘œğ‘™_ğ‘¡ğ‘¦ğ‘ğ‘’, ğ‘ ğ‘’ğ‘Ÿğ‘£ğ‘–ğ‘ğ‘’ and ğ‘“ ğ‘™ğ‘ğ‘”) and 38 numeric features, as shown in Table 1. It has a class label grouped into two categories (anomaly and normal) for binary classification. For multi-class classification, we group the label into five categories (i.e., Normal, Denial of Service (DoS), User-to-Root (U2R), Remote-to-Local (R2L), and Probe). Table 3 gives a summary of the number of traffic records in the NSL-KDD dataset.</mark>

---


### ç¬¬3éƒ¨åˆ†ï¼šè¯„ä¼°æŒ‡æ ‡

**è¯¥éƒ¨åˆ†ä»‹ç»æ¨¡å‹çš„è¯„ä¼°æŒ‡æ ‡ï¼Œå¸¸è§çš„åŒ…æ‹¬å‡†ç¡®ç‡ã€å¬å›ç‡ã€ç²¾ç¡®ç‡ã€Få€¼ã€è¯¯æŠ¥ç‡ç­‰ã€‚**

Chuanpu Fu, et al. Realtime Robust Malicious Traffic Detection via Frequency Domain Analysis. CCS.

Yakubu Imrana, et al. A bidirectional LSTM deep learning approach for intrusion detection. Expert Systems With Applications.

Neha Gupta, et al. LIO-IDS: Handling class imbalance using LSTM and improved one-vs-one technique in intrusion detection system. Computer Networks.

S. Krishnaveni, et al. Efficient feature selection and classification through ensemble method for network intrusion detection on cloud computing. Cluster Computing.

Mohammed A. Ambusaidi, et al. Building an Intrusion Detection System Using a Filter-Based Feature Selection Algorithm. IEEE TRANSACTIONS ON COMPUTERS.

Congyuan Xu, et al. A Method of Few-Shot Network Intrusion Detection Based on Meta-Learning Framework. IEEE TIFS.

Ning Wang, et al. MANDA: On Adversarial Example Detection for Network Intrusion Detection System. IEEE INFOCOM.

Vipin Kumar Kukkala, INDRA: Intrusion Detection Using Recurrent Autoencoders in Automotive Embedded Systems. IEEE TRANSACTIONS ON COMPUTER-AIDED DESIGN OF INTEGRATED CIRCUITS AND SYSTEMS.

**è¯„ä¼°ç®—æ³•çš„æ··æ·†çŸ©é˜µå¦‚ä¸‹ï¼š**

---


### ç¬¬4éƒ¨åˆ†ï¼šå®éªŒç¯å¢ƒ

**è¯¥éƒ¨åˆ†ä½œè€…åŒ…å«äº†Experiment Setupæˆ–Implementationç›¸å…³å†…å®¹ï¼Œä¸»è¦ä»‹ç»baselinesæˆ–å®éªŒç¯å¢ƒå†…å®¹ï¼Œä»¥åŠæ¨¡å‹çš„è¶…å‚æ•°ã€æ•°æ®é‡‡é›†æ–¹æ³•ç­‰ã€‚éƒ¨åˆ†è®ºæ–‡ä¼šä»‹ç»å®éªŒä¸­çš„ç›¸å…³å‡è®¾ã€‚**

> 
(1) Chuanpu Fu, et al. Realtime Robust Malicious Traffic Detection via Frequency Domain Analysis. CCS. ï¼ˆImplementationéƒ¨åˆ†ï¼‰


<mark>We prototype Whisper using C/C++ (GCC version 5.4.0) and Python (version 3.8.0) with more than 3,500 lines of code (LOC). The source code of Whisper can be found in [21].</mark>

<mark>Moreover, we implement a traffic generating tool using Intel DPDK to replay malicious traffic and benign traffic simultaneously. The hyper-parameters used in Whisper are shown in Table 3.</mark>

> 
(2) Chuanpu Fu, et al. Realtime Robust Malicious Traffic Detection via Frequency Domain Analysis. CCS. ï¼ˆExperiment Setupéƒ¨åˆ†ï¼‰


<mark>**Baselines.** To measure the improvements achieved by Whisper, we establish three baselines:</mark>

<mark>**Testbed**. We conduct the Whisper, FSC, and FAE experiments on a testbed built on a DELL server with two Intel Xeon E5645 CPUs (2 Ã— 12 cores), Ubuntu 16.04 (Linux 4.15.0 LTS), 24GB memory, one Intel 10 Gbps NIC with two ports that supports DPDK, and Intel 850nm SFP+ laser ports for optical fiber connections. We configure 8GB huge page memory for DPDK (4GB/NUMA Node). We bind 8 physical cores for 8 NIC RX queues to extract per-packet features and the other 8 cores for Whisper analysis threads, which extract the frequency domain features of traffic and perform statistical clustering. In summary, we use 17 of 24 cores to enable Whisper.</mark>

<mark>Note that, since Kitsune cannot handle high-rate traffic, we evaluate it with offline experiments on the same testbed. We deploy DPDK traffic generators on the other two servers with similar configurations. The reason why we use two traffic generators is that the throughput of Whisper exceeds the physical limit of 10 Gbps NIC, i.e., 13.22 Gbps. We connect two flow generators with optical fibers to generate high speed traffic.</mark>

> 
(3) Sunwoo Ahn, et al. Hawkware: Network Intrusion Detection based on Behavior Analysis with ANNs on an IoT Device. IEEE DAC.


<mark>We have implemented a prototype of Hawkware on a Raspberry Pi 3 Model B+ board which has a 1.4 GHz quad-core ARM Cortex-A53 processor with 1 GB RAM as it resembles many ARM-based IoT devices. We bound Hawkware to a single core for its computation with a 32 bit Linux OS.</mark>

<mark>We incorporated Tshark, a network packet capturing and analyzing tool, in implementing PA and used ftrace, an event tracing framework available in Linux kernels, in SCL. FP and HC are implemented in Python. Hawknet is trained offline on a separate server and then deployed on devices to perform detection. Hawknet and its training code are implemented with Tensorflow, which is one of the most popular frameworks for machine learning.</mark>

<mark>However, directly deploying this model strains IoT devices. In order to mitigate this issue, we first leveraged ARMâ€™s NEON SIMD instructions to accommodate the high degree of parallelism inherent in Hawknet. Unfortunately, due to the high memory pressure in ANN computation for loading its weight values, utilizing NEON alone still falls short of making Hawknet efficient enough for IoT devices. Therefore, in addition, we capitalized on ANN weight quantization [15], compressing the vector values of Hawknet from 32-bit floating point numbers to 8-bit fixed point numbers. The compressed model of Hawknet, generated by employing the Tensorflowlite, only occupies 60KB. The learning rate was set to 0.001, which is a standard starting point for typical deep learning. The number of parameters in each layer of Hawknet is set as following: NBAâ€™s embedding layer, encoding layer, decoding layer and reconstruction layer each respectively have 297, 3840, 567 and 297 parameters, DBAâ€™s embedding layer, LSTM layer and softmax layer each have 3160, 840 and 3476 parameters and there are 210 parameters for CC.</mark>

> 
(4) Ning Wang, et al. MANDA: On Adversarial Example Detection for Network Intrusion Detection System. IEEE INFOCOM.


<mark>We implemented the problem-space attacks and MANDA in TensorFlow. We ran all the experiments on a server equipped with an Intel Core i7-8700K CPU 3.70GHzÃ—12, a GeForce RTX 2080 Ti GPU, and Ubuntu 18.04.3 LTS. The IDS model is a muti-layer perceptron (MLP) composed of one input layer, one hidden layer with 50 neurons and one output layer. For completeness, we also implemented other models for IDS including Logistic Regression (LGR), K-Nearest Neighbors (KNN), Naive Bayes classifier for multivariate Bernoulli (BNB), Decision Tree Classifier (DTC) and Support Vector Machine (SVM) from scikit-learn library [47]. We implement four AE attacks including FGSM, BIM, CW (the L2-norm version) and JSMA (cf. Section III-C) and adapt the first three to problem-space of IDS. In each experiment, we generate AEs on the test samples that are correctly classified by the IDS model. Note here that we do not generate AEs for misclassified test samples. Next, we combine the successful AEs and the same number of clean data points (randomly selected) together as a mixed dataset, on which we run all detection algorithms. The benchmark for comparison is Artifact [17], the same as in [14], [44]. Artifact is proposed by Feinman et al. in [17] and becomes one of the state-of-the-art AE detection scheme. Different from MANDA, Artifact uses kernel density estimation (KDE) and Bayesian neural network uncertainty as two criteria to detect AEs.</mark>

<mark>On MNIST dataset, we use a convolutional neural network (CNN) rather than the above MLP as the target model for AE attacks. The CNN model comprises 4 convolutional layers with ReLU activation, followed by 2 fully-connected layers.</mark>

> 
(5) Yakubu Imrana, et al. A bidirectional LSTM deep learning approach for intrusion detection. Expert Systems With Applications.


<mark>In this section, we present the implementation of BiDLSTM and discuss the experimental findings. We compare the modelâ€™s performance with state-of-the-art methods trained and tested on the same dataset (i.e., the NSL-KDD dataset). Also, we present a comparison of results with some recently published methods on the NSL-KDD dataset.</mark>

<mark>The proposed model is a bidirectional LSTM implemented in python programming language using TensorFlow and Keras. The Adaptive Moment Estimation (Adam) algorithm is the optimizer used to update the modelâ€™s weights with a learning rate of 0.001. The loss functions used are the binary cross-entropy for binary classification and the categorical cross-entropy for multi-class classification. As shown in Fig. 3, the model starts by mapping inputs to their representations using an embedding layer. It then feeds the embeddings to the LSTM layers with two processing directions. The first in the forward direction and the other in the reversed direction. The LSTM outputs are then fed to fully connected layers with the rectified linear unit (ReLU) as an activation function. Ideally, the fully connected layers learn and compile the extracted data by the LSTM layers to form a final output that passes through an output layer for classification. Finally, we apply a dropout probability of 0.2 to the layers to ensure that our model does not over-fit the data. Table 4 displays a summary of the proposed model architecture.</mark>

<mark>The modelâ€™s performance is validated using a stratified K-fold cross-validation method with K set to 10. The stratified K-fold ensures that the sample percentage for each of the classes is equal in every fold. The process first shuffles the dataset and then splits it into K groups. Then fit the model with K-1 (10â€“1) folds and validated with the Kth folds remaining (9 folds). This process repeats until the last K-fold. Thus, it repeats until every K-fold serves as the test set. We record each foldâ€™s scores as depicted in Fig. 4 and then take the mean of these scores as the modelâ€™s performance.</mark>

> 
(6) Vipin Kumar Kukkala, et al. INDRA: Intrusion Detection Using Recurrent Autoencoders in Automotive Embedded Systems. IEEE TRANSACTIONS ON COMPUTER-AIDED DESIGN OF INTEGRATED CIRCUITS AND SYSTEMS.


<mark>To evaluate the performance of the INDRA framework, we first present an analysis for the selection of IT. Using the derived IT, we contrast it against the two variants of the same framework: 1) INDRA-LED and 2) INDRA-LD. The former removes the linear layer before the output and essentially leaving the GRU to decode the context vector. The term LED implies (L) linear layer, (E) encoder GRU and (D) decoder GRU. The second variation replaces the GRU and the linear layer at the decoder with a series of linear layers (LD implies linear decoder). These experiments were conducted to test the importance of different layers in the network. However, the encoder end of the network is not changed because we require a sequence model to generate an encoding of the timeseries data. We explored other variants as well, but they are not included in the discussion as their performance was poor compared to the LED and LD variants.</mark>

<mark>Subsequently, we compare the best variant of our framework with three prior works: 1) predictor LSTM (PLSTM [25]); 2) replicator neural network (RepNet [26]); and 3) CANet [23]. The first comparison work (PLSTM) uses an LSTM-based network that is trained to predict the signal values in the next message transmission. PLSTM achieves this by taking the 64-b CAN message payload as the input, and learns to predict the signal at a bit-level granularity by minimizing the prediction loss. A log loss or binary cross-entropy loss function is used to monitor the bit level deviations between the real next signal values and the predicted next signal values, and the gradient of this loss function is computed using backpropagation to update the weights in the network.</mark>

> 
(7) Ryan Heartfield, et al. Self-Configurable Cyber-Physical Intrusion Detection for Smart Homes Using Reinforcement Learning. IEEE TIFS.


<mark>Our experimental process consisted of three phases. Phase 1 was related to (i) live sample data collection of smart home behaviour (in terms of the data sources monitored) when not under attack and (ii) execution of each attack vector. This phase comprised two different types of experiments: one where users were present during data collection and another where no users were present in the household. Phase 2 was related to the adaptation of the offline reinforcement learning anomaly detection. Phase 3 was related to live monitoring of attack detection using the RL-optimised MAGPIE configuration.</mark>

<mark>Table III provides statistics about the live capture sample dataset for normal and attack execution experiments. Some attack vectors (WiFi de-authentication and ZigBee jamming) were observed to have a persistent effect on specific device behaviour, such as total connectivity loss to the WiFi network or disconnection of ZigBee nodes from the PAN, even after the attack had stopped. To ensure that persistent symptoms of one experiment did not interfere with another, after each attack execution, we reconnected affected devices and nodes to their respective networks and tested the automation rules to ensure that the smart home had returned to a known good state. For phase 1, each attack vector was executed independently so that normal and attack data samples were equally distributed with respect to the amount of time the smart home was monitored by MAGPIE under normal conditions and during attack execution. This process ensured that the captured dataset had a balanced set of normal and attack samples for testing. All live sample collection experiments were conducted on the training data for phase 2 reinforcement learning adaptation of the MAPGIEâ€™s anomaly models, whereas phase 3 consisted of executing live attack vectors against the MAGPIE prototype in a real-time monitoring state with the optimised anomaly model configuration. During the experiment, the users interacted with the smart home according to their normal routine. This activity generated a dataset that represented natural smart home user behaviour. Table X shows the different types of interactions performed by the users.</mark>

> 
(8) Mohammed A. Ambusaidi, et al. Building an Intrusion Detection System Using a Filter-Based Feature Selection Algorithm. IEEE TRANSACTIONS ON COMPUTERS.


<mark>In all experiments, the value of MI is estimated using the estimator proposed by Kraskov et al. [33] (discussed in Section 3.1). To select the best value of k used in the estimator for the approach of k-nearest neighbour, several experiments with different values for k are conducted. Through the experiments, we have found that the best estimated value of MI was achieved when k = 6, which is the same as the value suggested in [33]. In addition, the control parameter b for MIFS algorithm is varied in the range of [0,1], which is the range suggested in [11] and [34], with a step size of 0.1. The optimal value of b that gives the best accuracy rate is selected for a comparison with the proposed approach.</mark>

<mark>Empirical evidence shows that 0.3 is the best value for b in the three datasets, so we included the results with this optimal b value for comparison. We have also included the results with the value of b equal to 1, which is the same as the value applied in [34]. The reason of choosing different values of b is to test all possibilities of the feature rankings since the best value is undefined for the given problem. The experimental results of different values of b indicate that when the value is closer to 1 the MIFS algorithm assigns larger weights to the redundant features. In other words, the algorithm places more emphasis on the relation between input features rather than between input features and the class and vice versa.</mark>

<mark>Based on the above findings, to demonstrate the superiority of the proposed feature selection algorithm, five LSSVM-IDSs are built based on all features and the features that are chosen using four different feature selection algorithms (i.e., the proposed FMIFS, MIFS (b = 0.3), MIFS (b = 1), FLCFS), respectively, with k Â¼ 6. Three different datasets, namely KDD Cup 99 [41], NSL-KDD [24] and Kyoto 2006+ dataset [25], are used to evaluate the performance of these IDSs. The experimental results of the LSSVM-IDS based on FMIFS are compared with the results using the other four LSSVM-IDSs and several other state-of-the-art IDSs.</mark>

<mark>For the experiments on Kyoto 2006+ dataset, the data of 27, 28, 29, 30 and 31 August 2009 are selected, which contain the latest updated data. For the experimental aims on each dataset, 152,460 samples are randomly selected. A 10-fold cross-validation is used to evaluate the detection performance of the proposed LSSVM-IDS. In addition, in order to make a comparison with the detection system proposed in [20], the same sets of data captured from 1st to 3rd November 2007 are chosen for evaluation too. The comparison results are shown in Table 6.</mark>

> 
(9) Xinghua Li, et al. Sustainable Ensemble Learning Driving Intrusion Detection Model. IEEE TDSC.


<mark>This experiment uses the benchmark dataset NSL-KDD and 2014 standard dataset disclosed in the field of intrusion detection to evaluate the performance of our model. These public datasets have been pre-processed by common means and have become the organized data. Employing public datasets, on the one hand, can effectively reduce the impact of different datasets on the experimental results, on the other hand, it can enhance the experimentâ€™s reproducibility. The NSL-KDD dataset is collected in the US Air Force network environment, including various user types and network traffic. The original file contains more than 5 million records, including four significant traffics (i.e., DoS, Probe, U2L, and R2L) of attack and normal types. Our experiments use 10 percent of the sample data as the main experimental data. In order to further show the performance of our model in different network environments, we also use the standard dataset released by the Critical Infrastructure Protection Center of Mississippi State University in 2014 to evaluate our model. The dataset contains data on the network attack of two control systems: Gas and Water. The experimental environment is PC, Windows7 64-bit system, i7-6700 3.4 GHz CPU, 8 G RAM, Python language and scikit-learn machine learning library as programming languages and tools.</mark>

<font color="red">**æ³¨æ„ï¼šä¸‹ä¸€ç¯‡å°†ä»‹ç»å®éªŒåˆ†æã€å®éªŒå¯¹æ¯”å’Œè®¨è®ºã€‚**</font>

---


## ä¸‰.å®éªŒå›¾è¡¨

(1) Ryan Heartfield, et al. Self-Configurable Cyber-Physical Intrusion Detection for Smart Homes Using Reinforcement Learning. TIFS.

(2) Congyuan Xu, et al. A Method of Few-Shot Network Intrusion Detection Based on Meta-Learning Framework. TIFS.

(4) Zhenlong Xiao, et al. Anomalous IoT Sensor Data Detection: An Efficient Approach Enabled by Nonlinear Frequency-Domain Graph Analysis. IOTJ.

(5) Hongda Li, et al. vNIDS: Towards Elastic Security with Safe and Efficient Virtualization of Network Intrusion Detection Systems. CCS.

(6) Ron Bitton, et al. A Machine Learning-Based Intrusion Detection System for Securing Remote Desktop Connections to Electronic Flight Bag Servers. TDSC.

(10) Jun Zeng, et al. WATSON: Abstracting Behaviors from Audit Logs via Aggregation of Contextual Semantics. NDSS.

(11) Sunwoo Ahn, et al. Hawkware: Network Intrusion Detection based on Behavior Analysis with ANNs on an IoT Device. IEEE DAC.

---


## å››.æ€»ç»“

è¿™ç¯‡æ–‡ç« å°±å†™åˆ°è¿™é‡Œäº†ï¼Œå¸Œæœ›å¯¹æ‚¨æœ‰æ‰€å¸®åŠ©ã€‚ç”±äºä½œè€…è‹±è¯­å®åœ¨å¤ªå·®ï¼Œè®ºæ–‡çš„æ°´å¹³ä¹Ÿå¾ˆä½ï¼Œå†™å¾—ä¸å¥½çš„åœ°æ–¹è¿˜è¯·æµ·æ¶µå’Œæ‰¹è¯„ã€‚åŒæ—¶ï¼Œä¹Ÿæ¬¢è¿å¤§å®¶è®¨è®ºï¼ŒçœŸå¿ƒæ¨èåŸæ–‡ã€‚å­¦å®‰å…¨ä¸¤å¹´ï¼Œè®¤è¯†äº†å¾ˆå¤šå®‰å…¨å¤§ä½¬å’Œæœ‹å‹ï¼Œå¸Œæœ›å¤§å®¶ä¸€èµ·è¿›æ­¥ã€‚åŒæ—¶éå¸¸æ„Ÿè°¢å‚è€ƒæ–‡çŒ®ä¸­çš„å¤§ä½¬ä»¬ï¼Œæ„Ÿè°¢è€å¸ˆã€å®éªŒå®¤å°ä¼™ä¼´ä»¬çš„æ•™å¯¼å’Œäº¤æµï¼Œæ·±çŸ¥è‡ªå·±å¾ˆèœï¼Œå¾—åŠªåŠ›å‰è¡Œã€‚æ„Ÿæ©é‡è§ï¼Œä¸”è¡Œä¸”çæƒœï¼Œå°ççå¤ªå¯çˆ±äº†ï¼Œå“ˆå“ˆã€‚

æœ€åæ„Ÿè°¢CSDNå’Œè¯»è€…ä»¬åå¹´çš„é™ªä¼´ï¼Œä¸è®ºå¤–é¢å¦‚ä½•è¯„ä»·CSDNï¼Œè¿™é‡Œå§‹ç»ˆæ˜¯æˆ‘çš„å®¶ï¼Œåœ¨è¿™é‡Œå†™æ–‡ç« å¾ˆæ¸©é¦¨ï¼Œä¹Ÿè®¤è¯†äº†å¾ˆå¤šå¤§ä½¬å’Œæœ‹å‹ã€‚æ­¤å¤–ï¼Œä¸ªäººæ„Ÿè§‰ä»Šå¹´æ˜¯æˆ‘è¿‘åå¹´æ–‡ç« è´¨é‡æœ€é«˜çš„ä¸€å¹´ï¼Œæ¯ä¸€ç¯‡éƒ½å†™å¾—å¾ˆç”¨å¿ƒï¼Œéƒ½æ˜¯æˆ‘çš„è¡€è‚‰ï¼Œå¾ˆå¤šéƒ½è¦è‡ªå·±ä»é›¶å»å­¦ä¹ å†åˆ†äº«ï¼Œä¹Ÿå¸Œæœ›å¸®åŠ©æ›´å¤šåˆå­¦è€…ã€‚æ€»ä¹‹ï¼Œå¸Œæœ›è‡ªå·±è¿˜èƒ½å†™äºŒåå¹´ï¼Œäº”åå¹´ï¼Œä¸€è¾ˆå­ã€‚

(By:Eastmount 2021-12-14 æ™šä¸Š12ç‚¹ http://blog.csdn.net/eastmount/ )
