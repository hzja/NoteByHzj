# åŸåˆ›
ï¼š  [è®ºæ–‡é˜…è¯»] (13)è‹±æ–‡è®ºæ–‡æ¨¡å‹è®¾è®¡ï¼ˆModel Designï¼‰å¦‚ä½•æ’°å†™åŠç²¾å¥æ‘˜æŠ„â€”â€”ä»¥å…¥ä¾µæ£€æµ‹ç³»ç»Ÿ(IDS)ä¸ºä¾‹

# [è®ºæ–‡é˜…è¯»] (13)è‹±æ–‡è®ºæ–‡æ¨¡å‹è®¾è®¡ï¼ˆModel Designï¼‰å¦‚ä½•æ’°å†™åŠç²¾å¥æ‘˜æŠ„â€”â€”ä»¥å…¥ä¾µæ£€æµ‹ç³»ç»Ÿ(IDS)ä¸ºä¾‹

ã€Šå¨œç’‹å¸¦ä½ è¯»è®ºæ–‡ã€‹ç³»åˆ—ä¸»è¦æ˜¯ç£ä¿ƒè‡ªå·±é˜…è¯»ä¼˜ç§€è®ºæ–‡åŠå¬å–å­¦æœ¯è®²åº§ï¼Œå¹¶åˆ†äº«ç»™å¤§å®¶ï¼Œå¸Œæœ›æ‚¨å–œæ¬¢ã€‚ç”±äºä½œè€…çš„è‹±æ–‡æ°´å¹³å’Œå­¦æœ¯èƒ½åŠ›ä¸é«˜ï¼Œéœ€è¦ä¸æ–­æå‡ï¼Œæ‰€ä»¥è¿˜è¯·å¤§å®¶æ‰¹è¯„æŒ‡æ­£ï¼Œéå¸¸æ¬¢è¿å¤§å®¶ç»™æˆ‘ç•™è¨€è¯„è®ºï¼Œå­¦æœ¯è·¯ä¸ŠæœŸå¾…ä¸æ‚¨å‰è¡Œï¼ŒåŠ æ²¹ã€‚

<font color="red">**å‰ä¸€ç¯‡ä»ä¸ªäººè§’åº¦ä»‹ç»è‹±æ–‡è®ºæ–‡å¼•è¨€å¦‚ä½•æ’°å†™ã€‚è¿™ç¯‡æ–‡ç« å°†ä»ä¸ªäººè§’åº¦ä»‹ç»è‹±æ–‡è®ºæ–‡æ¨¡å‹è®¾è®¡ï¼ˆModel Designï¼‰å¦‚ä½•æ’°å†™ï¼Œå¹¶ä»¥å…¥ä¾µæ£€æµ‹ç³»ç»Ÿä¸ºä¾‹ï¼ˆIntrusion Detection Systemï¼‰ã€‚ä¸€æ–¹é¢è‡ªå·±è‹±æ–‡å¤ªå·®ï¼Œåªèƒ½é€šè¿‡æœ€åœŸçš„åŠæ³•æ…¢æ…¢æå‡ï¼Œå¦ä¸€æ–¹é¢æ˜¯è‡ªå·±çš„ä¸ªäººå­¦ä¹ ç¬”è®°ï¼Œå¹¶åˆ†äº«å‡ºæ¥å¸Œæœ›å¤§å®¶æ‰¹è¯„å’ŒæŒ‡æ­£ã€‚å¸Œæœ›è¿™ç¯‡æ–‡ç« å¯¹æ‚¨æœ‰æ‰€å¸®åŠ©ï¼Œè¿™äº›å¤§ä½¬æ˜¯çœŸçš„å€¼å¾—æˆ‘ä»¬å»å­¦ä¹ ï¼ŒçŒ®ä¸Šå°å¼Ÿçš„è†ç›–~fightingï¼**</font>

è¿™é‡Œé€‰æ‹©çš„è®ºæ–‡å¤šæ•°ä¸ºè¿‘ä¸‰å¹´çš„CCF Aå’ŒäºŒåŒºä»¥ä¸Šä¸ºä¸»ï¼Œå°¤å…¶æ˜¯é¡¶ä¼šé¡¶åˆŠã€‚å½“ç„¶ï¼Œä½œè€…èƒ½åŠ›æœ‰é™ï¼Œåªèƒ½ç»“åˆè‡ªå·±çš„å®åŠ›å’Œå®é™…é˜…è¯»æƒ…å†µå‡ºå‘ï¼Œä¹Ÿå¸Œæœ›è‡ªå·±èƒ½ä¸æ–­è¿›æ­¥ï¼Œæ¯ä¸ªéƒ¨åˆ†éƒ½ä¼šæŒç»­è¡¥å……ã€‚å¯èƒ½äº”å¹´åå¹´åï¼Œä¹Ÿä¼šè¯¦ç»†åˆ†äº«ä¸€ç¯‡è‹±æ–‡è®ºæ–‡å¦‚ä½•æ’°å†™ï¼Œç›®å‰ä¸»è¦ä»¥å­¦ä¹ å’Œç¬”è®°ä¸ºä¸»ã€‚å¤§ä½¬è¿˜è¯·é£˜è¿‡O(âˆ©_âˆ©)O

#### æ–‡ç« ç›®å½•

**å‰æ–‡èµæï¼š**

---


## ä¸€.æ¨¡å‹è®¾è®¡æˆ–æ–¹æ³•å¦‚ä½•æ’°å†™

è®ºæ–‡å¦‚ä½•æ’°å†™å› äººè€Œå¼‚ï¼Œä½œè€…ä»…åˆ†äº«è‡ªå·±çš„è§‚ç‚¹ï¼Œæ¬¢è¿å¤§å®¶æå‡ºæ„è§ã€‚ç„¶è€Œï¼ŒåšæŒé˜…è¯»æ‰€ç ”ç©¶é¢†åŸŸæœ€æ–°å’Œç»å…¸è®ºæ–‡ï¼Œè¿™ä¸ªå¤§å®¶åº”è¯¥ä¼šèµæˆï¼Œå¦‚æœèƒ½åšåˆ°ç›¸å…³é¢†åŸŸæ–‡çŒ®å¦‚æ•°å®¶çï¼Œå°±ç¦»ä½ æ’°å†™ç¬¬ä¸€ç¯‡è‹±æ–‡è®ºæ–‡æ›´è¿‘ä¸€æ­¥äº†ã€‚åœ¨æ¨¡å‹è®¾è®¡ä¸­ï¼Œé‡ç‚¹æ˜¯æ¨¡å‹å¦‚ä½•ä¸éœ€è¦è§£å†³çš„é—®é¢˜ç»“åˆï¼Œè®©äººè§‰å¾—ç¡®å®è¯¥æ¨¡å‹èƒ½è§£å†³ç±»ä¼¼çš„é—®é¢˜ï¼Œä¸€ä¸ªå¥½çš„æ•…äº‹æ˜¯è®ºæ–‡æˆåŠŸçš„å…³é”®ã€‚åŒæ—¶ï¼Œå¤šè¯»å¤šå†™æ˜¯åŸºæ“ï¼Œå…±å‹‰ï¼

### 1.è®ºæ–‡æ€»ä½“æ¡†æ¶åŠæ–¹æ³•æ’°å†™

è¯¥éƒ¨åˆ†å›é¡¾å’Œå‚è€ƒå‘¨è€å¸ˆçš„åšå£«è¯¾ç¨‹å†…å®¹ï¼Œæ„Ÿè°¢è€å¸ˆçš„åˆ†äº«ã€‚å…¸å‹çš„è®ºæ–‡æ¡†æ¶åŒ…æ‹¬ä¸¤ç§ï¼ˆThe typical â€œanatomyâ€ of a paperï¼‰ï¼Œå¦‚ä¸‹æ‰€ç¤ºï¼š

<mark>ç¬¬ä¸€ç§æ ¼å¼ï¼šç†è®ºç ”ç©¶</mark>

<mark>ç¬¬äºŒç§æ ¼å¼ï¼šç³»ç»Ÿç ”ç©¶</mark>

<mark>System Modelï¼ˆç³»ç»Ÿæ¨¡å‹ï¼‰</mark>

<mark>Mathematics and algorithmsï¼ˆç®—æ³•ï¼‰</mark>

æ³¨æ„ï¼Œé˜…è¯»ç†è§£è¯¥éƒ¨åˆ†æ˜¯å‰æï¼Œåœ¨é˜…è¯»ç®—æ³•å®ç°å‰ï¼Œæˆ‘ä»¬éœ€è¦æ³¨æ„ä»¥ä¸‹å‡ ç‚¹ï¼š

---


### 2.æ–¹æ³•æˆ–æ¨¡å‹è®¾è®¡æ’°å†™

è¯¥éƒ¨åˆ†ä¸»è¦æ˜¯å­¦ä¹ æ˜“è‰è€å¸ˆä¹¦ç±ã€Šå­¦æœ¯å†™ä½œåŸæ¥æ˜¯è¿™æ ·ã€‹ï¼Œå…·ä½“å¦‚ä¸‹ï¼š

â€œé€šå¸¸ï¼Œæˆ‘ä¼šæŒ‡å¯¼å­¦ç”Ÿä»æ–¹æ³•å’Œç»“æœéƒ¨åˆ†å¼€å§‹ä¸€ç¯‡è®ºæ–‡çš„å†™ä½œã€‚æ–¹æ³•å’Œç»“æœç›¸æ¯”äºè®ºæ–‡å…¶ä»–éƒ¨åˆ†æ¥è¯´æ¯”è¾ƒå¥½å†™ï¼Œå­¦ç”Ÿå‚ç…§æ–‡çŒ®â€˜ä¾è‘«èŠ¦ç”»ç“¢â€™ï¼Œä¹Ÿèƒ½å¿«é€ŸæŒæ¡ã€‚ä¸€èˆ¬å°±æ˜¯æŒ‰éƒ¨å°±ç­åœ°å†™ï¼Œå®éªŒæ˜¯æ€ä¹ˆåšçš„ï¼Œæ–¹æ³•éƒ¨åˆ†å°±æ€ä¹ˆå†™ï¼›å‘ç°äº†ä»€ä¹ˆï¼Œç»“æœéƒ¨åˆ†å°±å†™ä»€ä¹ˆã€‚â€

> 
<mark>ä¸ªäººè€Œè¨€ï¼Œæ„Ÿè§‰ä¸å¤ªèµåŒè¿™ä¸ªè§‚ç‚¹ã€‚ç§ä»¥ä¸ºæ–¹æ³•æˆ–ç³»ç»Ÿè®¾è®¡éå¸¸é‡è¦ï¼Œè‡³å°‘åœ¨è®¡ç®—æœºé¢†åŸŸï¼Œå°¤å…¶æ–¹æ³•å¯¹åº”çš„æ¡†æ¶å›¾ï¼Œä¸€å®šç¨‹åº¦ä¸Šèƒ½å†³å®šæ‚¨è®ºæ–‡çš„è§‚ç‚¹ã€åˆ›æ–°åŠè´¡çŒ®ï¼Œä¹Ÿå†³å®šè®ºæ–‡æœ€ç»ˆçš„å±‚æ¬¡ã€‚å…¶æ¬¡ï¼Œå¦‚æœæƒ³æŠ•é¡¶ä¼šæˆ–é¡¶åˆŠï¼Œä¸€ä¸ªå¥½çš„æ•…äº‹ï¼Œæˆ–è€…ä¸€ä¸ªä¸æ‚¨è´¡çŒ®å»åˆçš„æ–¹æ³•æè¿°è‡³å…³é‡è¦ã€‚å½“ç„¶ï¼Œåˆå­¦è€…å†™ä½œä»æ¨¡å‹è®¾è®¡å¼€å§‹æ˜¯å¯ä»¥çš„ã€‚</mark>


åœ¨æ–¹æ³•éƒ¨åˆ†çš„å†™ä½œä¸­ï¼Œéœ€è¦æ³¨æ„ï¼š

è¯¥éƒ¨åˆ†æœ‰ä¸€ä¸ªé‡è¦çš„é—®é¢˜â€”â€”<font color="red">**è°‹ç¯‡å¸ƒå±€ï¼šæ€ä¹ˆè®²å¥½ä¸€ä¸ªæ•…äº‹**</font>

<mark>ç¬¬ä¸€ä¸ªé—®é¢˜ï¼šä»€ä¹ˆæ ·çš„æ•…äº‹æ˜¯å¥½æ•…äº‹ï¼Ÿ</mark>

åœ¨è¯„ä¼°ä¸€ä¸ªç§‘ç ”æˆæœçš„ç§‘å­¦ä»·å€¼æ—¶ï¼Œæœ€é‡è¦çš„æ˜¯åˆ›æ–°æ€§å’Œç ”ç©¶æ„ä¹‰ã€‚åˆ›æ–°æ€§æ˜¯æŒ‡ç ”ç©¶è€…ä¸æ˜¯å•çº¯åœ°è·Ÿéšæˆ–é‡å¤åˆ«äººçš„ç ”ç©¶ï¼Œè€Œæ˜¯æœ‰è‡ªå·±çš„ç‹¬åˆ°çš„æ–°è´¡çŒ®ã€‚æ®è¯´ï¼Œç ”ç©¶è¦ç»å†ä¸‰ä¸ªé˜¶æ®µï¼šâ€œme tooâ€ã€â€œme betterâ€ã€â€œme onlyâ€ã€‚åŒæ ·ï¼Œåˆ›æ–°æ€§ä¹Ÿå¯ä»¥å¥—ç”¨ä¸‰ä¸ªé˜¶æ®µæè¿°ã€‚

**åŒæ—¶ï¼Œåˆ›æ–°ä¸æ˜¯å¤©é©¬è¡Œç©ºã€‚ç§‘ç ”ä¸­çš„åˆ›æ–°éƒ½æ˜¯æœ‰è¾¹ç•Œçš„ï¼Œåˆ›æ–°æ˜¯æœ‰ç ”ç©¶æ„ä¹‰çš„ã€‚æ€»ä¹‹ï¼Œåœ¨å¼€å§‹å†™è®ºæ–‡ä¹‹å‰ï¼Œæˆ‘ä»¬éœ€è¦è€ƒè™‘è¿™ç¯‡æ–‡ç« å¤§æ¦‚è¦æŠ•ç¨¿ç»™ä»€ä¹ˆæœŸåˆŠï¼Œæ˜¯å°é¢†åŸŸçš„ä¸“ä¸šæœŸåˆŠï¼Œè¿˜æ˜¯ä¸€èˆ¬çš„å¿ƒç†å­¦æœŸåˆŠï¼Œè¿™ä¸ªå†³å®šä¼šå½±å“ä½ çš„æ–‡ç« æ€è·¯ä»¥åŠè®²æ•…äº‹è¦è¾¾åˆ°çš„å±‚æ¬¡ã€‚**

æ¯”èµ·å…¶ä»–çš„å†™ä½œæŠ€èƒ½ï¼Œè®²æ•…äº‹çš„èƒ½åŠ›æ›´éš¾æŒæ¡ï¼Œå› ä¸ºè¿™æ˜¯ä¸€ç§â€œåªå¯æ„ä¼šä¸å¯è¨€ä¼ â€çš„ç¥ç§˜æŠ€èƒ½ï¼Œç”šè‡³æœ‰ä¸å°‘äººè§‰å¾—è¿™æ˜¯å†™ä½œçš„å¤©èŠ±æ¿ã€‚æœ‰äº›ç ”ç©¶è€…åœ¨å›½å¤–è€æ¿çš„å¤§å®éªŒå®¤é‡Œèƒ½åšå‡ºéå¸¸æ¼‚äº®çš„å·¥ä½œï¼Œå›åˆ°æŸœå†…è‡ªå·±åšPIæ—¶æˆæœå´å¹³å¹³æ— å¥‡ï¼Œå¤šæ˜¯å› ä¸ºå›½å¤–å¤§è€æ¿çš„ç ”ç©¶è§†é‡ï¼ˆvisionï¼‰å’Œå“å‘³å†³å®šäº†æ–‡ç« çš„å±‚æ¬¡ï¼Œè€Œä»–ä»¬è‡ªå·±å´æ²¡æœ‰å­¦ä¼šææœ‰å‰ç»æ€§å’Œåˆ›æ–°æ€§çš„ç§‘å­¦é—®é¢˜ã€‚

> 
ä¸ªäººæƒ³å¯¹ä¸Šé¢çš„è§‚ç‚¹è¿›è¡Œè¡¥å……ã€‚ç¡®å®å›½å¤–çš„å¤§è€æ¿èƒ½å¸¦ç»™æˆ‘ä»¬å¾ˆå¤§çš„è§†é‡ï¼Œæå‡è®ºæ–‡çš„å±‚æ¬¡ã€‚ç„¶è€Œï¼Œæˆ‘ä»¬å¤§éƒ¨åˆ†çš„ç§‘ç ”å·¥ä½œè€…ï¼Œå°¤å…¶æ˜¯åšå£«ç”Ÿï¼Œå¾ˆå°‘èƒ½æ¥è§¦åˆ°è¿™ä¹ˆå‰å®³çš„ç§‘å­¦å®¶ï¼Œç”šè‡³å¾ˆå¤šéƒ½éœ€è¦ç‹¬ç«‹çš„æè®ºæ–‡ã€‚æ­¤æ—¶ï¼Œæ€ä¹ˆåŠå‘¢ï¼Ÿ<br/><br/> <font color="red">æˆ‘è§‰å¾—ä¸€æ–¹é¢æˆ‘ä»¬éœ€è¦å¤šè¯»è®ºæ–‡ï¼Œå¤šçœ‹å›½å¤–å¤§ä½¬ä»¬çš„åˆ†äº«ï¼Œé€šè¿‡å­¦ä¹ å’Œå¯¹æ¯”ä»–ä»¬çš„è®ºæ–‡å’Œæ–¹æ³•æ¥æå‡è‡ªå·±ï¼›å¦ä¸€æ–¹é¢æˆ‘ä»¬è¦å¤šå†™è®ºæ–‡ï¼Œå¤šåšå®éªŒï¼Œå–„äºå…³æ³¨é—®é¢˜ï¼Œå½“æˆ‘ä»¬çš„è®ºæ–‡æ•…äº‹å™è¿°èƒ½å†™å¾—åƒé¡¶ä¼šã€é¡¶åˆŠæ—¶ï¼Œæˆ‘ä»¬è‡³å°‘ä¼šä¸­ä¸€äº›SCIäºŒåŒºã€Bä¼šï¼Œå¦‚æœå†æŒä¹‹ä»¥æ’çš„æå‡è´¨é‡ã€æƒ³ideaï¼Œæœ€åè‚¯å®šä¹Ÿèƒ½å†™å‡ºé«˜è´¨é‡è®ºæ–‡ã€‚èŠ¸èŠ¸ä¼—ç”Ÿï¼Œè™½ç„¶æˆ‘ä»¬æ²¡æœ‰è¿™äº›å¤§ä½¬çš„å¸®åŠ©ï¼Œä½†æˆ‘ç›¸ä¿¡é€šè¿‡åŠªåŠ›è‚¯å®šèƒ½å­¦ä¼šç§‘ç ”ï¼Œæå‡è‡ªå·±ã€‚è¿™ä¹Ÿæ˜¯æˆ‘å†™è¿™ä¸ªä¸“æ çš„ç›®çš„ï¼Œä»é›¶å¼€å§‹å­¦ä¹ è‹±æ–‡å†™ä½œï¼Œç”¨æœ€åœŸçš„æ–¹æ³•å­¦ä¹ å†™ä½œã€‚åšå£«è·¯ä¸Šä¸€èµ·å‰è¡Œï¼Œç›¸ä¿¡è‡ªå·±ï¼ŒåŠ æ²¹~</font>


<mark>ç¬¬äºŒä¸ªé—®é¢˜ï¼šæ€ä¹ˆå°†ä¸€ä¸ªæ•…äº‹è®²å¥½ï¼Ÿ</mark><br/> æœ‰äº†æ•…äº‹å†…æ ¸ï¼Œæˆ‘ä»¬è¿˜éœ€è¦æŠŠè¿™ä¸ªæ•…äº‹å®Œç¾åœ°å‘ˆç°å‡ºæ¥ã€‚ä¸ºæ­¤ï¼Œæˆ‘ä»¬éœ€è¦å­¦ä¹ å¦‚ä½•åˆ©ç”¨å¤§çº²ï¼ˆoutlineï¼‰æ¥å¸®åŠ©æ–‡ç« å¸ƒå±€ã€‚å¤§çº²æ˜¯å…³äºæ–‡ç« ç»„ç»‡æ¶æ„çš„å†™ä½œè®¡åˆ’ï¼Œå®ƒå¯ä»¥å¸®åŠ©ä½ æ€è€ƒæ–‡ç« çš„ä¸»è¦æ•…äº‹å’Œæ¡†æ¶ï¼ŒæŠ“ä½æ ¸å¿ƒç§‘å­¦é—®é¢˜ï¼ŒæŠŠæ–‡ç« çš„æ•…äº‹æœ‰é¡ºåºã€æœ‰é€»è¾‘ã€æœ‰é‡ç‚¹åœ°å‘ˆç°å‡ºæ¥ã€‚

---


### 3.æ¨¡å‹è®¾è®¡æ’°å†™ä¹‹ä¸ªäººç†è§£

ä¸ªäººæ„Ÿè§‰ï¼šæ¨¡å‹è®¾è®¡éå¸¸é‡è¦ï¼Œé€šå¸¸æˆ‘çš„å†™æ³•å¦‚ä¸‹ã€‚

**ä»¥å…¥ä¾µæ£€æµ‹ï¼ˆintrusion detectionï¼‰ä¸ºä¾‹ï¼Œç®€å•ä»‹ç»å‡ ç¯‡ç»å…¸è®ºæ–‡çš„æ¨¡å‹è®¾è®¡å†™æ³•åŠç»„æˆï¼Œé€šå¸¸éƒ½æ˜¯è®ºæ–‡æ¡†æ¶æˆ–ç®—æ³•å¦‚ä½•å®ç°çš„ï¼ŒåŒ…æ‹¬æ¡†æ¶å›¾ã€ç®—æ³•ã€å…¬å¼ã€è¡¨æ ¼ã€çº¦æŸç­‰ã€‚**

<mark>(1) Chuanpu Fu, et al. Realtime Robust Malicious Traffic Detection via Frequency Domain Analysis. CCS.</mark>

> 
4 DESIGN DETAILS



<mark>(2) Sunwoo Ahn, et al. Hawkware: Network Intrusion Detection based on Behavior Analysis with ANNs on an IoT Device. DAC</mark>

> 
III. HAWKWARE DESIGN



<mark>(3) Ning Wang, et al. MANDA: On Adversarial Example Detection for Network Intrusion Detection System. IEEE Infocom.</mark>

> 
III. SYSTEM MODEL AND THREAT MODEL

IV. THE MANDA SYSTEM



<mark>(4) Mohammed A. Ambusaidi, et al. Building an Intrusion Detection System Using a Filter-Based Feature Selection Algorithm. IEEE TRANSACTIONS ON COMPUTERS</mark>

> 
4 INTRUSION DETECTION FRAMEWORK BASED ON LEAST SQUARE SUPPORT VECTOR MACHINE



<mark>(5) Jun Zeng, et al. WATSON: Abstracting Behaviors from Audit Logs via Aggregation of Contextual Semantics. NDSS.</mark>

> 
III. WATSON DESIGN



<mark>(6) Ron Bitton, et al. A Machine Learning-Based Intrusion Detection System for Securing Remote Desktop Connections to Electronic Flight Bag Servers. IEEE TDSC.</mark>

> 
3 AN OVERVIEW OF THE PROPOSED NIDS FOR SECURING RDP CONNECTIONS

4 ADETAILED DESCRIPTION OF THE PROPOSED NIDS FOR SECURING RDP CONNECTIONS



---


### 4.æ•´ä½“ç»“æ„æ’°å†™è¡¥å……

åŒæ—¶ï¼Œæ¨¡å‹è®¾è®¡æ•´ä½“ç»“æ„å’Œå†™ä½œç»†èŠ‚è¡¥å……å‡ ç‚¹ï¼šï¼ˆå¼•ç”¨å‘¨è€å¸ˆåšå£«è¯¾ç¨‹ï¼Œå—ç›ŠåŒªæµ…ï¼‰

å®éªŒéƒ¨åˆ†åŒæ ·æœ‰å¾ˆå¤šç»†èŠ‚ï¼Œä¸‹ä¸€ç¯‡æ–‡ç« æˆ‘ä»¬å†è¯¦ç»†ä»‹ç»ã€‚

---


## äºŒ.å…¥ä¾µæ£€æµ‹ç³»ç»Ÿè®ºæ–‡å¼•è¨€å¥å­

ä¸ªäººä¹ æƒ¯å°†æ¨¡å‹è®¾è®¡ç»“åˆæ¡†æ¶å›¾è¿›è¡Œæè¿°ï¼Œä¹Ÿæ¬¢è¿å¤§å®¶æ‰¹è¯„æŒ‡æ­£ã€‚ä¸‹é¢ä¸»è¦ä»¥CCF Aä¼šè®®å’ŒæœŸåˆŠè®ºæ–‡ä¸ºä¸»è¿›è¡Œä»‹ç»ï¼Œé‡ç‚¹ä»¥å…¥ä¾µæ£€æµ‹ç³»ç»Ÿï¼ˆIntrusion Detection Systemï¼ŒIDSï¼‰é¢†åŸŸä¸ºä¸»ã€‚

### ç¬¬0éƒ¨åˆ†ï¼šå¼•å…¥

è¯¥éƒ¨åˆ†ä¸»è¦æ˜¯æ¨¡å‹è®¾è®¡æ¿å—çš„å¼•å…¥ï¼Œä»‹ç»è¿™éƒ¨åˆ†çš„æ ¸å¿ƒå†…å®¹ç»„æˆã€‚

<mark>In this section, we present the design details of Whisper, i.e., the design of three main modules in Whisper.</mark>

<mark>We will first describe the design goals of our provenance-based intrusion detection system, then we elaborate (è¯¦ç»†æè¿°) the details on design and implementation of this system.</mark>

<mark>In this section, we outline our SDN-based system to enforce MUD policies and dynamically inspect exception traffic which is a small fraction of total packets to/from IoT devices. Our system uses as input MUD profiles of 28 consumer IoT devices that we have automatically generated by the MUDgee tool [9] using packet traces collected over several months. We next begin with the architecture of our system.</mark>

<mark>In this section, we present the design of MANDA, the proposed AE detector for ML-based IDS, and explain the rationale behind each design choice. The valid input to an IDS system is real network traffic flows in the problem-space. Therefore, the generated AE should also lie in the same problem-space of IDS. We adapt existing feature-space AE generation algorithms to problem-space algorithms in order to generate AEs that can map back to valid real network events. The key insight for detecting AEs is to identify the discrepancy between true benign samples and AEs. Such an intuition motivates us to investigate AEâ€™s position to the decision-boundary of the IDS model and its position in the traffic manifolds formed by training samples.</mark>

<mark>In this section, the sensor data are analyzed in the frequency domain based on the NPGF. First, the second-order NPGF is introduced in Section III-A to reconstruct the IoT sensor data. To conduct the frequency-domain analysis for the sensor data reconstruction, GFT and its inverse transform are presented in Section III-B, and the frequency-domain analysis for the second-order NPGF is presented in Section III-C.</mark>

<mark>In this section, we describe how the disagreement-based semi-supervised learning works, and introduce how to use it to construct a false alarm filter (simply called DASSL false alarm filter). Then, we present the framework of DAS-CIDS and show how to combine semi-supervised learning with CIDSs.</mark>

<mark>In this section, we first present the intuition of a conventional LSTM architecture. Then, we explain in detail the bidirectional LSTM (BiDLSTM) architecture. We further describe the NSL-KDD dataset used to train our model.</mark>

<mark>In this section, we give a technical description of the features in the data sets used in our experiments. We then explain the details of the techniques employed for adversarial example generation. This leads to the layout of our computational setting.</mark>

---


### ç¬¬1éƒ¨åˆ†ï¼šSystem Model / Overview

è¯¥éƒ¨åˆ†ä¸»è¦ä»‹ç»æ¨¡å‹çš„æ€»ä½“æ¡†æ¶å’Œä¸»è¦å®ç°æ–¹æ³•ï¼Œæœ‰äº›è®ºæ–‡ä¹Ÿå°†Overviewæ”¾å…¥æ¨¡å‹è®¾è®¡çš„ç¬¬ä¸€éƒ¨åˆ†ï¼Œå½“ç„¶å¾ˆå¤šè®ºæ–‡å°†Overviewç½®äºæ¨¡å‹è®¾è®¡å‰å•ç‹¬å™è¿°ã€‚

<mark>The overall architecture of Hawkware is depicted in Figure 1. Hawkware is divided into two main modules: the monitor module (MM) and the detection module (DM). MM monitors both the network and device behaviors and extracts the relevant features for the ANN named as Hawknet. DM detects any suspicious behaviors indicating network intrusions by utilizing Hawknet.</mark>

<mark>Hawkware consists of five components and their functions are summarized as follows: (1) the packet analyzer (PA) analyzes network packet headers and extracts relevant features; (2) the system call logger (SCL) records the device behavior and extracts features related to incoming/outgoing network packets; (3) the feature preprocessor (FP) aggregates both extracted features and transfer them as inputs to Hawknet; (4) the Hawknet controller (HC) examines the Hawknetâ€™s outputs and determines the existence of intrusions; (5) the Hawknet quantifies the degree of anomaly.</mark>

<mark>The proposed anomaly detection method is designed to prevent malicious entities from exploiting vulnerabilities in the remote desktop server. The proposed solution specifically focuses on the remote framebuffer protocol [1], which is one of the common protocols used for connecting and interacting with computers remotely.</mark>

<mark>The framework of the proposed intrusion detection system is depicted in Fig. 1. The detection framework is comprised of four main phases: (1) data collection, where sequences of network packets are collected, (2) data preprocessing, where training and test data are preprocessed and important features that can distinguish one class from the others are selected, (3) classifier training, where the model for classification is trained using LS-SVM, and (4) attack recognition, where the trained classifier is used to detect intrusions on the test data.</mark>

<mark>Support Vector Machine is a supervised learning method [38]. It studies a given labeled dataset and constructs an optimal hyperplane in the corresponding data space to separate the data into different classes. Instead of solving the classification problem by quadratic programming, Suykens and Vandewalle [39] suggested re-framing the task of classification into a linear programming problem. They named this new formulation the Least Squares SVM (LS-SVM). LS-SVM is a generalized scheme for classification and also incurs low computation complexity in comparison with the ordinary SVM scheme [40]. One can find more details about calculating LS-SVM in Appendix B, available in the online supplemental material. The following sections explain each phase in detail.</mark>

<mark>Figure 1 summarises the MAGPIE architecture. Its collection phase captures and decodes the data coming from cyber (computation, communication) or physical feeds (e.g., audio, signal strength). It can dynamically activate or deactivate interfaces and decode the corresponding raw feeds, such as sensor readings or network datagrams.</mark>

<mark>Smart homes generate large volumes of usually encrypted data [24] that may differ considerably between different environments. In the transcription phase, MAGPIE considers only meta-data that are consistent across different smart homes. â€¦ Moreover, by reading only smart home network communication flow meta-data, MAGPIE is better positioned to preserve privacy. MAGPIE extracts meta-data streams (MDS) based on specific interface datastream parsing logic (e.g., communication/application/sensor protocol) (Figure 2).</mark>

<mark>Fig. 1 shows the architecture of Pagoda. It consists of six components, namely, Provenance collection, Provenance pruning, Provenance storage and maintenance, Rule building and deduplication, Detection process andForensic analysis. The Provenance collection component ï¼ˆéƒ¨åˆ†ï¼‰ is responsible for monitoring the behaviors of the normal/intrusion applications, intercepting the system calls invoked by them and translate these system calls to causality-based provenance records. Then the provenance pruning module omits the provenance records that are not related to intrusion detection to improve the detection accuracy and save the storage space simultaneously. The Provenance storage and maintenance component uses key-value memory database (e.g., Redis [37]) to store rule database and run the provenance-based intrusion detection algorithm to make real-time detection. The Rule building and deduplication module constructs the rule sets for intrusion detection and removes the duplicated strings to make the rule database as small as possible. The Detection process component judges whether the intrusion has happened according to the rule sets and also updates the rule sets according to the detection results. At last, the Forensic analysis module looks for the system vulnerability and intrusion sources by making forward and backward queries.</mark>

<mark>Fig. 3 illustrates the overall process of applying the proposed fine-grained algorithm for evaluating an incoming packet. As can be seen, the process starts with a new incoming packet. First, two types of features, contextual and content-based, are extracted from the packet (step 1). The contextual features are extracted from the header of the packet, and the content-based features are extracted from the packetâ€™s payload. Next, for dimensionality reduction, as well as for improving detection rate, a â€˜message type classificationâ€™ PCA model is applied on the content-based features (step 2). The resulting PCA features, along with the contextual features, are used as the input vector to a decision tree model.</mark>

<mark>The decision tree model is applied on the packetâ€™s feature vector to classify the packet based on its message type (step 3). Note that in the example provided in Fig. 3 the packet is classified by the decision tree model as a â€˜Pointer Eventâ€™ packet.</mark>

<mark>Based on the derived message type (â€˜Pointer Eventâ€™), in the next step (step 4) a second PCA model which was initially created for each specific message type, is applied on the original content-based features of the packet.</mark>

<mark>Finally, the resulting PCA features are used by a k-means algorithm and CBLOF model of the specific message type (â€˜Pointer Eventâ€™) in order to assign an anomaly score for the packet.</mark>

<mark>A typical architecture of a ML-based IDS is shown in Fig. 1. Usually, IDS is a passive infrastructure which rarely interferes with the network traffic under monitoring. An IDS sniffs the internal interface of the firewall in a read-only mode and sends alerts to an IDS management server via a read-and-write network interface [33], [34]. As Fig. 1 shows, a ML-based IDS is composed of the following modules [3]:</mark>

---


### ç¬¬2éƒ¨åˆ†ï¼šæ•°æ®é¢„å¤„ç†

<mark>The data obtained during the phase of data collection are first processed to generate the basic features such as the ones in KDD Cup 99 dataset [41]. This phase contains three main stages shown as follows.</mark>

<mark>**Data Transferring.** The trained classifier requires each record in the input data to be represented as a vector of real number. Thus, every symbolic feature in a dataset is first converted into a numerical value. For example, the KDD CUP 99 dataset contains numerical as well as symbolic features. These symbolic features include the type of protocol (i.e., TCP, UDP and ICMP), service type (e.g., HTTP, FTP, Telnet and so on) and TCP status flag (e.g., SF, REJ and so on). The method simply replaces the values of the categorical attributes with numeric values.</mark>

<mark>**Data Normalisation.** An essential step of data preprocessing after transferring all symbolic attributes into numerical values is normalisation. Data normalisation is a process of scaling the value of each attribute into a well-proportioned range, so that the bias in favor of features with greater values is eliminated from the dataset. Data used in Section 5 are standardised. Every feature within each record is normalised by the respective maximum value and falls into the same range of [0-1]. The transferring and normalisation process will also be applied to test data.</mark>

<mark>As mentioned in Section 4.3 above, the NSL-KDD dataset comes with 38 numeric and 3 non-numeric features. However, just as any RNN, the proposed BiDLSTM model only handles numerical data inputs. As a result, there is a need for us to convert all non-numeric features to numeric representations. The features (protocol type, service and flag) are the non-numeric features in the NSL-KDD dataset that require transformation into numeric form. These three features are encoded and assigned integer values unique to each of them. After successfully transforming these features into numeric form, the next appropriate thing is feature scaling. Feature scaling ensures that the dataset is in the normalized form. The values of some features in the NSL-KDD dataset (e.g., src_bytes and dst_bytes) have uneven distribution, so we scale every featureâ€™s values within the range of (0, 1) using Minâ€“Max scaling. By this, we ensure that our classifier does not produce biased outcomes. The expression for the Minâ€“Max feature scaling is as follows:</mark>

<mark>Note that we apply PCA transformation twice in the overall proposed process. In the first task, namely the message type classification, we apply the PCA transformation on all packet payloads in order to bring out the patterns that are useful for differentiating packets by its message types, as well as for dimensionality reduction. In the second task, namely the fine-grained anomaly detection, we apply the PCA transformation on subsets of packets belonging to the same message type; this is performed separately for each message type.</mark>

---


### ç¬¬3éƒ¨åˆ†ï¼šæœ¬æ–‡æå‡ºçš„æ ¸å¿ƒç®—æ³•ï¼ˆç‰¹å¾é€‰æ‹©ï¼‰

<mark>Thus, we need a measure capable of analysing the relation between two variables no matter whether they are linearly or nonlinearly dependent. For these reasons, this work intends to explore a means of selecting optimal features from a feature space regardless of the type of correlation between them.</mark>

<mark>Even though every connection in a dataset is represented by various features, not all of these features are needed to build an IDS. Therefore, it is important to identify the most informative features of traffic data to achieve higher performance. In the previous section using Algorithm 1, a flexible method for the problem of feature selection, FMIFS, is developed. However, the proposed feature selection algorithms can only rank features in terms of their relevance but they cannot reveal the best number of features that are needed to train a classifier. Therefore, this study applies the same technique proposed in [12] to determine the optimal number of required features. To do so, the technique first utilises the proposed feature selection algorithm to rank all features based on their importance to the classification processes.</mark>

<mark>Then, incrementally the technique adds features to the classifier one by one. The final decision of the optimal number of features in each method is taken once the highest classification accuracy in the training dataset is achieved.</mark>

<mark>The selected features for all datasets are depicted in Tables 1 [a, b, c], where each row lists the number and the indexes of the selected features with respect to the corresponding feature selection algorithm. In addition, for KDD Cup 99 and to make a comparison with those systems that have been evaluated on different types of attacks (discussed in Sections 5.5 and 5.6), we construct five classes. One of these classes contains purely the normal records and the other four hold different types of attacks (i.e., DoS, Probe, U2R, R2L), respectively. The proposed feature selection algorithm is applied to the aforementioned classes. The selected features are shown in Table 3.</mark>

---


### ç¬¬4éƒ¨åˆ†ï¼šæ¨¡å‹å®ç°è¯¦è§£

<mark>The proposed solution (i.e., the fine-grained anomaly detection algorithm) for detecting anomalous TCP packets in RFB traffic combines supervised classification techniques, together with unsupervised cluster analysis and anomaly detection methods. The solution consists of two primary phases, the Model Construction Phase in which we utilize legitimate RFB traffic to construct a predictive model which represents the normal protocol behavior; and the Detection Phase in which we apply these models in order to detect anomalous protocol behavior.</mark>

<mark>Now we utilize the statistical clustering algorithm to learn the patterns of the frequency domain features obtained from the feature extraction module with the selected parameters. We train the statistical clustering algorithm with only benign traffic. In the training phase, this module calculates the clustering centers of the frequency domain features and the averaged training loss. In order to improve the robustness of Whisper and reduce false positive caused by the extreme values, we segment the frequency domain feature matrix R with a sampling window of length. We use â€¦ to denote the number of samples and â€¦ to denote the start points. We average the sampling window on the dimension of the feature sequence and use â€¦ to indicate the input of the clustering algorithm. We can obtain:</mark>

<mark>In this module, we extract the frequency domain features from high speed traffic. We acquire the per-packet features of ğ‘ packets from the same flow by polling the high speed packet parser module. We use the mathematical representation similar to Bartos et al. [4] to denote the features.</mark>

<mark>Once the optimal subset of features is selected, this subset is then taken into the classifier training phase where LS-SVM is employed. Since SVMs can only handle binary classification problems and because for KDD Cup 99 five optimal feature subsets are selected for all classes, five LS-SVM classifiers need to be employed. Each classifier distinguishes one class of records from the others. For example the classifier of Normal class distinguishes Normal data from nonNormal (all types of attacks). The DoS class distinguishes DoS traffic from non-DoS data (including Normal, Probe, R2L and U2R instances) and so on. The five LS-SVM classifiers are then combined to build the intrusion detection model to distinguish all different classes.</mark>

---


### ç¬¬5éƒ¨åˆ†ï¼šå…¬å¼å¼•å‡ºè¡¨è¾¾

è¿™é‡Œä»…ç»™å‡ºå…¬å¼çš„å¼•å‡ºå¥å­ã€‚

**(1) Chuanpu Fu, et al. Realtime Robust Malicious Traffic Detection via Frequency Domain Analysis. CCS.**

**(2) Mohammed A. Ambusaidi, et al. Building an Intrusion Detection System Using a Filter-Based Feature Selection Algorithm. IEEE TRANSACTIONS ON COMPUTERS.**

**æ¨¡å‹è¯„ä¼°å…¬å¼ï¼š**

**(3) Ning Wang, et al. MANDA: On Adversarial Example Detection for Network Intrusion Detection System. IEEE INFOCOM.**

**å…¶ä»–å¥å­ï¼š**

---


## ä¸‰.æ¨¡å‹æ¡†æ¶å›¾

å¥½çš„æ¡†æ¶å›¾æ˜¯éå¸¸é‡è¦çš„ï¼Œä¸‹é¢ç»™å‡ºIDSæ¯”è¾ƒç»å…¸çš„å‡ ä¸ªæ€»ä½“æ¡†æ¶ã€‚

(1) Chuanpu Fu, et al. Realtime Robust Malicious Traffic Detection via Frequency Domain Analysis. CCS.

(2) Ron Bitton, et al. A Machine Learning-Based Intrusion Detection System for Securing Remote Desktop Connections to Electronic Flight Bag Servers. IEEE TDSC.

(3) Tohid Shekari, et al. RFDIDS: Radio Frequency-based Distributed Intrusion Detection System for the Power Grid. NDSS.

(4) Ryan Heartfield, et al. Self-Configurable Cyber-Physical Intrusion Detection for Smart Homes Using Reinforcement Learning. IEEE TIFS.

(5) Congyuan Xu, et al. A Method of Few-Shot Network Intrusion Detection Based on Meta-Learning Framework. IEEE TIFS.

(6) Jun Zeng, et al. WATSON: Abstracting Behaviors from Audit Logs via Aggregation of Contextual Semantics. NDSS.

(7) Ning Wang, et al. MANDA: On Adversarial Example Detection for Network Intrusion Detection System. IEEE Infocom.

(8) Sunwoo Ahn, et al. Hawkware: Network Intrusion Detection based on Behavior Analysis with ANNs on an IoT Device. DAC

(9) Xinghua Li, et al. Sustainable Ensemble Learning Driving Intrusion Detection Model. IEEE TDSC.

(10) Neha Gupta, et al. LIO-IDS: Handling class imbalance using LSTM and improved one-vs-one technique in intrusion detection system. Computer Networks.

(11) Ron Bitton, et al. A Machine Learning-Based Intrusion Detection System for Securing Remote Desktop Connections to Electronic Flight Bag Servers. IEEE TDSC.

---


## å››.æ€»ç»“

è¿™ç¯‡æ–‡ç« å°±å†™åˆ°è¿™é‡Œäº†ï¼Œå¸Œæœ›å¯¹æ‚¨æœ‰æ‰€å¸®åŠ©ã€‚ç”±äºä½œè€…è‹±è¯­å®åœ¨å¤ªå·®ï¼Œè®ºæ–‡çš„æ°´å¹³ä¹Ÿå¾ˆä½ï¼Œå†™å¾—ä¸å¥½çš„åœ°æ–¹è¿˜è¯·æµ·æ¶µå’Œæ‰¹è¯„ã€‚åŒæ—¶ï¼Œä¹Ÿæ¬¢è¿å¤§å®¶è®¨è®ºï¼ŒçœŸå¿ƒæ¨èåŸæ–‡ã€‚å­¦å®‰å…¨ä¸¤å¹´ï¼Œè®¤è¯†äº†å¾ˆå¤šå®‰å…¨å¤§ä½¬å’Œæœ‹å‹ï¼Œå¸Œæœ›å¤§å®¶ä¸€èµ·è¿›æ­¥ã€‚åŒæ—¶éå¸¸æ„Ÿè°¢å‚è€ƒæ–‡çŒ®ä¸­çš„å¤§ä½¬ä»¬ï¼Œæ„Ÿè°¢è€å¸ˆã€å®éªŒå®¤å°ä¼™ä¼´ä»¬çš„æ•™å¯¼å’Œäº¤æµï¼Œæ·±çŸ¥è‡ªå·±å¾ˆèœï¼Œå¾—åŠªåŠ›å‰è¡Œã€‚æ„Ÿæ©é‡è§ï¼Œä¸”è¡Œä¸”çæƒœï¼Œå°ççå¤ªå¯çˆ±äº†ï¼Œå“ˆå“ˆã€‚

æœ€åæ„Ÿè°¢CSDNå’Œè¯»è€…ä»¬åå¹´çš„é™ªä¼´ï¼Œä¸è®ºå¤–é¢å¦‚ä½•è¯„ä»·CSDNï¼Œè¿™é‡Œå§‹ç»ˆæ˜¯æˆ‘çš„å®¶ï¼Œåœ¨è¿™é‡Œå†™æ–‡ç« å¾ˆæ¸©é¦¨ï¼Œä¹Ÿè®¤è¯†äº†å¾ˆå¤šå¤§ä½¬å’Œæœ‹å‹ã€‚æ­¤å¤–ï¼Œä¸ªäººæ„Ÿè§‰ä»Šå¹´æ˜¯æˆ‘è¿‘åå¹´æ–‡ç« è´¨é‡æœ€é«˜çš„ä¸€å¹´ï¼Œæ¯ä¸€ç¯‡éƒ½å†™å¾—å¾ˆç”¨å¿ƒï¼Œéƒ½æ˜¯æˆ‘çš„è¡€è‚‰ï¼Œå¾ˆå¤šéƒ½è¦è‡ªå·±ä»é›¶å»å­¦ä¹ å†åˆ†äº«ï¼Œä¹Ÿå¸Œæœ›å¸®åŠ©æ›´å¤šåˆå­¦è€…ã€‚æ€»ä¹‹ï¼Œå¸Œæœ›è‡ªå·±è¿˜èƒ½å†™äºŒåå¹´ï¼Œäº”åå¹´ï¼Œä¸€è¾ˆå­ã€‚

(By:Eastmount 2021-12-07 æ™šä¸Š12ç‚¹ http://blog.csdn.net/eastmount/ )
