# 原创
：  论文推荐 | 借助大语言模型GPT-4辅助恶意代码动态分析

# 论文推荐 | 借助大语言模型GPT-4辅助恶意代码动态分析

**2023年是大语言模型发展的元年，许多大语言模型崭露头角，以ChatGPT为首的生成式对话模型已然成为人工智能领域的研究热点，引领着自然语言处理技术不断发展。得益于大语言模型在多项语言任务和实际应用上取得的显著成果，现如今，各个领域都在积极投入资源和努力，共同推动大模型的建设和发展。这篇文章将介绍由广东省智能信息处理重点实验室发布的一项研究成果——借助大语言模型GPT-4辅助恶意代码动态分析。该研究首次将大语言模型和提示工程技术应用于恶意代码检测，并且相较于以往工作，该研究所提方法在多个检测指标上都有着显著提升。**

**原文作者**：Pei Yan, Shunquan Tan, Miaohui Wang, Jiwu Huang<br/> **原文标题**：Prompt Engineering-assisted Malware Dynamic Analysis Using GPT-4<br/> **原文链接**： [https://arxiv.org/pdf/2312.08317.pdf](https://arxiv.org/pdf/2312.08317.pdf)<br/> **下载地址：** [https://github.com/yan-scnu/Prompted_Dynamic_Detection](https://github.com/yan-scnu/Prompted_Dynamic_Detection)<br/> **投稿作者：** 严沛<br/> **作者单位：** 广东省智能信息处理重点实验室

> 
<font color="red">该系列主要是督促自己阅读优秀论文及听取学术讲座，并分享给大家，希望您喜欢。这篇文章来源于广东省智能信息处理重点实验室团队及严沛老师的投稿（原创），推荐大家去阅读和学习，在此表示感谢。同时，欢迎大家给我留言评论以及投稿，学术路上期待与您前行，加油~</font>


#### 文章目录

---


## 摘要

动态分析方法可以有效识别加壳、包装和混淆的恶意代码，阻止它们入侵计算机。API序列作为一种重要的恶意代码动态行为信息，已逐渐成为动态分析方法的重要特征。尽管目前许多基于API序列的深度学习检测模型被提出，但这些模型普遍存在以下问题：

<mark>为了解决这些问题，本文引入GPT-4的提示工程辅助恶意代码动态分析。在所提方法中，我们使用GPT-4为API序列中的每个API调用生成解释文本，再使用预训练模型BERT获取解释文本的表征，进而得到API序列的表征。所提方法理论上能够为所有API调用生成表征，并且生成过程不需要依赖额外的数据集进行训练。此外，本文设计了基于CNN的检测网络从表征中进一步提取和学习特征。本文使用五个基准数据集来验证所提出模型的性能。实验结果表明，所提出的检测模型比目前主流的模型有着更好的检测性能，并且在跨数据库实验和小样本学习实验中也展现出很好的效果，充分验证了其优越的泛化性能。</mark>

---


## 1.简介

动态检测方法是一种根据恶意代码在运行过程中的动态行为特征进行检测的方法：将代码放进沙箱中运行，沙箱会记录下代码在运行过程中的行为特征，再通过行为特征判断该代码是否为恶意代码。API序列是一种最重要、最常用的动态行为特征，记录代码在运行过程中依次调用的API。为方便表示，我们将API序列中的每个元素称之为API调用。因为API序列和自然文本存在较高的相似性，因此目前主流的恶意代码检测方法都有借鉴自然语言处理领域相关模型。随着深度学习技术被广泛且成熟地应用于自然语言处理任务，部分研究者尝试将基于深度学习的文本分类模型应用于API序列分类任务，他们所提模型也普遍表现出更好的检测性能。最近，大语言模型凭借着强大的语言理解和语言生成能力成为了当前NLP领域的研究热点，其他领域也在尝试集成大语言模型来解决相关问题。在恶意代码检测领域，部分研究团队也在探索如何将大语言模型和恶意代码检测相结合，一些结合后的模型被相继提出，但整体而言，现有模型的检测性能往往欠佳。此外，目前基于API序列的检测模型还普遍存在以下问题：

为了解决上述问题，本文提出了一种借助GPT-4提示工程辅助恶意代码检测的方法。本文先使用GPT-4为API调用生成解释文本，再使用大规模预训练模型为解释文本生成表征，通过这种方法可以间接得到API序列的表征，接着再设计相应的深度神经网络模块进行学习和分类。

本文的主要贡献如下：

---


## 2 研究方法

**(1) 模型架构**<br/> 在本研究中，我们使用GPT-4为API调用生成解释文本。得益于在大规模语料库上进行训练，GPT-4可以通过提示工程对 API 调用相关知识进行概括和重述。在提示工程中，我们可以通过对提示文本进行设计，引导GPT-4生成更高质量的解释文本。 在得到解释文本后，我们使用预训练模型BERT来为解释文本生成表征，之后将每个API调用的解释文本的表征拼接起来，得到整个 API 序列的表征。随后部署深度神经网络从这些表征中提取特征并进行学习，最后通过带有softmax函数的全连接层连接到各个恶意代码类别。 所提模型的总体架构如图所示。

**(2) 表征生成**

**(3) 表征学习**<br/> 在三维张量表征中，每个嵌入通道对应一个表征矩阵，表征矩阵中的每个元素都与周围元素之间存在上下文关联性。具体而言，垂直相关性源于解释文本，水平相关性来自API序列。 因此，有必要设计一个用于表征调整和语义信息捕获模块。考虑到每个维度的表征反映了API调用的特征，并且跨维度表征的相关性不强，因此我们采用逐层卷积网络来微调每个维度的表征。此外，逐层卷积网络可以捕获表征矩阵中各元素的上下文关联性，也能够对表征矩阵的局部特征进行提取。

在对表征进行微调之后，我们参照**TextCNN**，使用具有不同内核大小的二维卷积块来生成各自的特征图，并执行最大池化和批量归一化操作。最大池化操作可以从每个特征图中选择最大值，从而使模型能够捕获每个特征图中的重要特征。考虑到特征图各维度统计特性不同，导致不同维度的最大池化结果存在较大差异，我们对最大池化层输出特征进行标准化，最后将输出的特征进行拼接，通过带有**softmax**函数的全连接层连接到各个分类类别。

**(4) 质量表征**<br/> 表征方法将API调用映射成固定长度的连续向量，我们可以通过这些向量计算每个API调用之间的相关性。API调用的相关性越高，他们表征向量的接近程度越高。**TextCNN**和**BiLSTM**都使用词嵌入层对API调用进行表征，表征以向量形式进行呈现；我们所提的表征生成方法使用一个矩阵对API调用进行表征。本文使用余弦相似度作为API调用相关性的度量指标，如果两个API调用的相关性越高，则它们表征的余弦相似度越接近于1。具体公式如下所示，其中  
     
      
       
       
         A 
        
       
      
        \textbf{A} 
       
      
    A 和  
     
      
       
       
         B 
        
       
      
        \textbf{B} 
       
      
    B 分别为两个不同的API调用的表征。<br/>  
      
       
        
        
          C 
         
        
          o 
         
        
          s 
         
        
          i 
         
        
          n 
         
        
          e 
         
        
          ( 
         
        
          A 
         
        
          , 
         
        
          B 
         
        
          ) 
         
        
          = 
         
         
          
          
            ∣ 
           
           
           
             ∑ 
            
            
            
              j 
             
            
              = 
             
            
              1 
             
            
           
             n 
            
           
          
            ( 
           
           
           
             A 
            
            
            
              i 
             
            
              j 
             
            
           
          
            ∗ 
           
           
           
             B 
            
            
            
              i 
             
            
              j 
             
            
           
          
            ) 
           
          
            ∣ 
           
          
          
           
            
             
             
               ∑ 
              
              
              
                j 
               
              
                = 
               
              
                1 
               
              
             
               n 
              
             
            
              ( 
             
             
             
               A 
              
              
              
                i 
               
              
                j 
               
              
             
               2 
              
             
            
              ) 
             
            
           
          
            ∗ 
           
           
            
             
             
               ∑ 
              
              
              
                j 
               
              
                = 
               
              
                1 
               
              
             
               n 
              
             
            
              ( 
             
             
             
               B 
              
              
              
                i 
               
              
                j 
               
              
             
               2 
              
             
            
              ) 
             
            
           
          
         
        
       
         Cosine(\textbf{A},\textbf{B}) = \frac{| \sum_{j=1}^{n}(\textbf{A}_{ij} * \textbf{B}_{ij}) |}{\sqrt{\sum_{j=1}^{n}(\textbf{A}_{ij}^2)} * \sqrt{\sum_{j=1}^{n}(\textbf{B}_{ij}^2)}} 
        
       
     Cosine(A,B)=∑j=1n​(Aij2​)
​∗∑j=1n​(Bij2​)
​∣∑j=1n​(Aij​∗Bij​)∣​

下图分别为**TextCNN**、**BiLSTM**和我们所提方法生成的表征关联热力图（训练数据集为**Aliyun**），从图中我们可以看出**TextCNN**和**BiLSTM**得到的API调用表征关联比较稀疏，关联矩阵中有约25%的元素为0，由于数据集的划分，部分在测试集中的API调用并没有出现在训练集中，导致模型无法学到未见过的API调用的表征，进而影响模型的检测性能和泛化性能。而我们所提的表征生成方法理论上可以为所有API调用生成表征，因此表征关联矩阵相对稠密，并且表征生成的过程不依赖额外的数据集进行训练，不存在因为数据集划分导致部分API调用缺失表征的问题，这也使得所提模型有更好的检测性能。

---


## 3.实验

### 3.1 实验环境与数据集

**实验环境**

**数据集统计特性**

---


### 3.2 检测性能对比实验

为了验证本文所提模型的性能，我们使用基于**RNN**的模型、基于**CNN**的模型、基于**CNN+RNN**的模型、基于**Transformer**的模型与其进行比较，并分别在**Aliyun**、**Catak**、**GraphMal**三个数据集上进行训练和验证。此外，为了验证所提表征方法的性能，本文做了消融实验。在保持表征学习模块不变的条件下，我们使用嵌入层创建API序列的表征矩阵，然后通过复制该矩阵来构造表征张量。该张量的形状与我们所提表征方法生成的张量形状相同，都是 
     
      
       
       
         ( 
        
       
         ∈ 
        
        
        
          R 
         
         
         
           100 
          
         
           ∗ 
          
         
           102 
          
         
           ∗ 
          
         
           768 
          
         
        
       
         ) 
        
       
      
        ( \in R^{100*102*768}) 
       
      
    (∈R100∗102∗768)，该方法在表格中记为**Embed3D+CNN**。如下表所示，与目前主流方法相比，本文所提的模型在三个数据集上有着更好的检测性能。

---


### 3.3 泛化性能对比实验

为了验证所提模型的泛化性能，本文设计了两种类型的跨库实验：表征适应实验和领域适应实验。这两种实验都是使用不同的数据集分别进行训练和验证，区别在于训练和验证数据集包含API调用种类的差异。表征适应实验使用的训练和验证数据集的API调用种类差异小，比如训练集和验证集都在 
     
      
       
        
        
          D 
         
         
         
           b 
          
         
           a 
          
         
           s 
          
         
           e 
          
         
        
       
      
        \mathcal{D}_{base} 
       
      
    Dbase​集合中；而领域适应实验使用的训练和验证数据集的API调用种类差异大，比如训练数据集在 
     
      
       
        
        
          D 
         
         
         
           b 
          
         
           a 
          
         
           s 
          
         
           e 
          
         
        
       
      
        \mathcal{D}_{base} 
       
      
    Dbase​集合中，验证数据集在 
     
      
       
        
        
          D 
         
         
         
           l 
          
         
           a 
          
         
           r 
          
         
           g 
          
         
           e 
          
         
        
       
      
        \mathcal{D}_{large} 
       
      
    Dlarge​集合中，在这种情况下，验证集许多的API调用并没有出现在训练集中，这对检测模型的泛化能力提出了更高的要求。

---


### 3.4 表征质量实验

---


## 4.总结

本文提出了一种借助GPT-4提示工程辅助恶意代码动态检测的方法。我们首先设计提示文本来引导GPT-4为API序列中的每个API调用生成解释文本，接着使用预训练模型BERT为每个解释文本生成表征，进而得到整个API序列的表征，之后使用CNN从表征中进一步提取和学习特征，并最终实现恶意代码的分类。在所提方法中，API序列表征生成不依赖与恶意代码数据集的训练，理论上可以为所用API序列生成表征，因此所提方法具备较强的泛化性能，也能更好地应对概念漂移现象。与目前的主流模型相比，我们所提模型在检测效果、泛化性能上都有着较大地提升。在未来工作中，我们将收集更大规模的恶意代码表征数据集，为构建专门面向恶意代码检测的大规模模型做必要准备。

这篇文章就写到这里，希望对您有所帮助，在此感谢严老师的投稿及创作，未来作者也将分享更多LLM和安全结合的文章，尤其是恶意代码。此外，请大家多多关注广东省智能信息处理重点实验室团队的成果，2024年继续加油！感恩遇见，不负青春。

(By:Eastmount 2024-01-21 周四夜于武汉 http://blog.csdn.net/eastmount/ )
