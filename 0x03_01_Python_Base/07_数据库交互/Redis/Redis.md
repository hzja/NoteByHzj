# Redis

## 基本数据类型

Redis支持5种数据类型：string、hash、list、set、zset。



### String 

**String**是Redis最基础的类型，就是做简单的KV缓存，String可以缓存任何数据

**底层是怎么存储的？**

**SDS：**Redis没有直接使用C语言的字符串，而是自己构建了一个`动态字符串（SDS）`。

1. C字符串获取字符串长度时间复杂度为O(N)，而SDS因为保存了长度信息，所以获取字符串长度的时间复杂度降低到了O(1)
2. 因为C字符串不记录自身长度和空闲空间，很容易造成缓冲区溢出，而SDS在拼接字符串之前会检测剩余空间能否满足需求，不能满足需求的就会扩容
3. C字符串再增长或缩短时，需要做内存重分配，而SDS对这种情况作了优化，包括两种方式：空间预分配和惰性空间释放

- - **空间预分配：**除了分配扩容时所需要的空间，还会额外多分配一些的空间
  - **惰性空间释放：**在对字符串进行缩短操作的时候，程序并不会立刻回收缩短之后多出来的字节，而是使用free属性将这些字节的数量记录下来等以后使用

- ![v2-cdbba6ed68e0fc3b0f6a3baf2f05be34_720w](D:\Note\python\数据库交互\图片\v2-cdbba6ed68e0fc3b0f6a3baf2f05be34_720w.jpg)

就好比这样的一个命令，其实我是在Redis创建了两个SDS，一个是名为`aobing`的Key SDS，另一个是名为`cool`的Value SDS，就算是字符类型的List，也是由很多的SDS构成的Key和Value罢了。

**使用场景**

- **缓存功能：**利用**Redis**缓存热点数据，可以提高系统并发能力、减轻后端数据库的压力。
- **计数器：**微博数、 粉丝数，可以快速实现计数和查询的功能
- **计时器：**用户下订单后，需要在10分钟内完成支付，否则订单关闭，结合键空间事件通知就行
- **分布式锁：**

~~~  python
redis 127.0.0.1:6379> SET name "runoob"
"OK"
redis 127.0.0.1:6379> GET name
"runoob"

# incr计数器
redis 127.0.0.1:6379> set mycounter 99 
OK
redis 127.0.0.1:6379> get mycounter
"99"
redis 127.0.0.1:6379> incr mycounter
(integer) 100
redis 127.0.0.1:6379> incrby mycounter 2
(integer) 102
redis 127.0.0.1:6379> incrby mycounter -2
(integer) 100
~~~



### Hash

**Hash**也是一种KV缓存，只不过它的Value是一个Map，适合存储对象

**底层是怎么存储的？**

底层使用**散列****表**实现，散列表的好处就是如果散列函数选好，值的分布均匀，那么时间复杂度可以接近 O(1) 的时间内处理读写操作。散列表通过散列函数实现Key和数组下标的转换，使用链地址法来解决键冲突，被分配到同一个索引位置的多个键值对会形成一个单向链表。散列表设计的好坏决定了散列冲突的概率，也就决定散列表的性能，**当一个哈希只包含少量键值对，那么Redis就会使用压缩列表存储数据**

**使用场景**

- **比如微博用户信息，**用户ID为key，value对象包含姓名，年龄，生日、爱好、所在地等信息，主要有以下2种存储方式：

1. 1. **第一种方式将用户ID作为查找key，把其他信息序列化成一个string类型存储**，这种方式的缺点是，增加了序列化/反序列化的开销，并且在需要修改其中一项信息时，需要把整个对象取回，并且修改操作需要对并发进行保护，引入CAS等复杂问题。
   2. **第二种方式将用户ID作为查找key**，**把其他信息序列化成一个Map类型存储**，这样对数据的修改和存取都可以直接通过其内部Map的Key(Redis里称内部Map的key为field)，也就是通过 key(用户ID) + field(属性标签) 就可以操作对应属性数据了，既不需要重复存储数据，也不会带来序列化和并发修改控制的问题。

~~~ python
redis> HSET myhash field1 "Hello" field2 "World"
"OK"
redis> HGET myhash field1
"Hello"
redis> HGET myhash field2
"World"
~~~



### List

**List**列表是简单的字符串列表，你可以向列表的头部或尾部插入元素，并且可以保证顺序。

**常用命令：**lpush，rpush，lpop，rpop，lrange（获取列表片段，LRANGE key start stop）

**底层是怎么存储的？**

List的底层实现是双向链表， 但是当元素较少时，会优先考虑使用压缩列表，因为压缩列表更省空间。

**使用场景**

- **微博上滑下滑的功能**，如果用户下滑就不断向List中添加数据，如果性能高，滑的时候可以一次一页的添加
- **微博我经常访问的人**：记录前N个最新访问的用户Id列表，超出的范围可以从数据库中获得
- **消息队列：**这个最基本的了吧

~~~ python
//把当前登录人添加到链表里
ret = r.lpush("login:last_login_times", uid)
//保持链表只有N位
ret = redis.ltrim("login:last_login_times", 0, N-1)
//获得前N个最新登陆的用户Id列表
last_login_list = r.lrange("login:last_login_times", 0, N-accbabbaab
~~~



### Set

**Set**是String类型的无序集合，可以交集，并集，差集，set中的元素是没有顺序的，所以添加，删除，查找的复杂度都是O(1)

**常用命令：**sadd，spop，smembers，sunion

**底层是怎么存储的？**

底层使用了**数组**和**哈希表**两种数据结构，如果存储的元素类型是哈希类型，就会被保存到哈希表里，如果是数组类型，就用数组保存，如果这个数组长度超出限制，那么多余的也会存储到哈希表。因为数组存储是有序的，所以set可以二分查找和范围查找

**使用场景**

- **交集，并集，差集：**Set与List类似，都是提供一个列表的功能，特殊之处在于Set是可以自动去重的，并且set提供了判断某个成员是否在一个Set集合内的重要接口
- **微博共同关注、互相关注、共同喜好**，可以将一个用户所有的关注人存在一个集合中，将其所有粉丝存在一个集合

~~~ python
//book表存储book名称
set book:1:name    ”The Ruby Programming Language”
set book:2:name     ”Ruby on rail”
set book:3:name     ”Programming Erlang”
//tag表使用集合来存储数据，因为集合擅长求交集、并集
sadd tag:ruby 1
sadd tag:ruby 2
sadd tag:web 2
sadd tag:erlang 3
//即属于ruby又属于web的书？
inter_list = redis.sinter("tag.web", "tag:ruby") 
//即属于ruby，但不属于web的书？
inter_list = redis.sdiff("tag.ruby", "tag:web") 
//属于ruby和属于web的书的合集？
inter_list = redis.sunion("tag.ruby", "tag:web")
~~~



### Zset

**Zset**是排序的**Set**，去重而且排序，写进去的时候给一个分数，可以自动根据分数排序

**常用命令**：zadd，zrange，zrem，zcard。*zadd 命令：*添加元素到集合，元素在集合中存在则更新对应score。

**底层是怎么存储的？**

Zset的内部使用**散列表**和**跳跃表**来实现有序集合，散列表里放的是成员到score（si告尔）的映射，而跳跃表里存放的是所有的成员，排序依据是散列表里存的分数，使用跳跃表可以获得二分查找的效率

[跳表](https://www.yuque.com/keep_running/python/emvriu)

**跳表是可以实现了二分查找的有序链表**，就比如拿普通的链表的来说，如果想查找一个元素，那么只能从头开始找，时间复杂度为O(n)，而跳表是通过在原始链表的基础上创建多层的索引结构，查找的某一个元素的时候就可以使用类似二分查找的方式从上到下查找元素。查询、插入、删除的时间复杂度都是O(log n)。与平衡二叉树差不多，但是比平衡二叉树简单，范围查找时比红黑树速度更快为O(logn)。



**压缩列表**

当一个Zset只包含少量数据时，那么Redis就会使用压缩列表来做列表的底层实现。每个集合元素使用两个紧挨在一起的压缩列表节点来保存，第一个节点保存元素的成员，第二个节点保存元素的分值。并且压缩列表内的集合元素按分值从小到大的顺序进行排列，小的放置在靠近表头的位置，大的放置在靠近表尾的位置。



**使用场景**

- **微博热搜：**比如微博以关注度作为score（si告尔）来存储，这样获取时就是自动按关注度排好序的
- **弹幕系统：**比如B站的视频回放的时候需要播放用户发的弹幕，通过Zadd添加消息，其中score记录弹幕的相对视频的开始时间，视频播放过程中通过ZrangeByScore两秒一次轮询，播放弹幕

~~~ python
redis 127.0.0.1:6379> zadd zs 100 redis
(integer) 1
redis 127.0.0.1:6379> zadd zs 96 mongodb
(integer) 1
redis 127.0.0.1:6379> zadd zs 97 rabitmq
(integer) 1
redis 127.0.0.1:6379> zadd zs 98 rabitmq
(integer) 0
redis 127.0.0.1:6379> > ZrangeByScore zs 0 1000
1) "mongodb"
2) "rabitmq"
3) "redis"
~~~



### 压缩列表

首先应该知道数组存储时其实是一堆连续存放大小相同的格子，如果要存储的字符串大小不一，那么就需要申请格子的时候就需要申请更大的格子，会浪费部分存储空间。压缩列表继承了数组连续存放的特点，然后对每一个元素添加一个len的属性，我们在遍历节点的之后就知道每个节点的长度，就可以很容易计算出下一个节点的位置。

![image](D:\Note\python\数据库交互\图片\image1.png)



### 持久化策略

**Redis** 提供了 RDB 和 AOF 两种持久化方式，

**RDB：**RDB是通过写定时策略对数据做快照，分为手动触发和自动触发两种方式，实际原理就是是fork一个子进程将数据写入临时文件，写入成功后，再替换之前的文件。这种方式实时性较差，而且备份期间会出现请求变慢的情况。

- **手动触发**

- - save命令：执行bgsave命令时Redis主进程会fork一个子进程来完成RDB的过程。

- **自动触发**

- - 配置redis.conf，定时定量触发执行
  - 执行shutdown命令关闭服务器时，如果没有开启AOF持久化功能，那么会自动执行一次bgsave
  - 主从同步模式

**AOF：**AOF是通过类似记录增量日志的方式记录所有的写操作，缺点是AOF会越来越大，为了避免这个问题，Redis会对AOF定期重写，重写意味着Redis只关心所有键值对的最新状态，不再关心历史状态，重写虽然可以减少AOF文件大小，但是可能导致重写期间请求出现变慢的情况，所以Redis将这种任务放到后台子线程去处理，并且为了避免子线程处理过程中主线程的数据发生变化，Redis还做了一层优化，就是子线程处理过程中，主线程会将数据变更追加到AOF重写缓冲区，等到AOF文件重写完成后，再将AOF重写缓冲区中的数据加载到AOF文件。

- **手动触发**
- **自动触发**，会监控以下三个变量

- - 记录当前AOF文件大小的变量aof_current_size
  - 记录最后一次AOF重写之后，AOF文件大小的变量aof_rewrite_base_size
  - 增长百分比变量aof_rewrite_perc



### key过期策略

**两种过期策略**（redis使用被动删除+定期删除）

- **被动删除**：下一次查询到过期的key时，才会被删除
- **定期删除**：Redis内部维护了一个定时任务，这些任务每隔一段时间就会运行一次清理过期key的任务
- **强制删除：**如果redis使用的内存已经达到maxmemory配置的值时，会触发强制清理策略，清理策略如下方淘汰策略



### 内存淘汰策略

好的，面试官。这个问题我需要从两个方面来回答。 

第一个方面： 

当 Redis 使用的内存达到 maxmemory 参数配置的阈值的时候，Redis 就会根据配置的内存淘汰策略淘汰掉Key。 maxmemory 默认情况是当前服务器的最大内存。 

第二个方面： 

Redis 默认提供了 8 种缓存淘汰策略，总的来说我认为可以归类成五种：

1. 第一种， 采用 LRU 策略，就是把不经常使用的 key 淘汰掉。 
2. 第二种，采用 LFU 策略，它在 LRU 算法上做了优化，增加了数据访问次数，从而确保淘汰的是非热点 key。 
3. 第三种，随机策略，也就是是随机删除一些 key。 
4. 第四种，ttl 策略，从设置了过期时间的 key 里面，挑选出过期时间最近的 key 进行优先淘汰。
5. 第五种，禁止写入，当内存不够的时候，直接报错，这是默认的策略。 



1. volatile-lru：从已设置过期时间的数据集中挑选最近最少使⽤的数据淘汰。

2. volatile-random：从已设置过期时间的数据集中任意选择数据淘汰。

3. allkeys-lru：当内存不⾜以容纳新写⼊数据时，在键空间中，移除最近最少使⽤的 key(常用)

4. allkeys-random：从数据集（server.db[i].dict）中任意选择数据淘汰。
5. volatile-ttl：从已设置过期时间的数据集中挑选将要过期的数据淘汰。

6. no-eviction：禁⽌驱逐数据，也就是说当内存不⾜以容纳新写⼊数据时，新写⼊操作会报错OOM。

4.0 版本后增加以下两种：

7. volatile-lfu：从已设置过期时间的数据集中挑选最不经常使⽤的数据淘汰。

8. allkeys-lfu：当内存不⾜以容纳新写⼊数据时，在键空间中，移除最不经常使⽤的 key。



### 数据一致性

一般情况下，Redis被当做数据缓存使用，主要是为了减少数据库 IO，当应用程序需要去读取某个数据的时候，首先会先尝试去 Redis 里面加载，如果 命中就直接返回。反之就查询Mysql，查询到数据后再把这个数据缓存到 Redis 里面。在这样一个架构中，会出现一个问题，就是一份数据，同时保存在Mysql和 Redis 里面，当数据发生变化的时候，需要同时更新 Redis 和 Mysql，由于更新是有先后顺序的，所以就会出现数据一致性问题。



**方案一**：**延迟双删，**不严谨。

1. 先删除缓存
2. 再写数据库
3. 再次删除缓存



**方案二**：**MQ异步延迟双删（高并发）**

1. 先删除缓存
2. 再写数据库
3. 将删除的消息写入MQ（使用RocketMQ 的可靠性消息通信，来实现最终一致性）
4. 由MQ消费者去删除缓存



**方案三**：**异步更新缓存(基于binlog的同步机制，主从复制中获得的灵感)**

1. 先修改数据库
2. 再使用阿里的Canal订阅Binlog日志，将消息写入MQ，由MQ消费者去删除缓存



### 缓存击穿

指的是单个key非常热点，当这个key在失效的瞬间，大量的请求直接打到数据库上

#### 解决办法

1. **设置互斥锁：**在并发的多个请求中，只有第一个请求线程能拿到锁并执行数据库查询操作，其他的线程拿不到锁就阻塞等着，等到第一个线程将数据写入缓存后，直接走缓存。
2. **热点数据不过期**：直接将缓存设置为不过期，然后由定时任务去异步加载数据，更新缓存。使用时需要考虑能接受数据不一致的问题



### 缓存穿透

产生这个问题的原因可能是外部的恶意攻击，比如我们对用户信息进行了缓存，但是攻击者使用不存在的用户id频繁请求接口，导致查询缓存不命中，然后穿透 DB 查询依然不命中。

#### 解决办法

1. **缓存空对象：**从数据库找不到时，将这个空对象设置到缓存里边去，下次再请求的时候，就可以从缓存里边获取了，但是需要将空对象设置一个较短的过期时间。
2. **布隆过滤器（每次都查，会很慢）**

- 将所有的数据使用散列函数的方法映射到一个足够大的数组中，如果这个数组中查不到就直接过滤，存在的 key 则再进一步查询缓存和数据库；不直接存储到散列表的是因为随着数据量增多，占据的内存会很大。

**使用场景:**

1. 1. **网页爬虫对URL的去重：**避免爬取相同的URL地址
   2. **反垃圾邮件：**从数十亿个垃圾邮件列表中判断某邮箱是否垃圾邮箱（同理，垃圾短信）
   3. **大数据判断是否存在**：这就可以实现出上述的去重功能，如果你的服务器内存足够大的话，那么使用 HashMap 可能是一个不错的解决方案，理论上时间复杂度可以达到O(1)的级别，但是当数据量起来之后，还是只能考虑布隆过滤器



### 缓存雪崩

指的是多个key非常热点，当这些key在失效的瞬间，大量的请求直接打到数据库上

出现原因:

1. key同时失效    
2. redis本身崩溃了

#### 解决办法

1. **设置互斥锁：**在并发的多个请求中，只有第一个请求线程能拿到锁并执行数据库查询操作，其他的线程拿不到锁就阻塞等着，等到第一个线程将数据写入缓存后，直接走缓存。(缓存重建期间key是锁着的，这是过来1000个请求999个都在阻塞的。同样会导致用户等待超时，这是个治标不治本的方法！)
2. **热点数据不过期**：直接将缓存设置为不过期，然后由定时任务去异步加载数据，更新缓存。使用时需要考虑能接受数据不一致的问题
3. **设置不同的过期时间：**可以给缓存的过期时间再加上一个随机值，让每个 key 的过期时间分散开，不会集中在同一时刻失效。
4. **高可用：**使用主从模式和集群模式来尽量保证缓存服务的高可用。



### 主从模式

首先slave连接到master，master会启动一个线程，并把最新的**RDB**文件发送给slave的，slave首先将数据写入本地磁盘，然后加载进内存。这个过程可能有新的写请求，master会通过**AOF**增量日志的方式将新数据同步给slave，就像**MySQL**的**Binlog**一样，把日志增量同步给slave服务。通过这样的架构可以实现Redis读写分离提升数据查询效率，但是主从模式不提供容错和恢复功能，Master挂了需要手动切换主从



### 哨兵模式

哨兵会监视主从服务器，每隔2s都会发送ping命令，Master挂掉后，会通过Raft协议做选举将某个slave提升为master，但是主从架构无法实现在线扩容



### 集群模式

实现了Redis的分布式存储，通过每个节点存储不同的Slow槽实现数据分片的功能， 一个Redis集群包含16384个Slow槽，当我们存储Key的时候，Redis会根据Key去计算得到一个Slow的值，然后找到对应的节点进行读写；在高可用方面，集群模式引入了主从复制的模式，一个Master可以对应多个Slave节点，Master出现故障会选举和切换Slave

1. 集群中的每个节点负责维护一部分哈希槽。 比如一个集群可以有三个节点：

- 节点 A 负责处理 0 号至 5500 号哈希槽
- 节点 B 负责处理 5501 号至 11000 号哈希槽
- 节点 C 负责处理 11001 号至 16384 号哈希槽

2. 如果节点A向节点B发送ping消息，节点B没有在规定的时间内响应，那么节点A会标记节点B为疑似下线状态，同时把B的状态通过消息的方式发送给其他节点，如果超过半数以上的节点都标记B为疑似下线状态，B就会被标踢出集群，然后将会发生故障转移，优先从复制数据较多的从节点选择一个成为主节点，整个过程和哨兵非常类似，都是基于Raft协议做选举。



### 哨兵模式和集群模式区别

Redis 哨兵集群是基于主从复制来实现的，所以它可以实现读写分离，分担 Redis 读操作的压力 

而 Redis Cluster 集群的 Slave 节点只是实现冷备机制，它只有在 Master 宕机 之后才会工作。 

Redis 哨兵集群无法在线扩容，所以它的并发压力受限于单个服务器的资源配置。 

Redis Cluster 提供了基于 Slot 槽的数据分片机制，可以实现在线扩容提升写数 据的性能 从集群架构上来说，Redis 哨兵集群是一主多从， 而 Redis Cluster 是多主多从



### 为什么是单线程

1. 纯内存操作
2. 单线程也避免了CPU频繁的上下文切换，所以CPU不是瓶颈
3. 使用基于非阻塞的IO多路复用机制，一个线程可以跟踪多个客户端Socket状态，哪个就绪，就处理哪个
4. 如果使用多线程，意味着需要对Redis所有指令都考虑线程安全问题，也就是说需要加锁来解决，这种方式对性能的影响可能更大了
5. 使用基于跳跃表数据增删改效率非常高



### 如何实现客户端并发线程安全

1. 尽可能使用Redis自带的原子指令
2. 对于资源访问加锁
3. 通过Lua脚本去实现多个指令的操作



### 跳表

跳表是可以实现了二分查找的有序链表，就比如拿普通的链表的来说，如果想查找一个元素，那么只能从头开始找，时间复杂度为O(n)，而跳表是通过在原始链表的基础上创建多层的索引结构，查找的某一个元素的时候就可以使用类似二分查找的方式从上到下查找元素。查询、插入、删除的时间复杂度都是O(log n)，与平衡二叉树差不多，但是比平衡二叉树简单，范围查找时比红黑树速度更快为O(logn)。



### 为什么Redis选择使用跳表而不是红黑树来实现有序集合？

由以下四个方面对比跳表和红黑树：

1. 插入一个元素
2. 删除一个元素
3. 查找一个元素
4. 范围查找元素（比如查找值在 [100, 356] 之间的数据） 

其中，前三个操作红黑树也可以完成，且时间复杂度跟跳表是一样的。但是范围查找数据这个操作，红黑树的效率没有跳表高，因为跳表是先通过 O(logn)的时间复杂度查找到数据起点，然后在原始链表中顺序遍历就可以了，并且在Redis中可以散列表将查找的时间复杂度降为O(1)
